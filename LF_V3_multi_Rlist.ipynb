{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Learning (RNN) Demo for Load Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import all the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn, rnn_cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import random as rd\n",
    "import argparse\n",
    "import os, sys\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: setting all global parameters -- sec 2 network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time1 = time.time() # set up counter to record run time\n",
    "data_dir = './data/' # directory contains input data\n",
    "num_epoches = 8000 # training epoches for each customer samples\n",
    "n_steps = 48 # input size\n",
    "cus_num = 14\n",
    "test_batch_size = 70*48*cus_num # days of a batch\n",
    "test_minibatch_size = 70*48\n",
    "train_batch_size = 10*48*cus_num\n",
    "feature_size = 1 # same time of a week\n",
    "n_hidden = 30 # input size\n",
    "num_layers = 5\n",
    "n_output = 1\n",
    "Rs =4000\n",
    "cus_label_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 4: define data generating function code. \n",
    "which generate a batch of batch-size large sequence data. the data is feature_size dims width and is a time series of float32 of steps steps. inputs and outputs are:\n",
    "\n",
    "inputs:\n",
    "----n_batch: number of samples in a batch\n",
    "----steps: the sequence length of a sample data\n",
    "----feature_size: dimensions of a single time step data frame\n",
    "\n",
    "outputs:\n",
    "----X inputs, shape(n_batch,steps,feature_size)\n",
    "----Y outputs should be, shape(n_batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findTrLabel(index,n):\n",
    "    res = 0\n",
    "    tmp = 0\n",
    "    for i in range(0,cus_num):\n",
    "        tmp = tmp + cus_label_list[i]\n",
    "        if tmp > index:\n",
    "            res = i\n",
    "            break\n",
    "    \n",
    "    retur = np.zeros((n,cus_num))\n",
    "    retur[:,res] = 1\n",
    "    \n",
    "    #retur = np.zeros((cus_num))\n",
    "    #retur[res] = 1\n",
    "    \n",
    "    #retur = float(retur)\n",
    "    return retur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findTsLabel(index,n):\n",
    "    res = 0\n",
    "    res = np.floor(index/test_minibatch_size)\n",
    "    \n",
    "    retur = np.zeros((n,cus_num))\n",
    "    retur[:,res] = 1\n",
    "    \n",
    "    #retur = np.zeros((cus_num))\n",
    "    #retur[res] = 1\n",
    "    \n",
    "    #retur = float(retur)\n",
    "    return retur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_data_gen(totaltraindays,x_data,y_data,steps = 48, n_batch = train_batch_size):\n",
    "    X = np.zeros((n_batch,steps,feature_size))\n",
    "    Y = np.zeros((n_batch,feature_size))\n",
    "    rang = range(totaltraindays) # test day sample range\n",
    "    train_days_list = rd.sample(rang,n_batch) # pick unduplicated n indexes as examples\n",
    "    #print totaltraindays\n",
    "    tmpX = [x_data[i,0-steps:] for i in train_days_list]\n",
    "    tmpY = [y_data[i,:] for i in train_days_list]\n",
    "    X = np.array(tmpX).reshape(n_batch,steps,feature_size)\n",
    "    Y = np.array(tmpY).reshape(n_batch,feature_size)\n",
    "    tmpZ = [findTrLabel(i,steps) for i in train_days_list]\n",
    "    Z = np.array(tmpZ).reshape(n_batch,steps,cus_num)\n",
    "        \n",
    "    return (X,Y,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_data_gen(x_data,y_data,steps = 48, n_batch = test_batch_size):\n",
    "    X = np.zeros((n_batch,steps,feature_size))\n",
    "    Y = np.zeros((n_batch,feature_size))\n",
    "    tmpZ = [findTsLabel(i,steps) for i in range(test_batch_size)]\n",
    "    #print tmpZ\n",
    "    Z = np.array(tmpZ).reshape(n_batch,steps,cus_num)\n",
    "    #print x_data[:,0-steps:].shape,y_data.shape\n",
    "    #print n_batch, steps\n",
    "    X = x_data[:,0-steps:].reshape(n_batch,steps,feature_size)\n",
    "    Y = y_data.reshape(n_batch,feature_size)\n",
    "    \n",
    "    return (X,Y,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: construct RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create placeholder for x and y\n",
    "x = tf.placeholder(\"float\",[None,n_steps,feature_size])\n",
    "z = tf.placeholder(\"float\",[None,n_steps,cus_num])\n",
    "#z = tf.placeholder(\"float\",[None,cus_num])\n",
    "istate = tf.placeholder(\"float\",[None,num_layers*2*n_hidden])\n",
    "y = tf.placeholder(\"float\",[None,n_output])\n",
    "\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'inp': tf.Variable(tf.random_normal([cus_num, n_hidden])),\n",
    "    'hidden': tf.Variable(tf.random_normal([feature_size, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output]))\n",
    "}\n",
    "biases = {\n",
    "    'inp': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(_X, _Z, _istate, _weights, _biases):\n",
    "\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    _Z = tf.transpose(_Z, [1, 0, 2])\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, feature_size]) # (n_steps*batch_size, n_input)\n",
    "    _Z = tf.reshape(_Z, [-1, cus_num])\n",
    "    # Linear activation\n",
    "    _X = tf.matmul(_X, _weights['hidden']) + _biases['hidden']\n",
    "    _Z = tf.matmul(_Z, _weights['inp']) + _biases['inp']\n",
    "    _Q = tf.add(_X,_Z)\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    stacked_lstm_cell = rnn_cell.MultiRNNCell([lstm_cell]*num_layers)\n",
    "    \n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _Q = tf.split(0, n_steps, _Q) # n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(stacked_lstm_cell, _Q, initial_state=_istate)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get inner loop last output\n",
    "    return tf.matmul(outputs[-1], _weights['out']) + _biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = RNN(x, z, istate, weights, biases)\n",
    "\n",
    "#cost function \n",
    "cost = tf.reduce_mean(tf.pow(pred-y,2)) # cost function of this batch of data\n",
    "#cost2 = tf.abs(pred-y) # \n",
    "#compute parameter updates\n",
    "#train_op = tf.train.GradientDescentOptimizer(0.008).minimize(cost)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "#optimizer2 = tf.train.RMSPropOptimizer(0.005, 0.3).minimize(cost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## iterating among all customers to find current training customer\n",
    "result_final = []\n",
    "#cus_id_forselect[cus_num]\n",
    "sim_id_forecast = [0,266,295,431,465,597,615,627,736,798]\n",
    "dis_id_forecast = [0,230,460,487,520,655,754,767,818,907]\n",
    "cus_list = [8,9,11,18,29,45,48,49,58,60,64,65,66,68]\n",
    "starti = 0\n",
    "endi = cus_num\n",
    "for i in range(starti,endi):\n",
    "    #ii = cus_id[i]\n",
    "    ii = cus_list[i]#sim_id_forecast[i]\n",
    "    test_x_name = data_dir + 'test_x_' + str(ii) + '.csv'\n",
    "    test_y_name = data_dir + 'test_y_' + str(ii) + '.csv'\n",
    "    train_x_name = data_dir + 'train_x_' + str(ii) + '.csv'\n",
    "    train_y_name = data_dir + 'train_y_' + str(ii) + '.csv'\n",
    "    leng_list = []\n",
    "    tmp_data = np.array(pd.read_csv(test_x_name,header = None))\n",
    "    if i == starti:\n",
    "        test_x_data = tmp_data[:,1:]\n",
    "    else:\n",
    "        test_x_data = np.concatenate((test_x_data,tmp_data[:,1:]),axis=0)\n",
    "    \n",
    "    # print test_x_data.dtype  data are stored as float64 double precision format\n",
    "    tmp_data = np.array(pd.read_csv(test_y_name,header = None))\n",
    "    if i == starti:\n",
    "        test_y_data = tmp_data[:,1:]\n",
    "    else:\n",
    "        test_y_data = np.concatenate((test_y_data,tmp_data[:,1:]),axis=0)\n",
    "    \n",
    "    tmp_data = np.array(pd.read_csv(train_x_name,header = None))\n",
    "    if i == starti:\n",
    "        train_x_data = tmp_data[:,1:]\n",
    "    else:\n",
    "        train_x_data = np.concatenate((train_x_data,tmp_data[:,1:]),axis=0)\n",
    "        \n",
    "    tmp_data = np.array(pd.read_csv(train_y_name,header = None))\n",
    "    if i == starti:\n",
    "        train_y_data = tmp_data[:,1:]\n",
    "    else:\n",
    "        train_y_data = np.concatenate((train_y_data,tmp_data[:,1:]),axis=0)\n",
    "    cus_label_list.append(tmp_data[:,1:].shape[0])\n",
    "    \n",
    "traindays = train_y_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:6: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47040, 48, 1) (47040, 48, 14)\n",
      "-0.0552028231541\n",
      "Iter 0 ---- Process: 0.00%\n",
      "-0.023096722104\n",
      "Iter 10 ---- Process: 0.12%\n",
      "-0.0102009758356\n",
      "Iter 20 ---- Process: 0.25%\n",
      "-0.00166911906849\n",
      "Iter 30 ---- Process: 0.38%\n",
      "0.0138507578893\n",
      "Iter 40 ---- Process: 0.50%\n",
      "0.052918972791\n",
      "Iter 50 ---- Process: 0.62%\n",
      "0.120314238023\n",
      "Iter 60 ---- Process: 0.75%\n",
      "0.185857387239\n",
      "Iter 70 ---- Process: 0.88%\n",
      "0.227011934052\n",
      "Iter 80 ---- Process: 1.00%\n",
      "0.254235131245\n",
      "Iter 90 ---- Process: 1.12%\n",
      "0.269043896182\n",
      "Iter 100 ---- Process: 1.25%\n",
      "0.278921171295\n",
      "Iter 110 ---- Process: 1.38%\n",
      "0.306556777632\n",
      "Iter 120 ---- Process: 1.50%\n",
      "0.323216442534\n",
      "Iter 130 ---- Process: 1.62%\n",
      "0.317621192264\n",
      "Iter 140 ---- Process: 1.75%\n",
      "0.305514134967\n",
      "Iter 150 ---- Process: 1.88%\n",
      "0.321736749108\n",
      "Iter 160 ---- Process: 2.00%\n",
      "0.374543369699\n",
      "Iter 170 ---- Process: 2.12%\n",
      "0.387040901926\n",
      "Iter 180 ---- Process: 2.25%\n",
      "0.384578725231\n",
      "Iter 190 ---- Process: 2.38%\n",
      "0.379514278114\n",
      "Iter 200 ---- Process: 2.50%\n",
      "0.401430346915\n",
      "Iter 210 ---- Process: 2.62%\n",
      "0.402676509333\n",
      "Iter 220 ---- Process: 2.75%\n",
      "0.406994615216\n",
      "Iter 230 ---- Process: 2.88%\n",
      "0.411337962644\n",
      "Iter 240 ---- Process: 3.00%\n",
      "0.419588941526\n",
      "Iter 250 ---- Process: 3.12%\n",
      "0.418540059736\n",
      "Iter 260 ---- Process: 3.25%\n",
      "0.426711681974\n",
      "Iter 270 ---- Process: 3.38%\n",
      "0.427004807983\n",
      "Iter 280 ---- Process: 3.50%\n",
      "0.423570274382\n",
      "Iter 290 ---- Process: 3.62%\n",
      "0.43741637476\n",
      "Iter 300 ---- Process: 3.75%\n",
      "0.439277767929\n",
      "Iter 310 ---- Process: 3.88%\n",
      "0.44557678334\n",
      "Iter 320 ---- Process: 4.00%\n",
      "0.450366828378\n",
      "Iter 330 ---- Process: 4.12%\n",
      "0.452226985599\n",
      "Iter 340 ---- Process: 4.25%\n",
      "0.45016027279\n",
      "Iter 350 ---- Process: 4.38%\n",
      "0.464538811842\n",
      "Iter 360 ---- Process: 4.50%\n",
      "0.454281744143\n",
      "Iter 370 ---- Process: 4.62%\n",
      "0.47780203674\n",
      "Iter 380 ---- Process: 4.75%\n",
      "0.488294078375\n",
      "Iter 390 ---- Process: 4.88%\n",
      "0.493553476925\n",
      "Iter 400 ---- Process: 5.00%\n",
      "0.502490769313\n",
      "Iter 410 ---- Process: 5.12%\n",
      "0.509690041857\n",
      "Iter 420 ---- Process: 5.25%\n",
      "0.513961592161\n",
      "Iter 430 ---- Process: 5.38%\n",
      "0.524929198983\n",
      "Iter 440 ---- Process: 5.50%\n",
      "0.534616945444\n",
      "Iter 450 ---- Process: 5.62%\n",
      "0.535558192766\n",
      "Iter 460 ---- Process: 5.75%\n",
      "0.545387238135\n",
      "Iter 470 ---- Process: 5.88%\n",
      "0.553648525749\n",
      "Iter 480 ---- Process: 6.00%\n",
      "0.562290654895\n",
      "Iter 490 ---- Process: 6.12%\n",
      "0.556013123292\n",
      "Iter 500 ---- Process: 6.25%\n",
      "0.566169461357\n",
      "Iter 510 ---- Process: 6.38%\n",
      "0.570091423\n",
      "Iter 520 ---- Process: 6.50%\n",
      "0.569411426558\n",
      "Iter 530 ---- Process: 6.62%\n",
      "0.573466628054\n",
      "Iter 540 ---- Process: 6.75%\n",
      "0.575391614847\n",
      "Iter 550 ---- Process: 6.88%\n",
      "0.572451850111\n",
      "Iter 560 ---- Process: 7.00%\n",
      "0.57967763723\n",
      "Iter 570 ---- Process: 7.12%\n",
      "0.577154455896\n",
      "Iter 580 ---- Process: 7.25%\n",
      "0.580175541808\n",
      "Iter 590 ---- Process: 7.38%\n",
      "0.579538600028\n",
      "Iter 600 ---- Process: 7.50%\n",
      "0.585116231925\n",
      "Iter 610 ---- Process: 7.62%\n",
      "0.585032663431\n",
      "Iter 620 ---- Process: 7.75%\n",
      "0.58229651431\n",
      "Iter 630 ---- Process: 7.88%\n",
      "0.584849555721\n",
      "Iter 640 ---- Process: 8.00%\n",
      "0.580681083696\n",
      "Iter 650 ---- Process: 8.12%\n",
      "0.588975736593\n",
      "Iter 660 ---- Process: 8.25%\n",
      "0.587592266041\n",
      "Iter 670 ---- Process: 8.38%\n",
      "0.588019314577\n",
      "Iter 680 ---- Process: 8.50%\n",
      "0.591462212037\n",
      "Iter 690 ---- Process: 8.62%\n",
      "0.588570522562\n",
      "Iter 700 ---- Process: 8.75%\n",
      "0.590898264451\n",
      "Iter 710 ---- Process: 8.88%\n",
      "0.590836682108\n",
      "Iter 720 ---- Process: 9.00%\n",
      "0.591560816579\n",
      "Iter 730 ---- Process: 9.12%\n",
      "0.593577688832\n",
      "Iter 740 ---- Process: 9.25%\n",
      "0.594958662693\n",
      "Iter 750 ---- Process: 9.38%\n",
      "0.594511141833\n",
      "Iter 760 ---- Process: 9.50%\n",
      "0.596199786037\n",
      "Iter 770 ---- Process: 9.62%\n",
      "0.592211495691\n",
      "Iter 780 ---- Process: 9.75%\n",
      "0.59610261355\n",
      "Iter 790 ---- Process: 9.88%\n",
      "0.595645362653\n",
      "Iter 800 ---- Process: 10.00%\n",
      "0.596030969866\n",
      "Iter 810 ---- Process: 10.12%\n",
      "0.596849291093\n",
      "Iter 820 ---- Process: 10.25%\n",
      "0.599176778438\n",
      "Iter 830 ---- Process: 10.38%\n",
      "0.598248281484\n",
      "Iter 840 ---- Process: 10.50%\n",
      "0.598690744391\n",
      "Iter 850 ---- Process: 10.62%\n",
      "0.600311622224\n",
      "Iter 860 ---- Process: 10.75%\n",
      "0.601175322084\n",
      "Iter 870 ---- Process: 10.88%\n",
      "0.600388617057\n",
      "Iter 880 ---- Process: 11.00%\n",
      "0.600660638088\n",
      "Iter 890 ---- Process: 11.12%\n",
      "0.597778014486\n",
      "Iter 900 ---- Process: 11.25%\n",
      "0.603163823742\n",
      "Iter 910 ---- Process: 11.38%\n",
      "0.603748519307\n",
      "Iter 920 ---- Process: 11.50%\n",
      "0.602620858797\n",
      "Iter 930 ---- Process: 11.62%\n",
      "0.601982711448\n",
      "Iter 940 ---- Process: 11.75%\n",
      "0.60427273161\n",
      "Iter 950 ---- Process: 11.88%\n",
      "0.603988518996\n",
      "Iter 960 ---- Process: 12.00%\n",
      "0.604097434776\n",
      "Iter 970 ---- Process: 12.12%\n",
      "0.604518393373\n",
      "Iter 980 ---- Process: 12.25%\n",
      "0.603496895697\n",
      "Iter 990 ---- Process: 12.38%\n",
      "0.605439559303\n",
      "Iter 1000 ---- Process: 12.50%\n",
      "0.604222986024\n",
      "Iter 1010 ---- Process: 12.62%\n",
      "0.607413811387\n",
      "Iter 1020 ---- Process: 12.75%\n",
      "0.601713825842\n",
      "Iter 1030 ---- Process: 12.88%\n",
      "0.607209163056\n",
      "Iter 1040 ---- Process: 13.00%\n",
      "0.606644929502\n",
      "Iter 1050 ---- Process: 13.12%\n",
      "0.606937986883\n",
      "Iter 1060 ---- Process: 13.25%\n",
      "0.60924950421\n",
      "Iter 1070 ---- Process: 13.38%\n",
      "0.609736840358\n",
      "Iter 1080 ---- Process: 13.50%\n",
      "0.59547980535\n",
      "Iter 1090 ---- Process: 13.62%\n",
      "0.606562253627\n",
      "Iter 1100 ---- Process: 13.75%\n",
      "0.605301548768\n",
      "Iter 1110 ---- Process: 13.88%\n",
      "0.605475403789\n",
      "Iter 1120 ---- Process: 14.00%\n",
      "0.608878451339\n",
      "Iter 1130 ---- Process: 14.12%\n",
      "0.609835703783\n",
      "Iter 1140 ---- Process: 14.25%\n",
      "0.609417608301\n",
      "Iter 1150 ---- Process: 14.38%\n",
      "0.610719853284\n",
      "Iter 1160 ---- Process: 14.50%\n",
      "0.608263717607\n",
      "Iter 1170 ---- Process: 14.62%\n",
      "0.607889780449\n",
      "Iter 1180 ---- Process: 14.75%\n",
      "0.609970192581\n",
      "Iter 1190 ---- Process: 14.88%\n",
      "0.609831927399\n",
      "Iter 1200 ---- Process: 15.00%\n",
      "0.610233321981\n",
      "Iter 1210 ---- Process: 15.12%\n",
      "0.610185627999\n",
      "Iter 1220 ---- Process: 15.25%\n",
      "0.612121687786\n",
      "Iter 1230 ---- Process: 15.38%\n",
      "0.611003307154\n",
      "Iter 1240 ---- Process: 15.50%\n",
      "0.611304711853\n",
      "Iter 1250 ---- Process: 15.62%\n",
      "0.608935383588\n",
      "Iter 1260 ---- Process: 15.75%\n",
      "0.612367257142\n",
      "Iter 1270 ---- Process: 15.88%\n",
      "0.611130705302\n",
      "Iter 1280 ---- Process: 16.00%\n",
      "0.611791662918\n",
      "Iter 1290 ---- Process: 16.12%\n",
      "0.612675233698\n",
      "Iter 1300 ---- Process: 16.25%\n",
      "0.614680223937\n",
      "Iter 1310 ---- Process: 16.38%\n",
      "0.611797742923\n",
      "Iter 1320 ---- Process: 16.50%\n",
      "0.614377436328\n",
      "Iter 1330 ---- Process: 16.62%\n",
      "0.611275555944\n",
      "Iter 1340 ---- Process: 16.75%\n",
      "0.610315114748\n",
      "Iter 1350 ---- Process: 16.88%\n",
      "0.612861147665\n",
      "Iter 1360 ---- Process: 17.00%\n",
      "0.6132024772\n",
      "Iter 1370 ---- Process: 17.12%\n",
      "0.611977763732\n",
      "Iter 1380 ---- Process: 17.25%\n",
      "0.610954221417\n",
      "Iter 1390 ---- Process: 17.38%\n",
      "0.612398480322\n",
      "Iter 1400 ---- Process: 17.50%\n",
      "0.61524010157\n",
      "Iter 1410 ---- Process: 17.62%\n",
      "0.615101336829\n",
      "Iter 1420 ---- Process: 17.75%\n",
      "0.611952967108\n",
      "Iter 1430 ---- Process: 17.88%\n",
      "0.614160199116\n",
      "Iter 1440 ---- Process: 18.00%\n",
      "0.614069535453\n",
      "Iter 1450 ---- Process: 18.12%\n",
      "0.613084663875\n",
      "Iter 1460 ---- Process: 18.25%\n",
      "0.615433866033\n",
      "Iter 1470 ---- Process: 18.38%\n",
      "0.615062736044\n",
      "Iter 1480 ---- Process: 18.50%\n",
      "0.614447890869\n",
      "Iter 1490 ---- Process: 18.62%\n",
      "0.615730610591\n",
      "Iter 1500 ---- Process: 18.75%\n",
      "0.61413817621\n",
      "Iter 1510 ---- Process: 18.88%\n",
      "0.615595781671\n",
      "Iter 1520 ---- Process: 19.00%\n",
      "0.615849359068\n",
      "Iter 1530 ---- Process: 19.12%\n",
      "0.615322213846\n",
      "Iter 1540 ---- Process: 19.25%\n",
      "0.614502052816\n",
      "Iter 1550 ---- Process: 19.38%\n",
      "0.610922763853\n",
      "Iter 1560 ---- Process: 19.50%\n",
      "0.616193061389\n",
      "Iter 1570 ---- Process: 19.62%\n",
      "0.617292983141\n",
      "Iter 1580 ---- Process: 19.75%\n",
      "0.617268958587\n",
      "Iter 1590 ---- Process: 19.88%\n",
      "0.616089227966\n",
      "Iter 1600 ---- Process: 20.00%\n",
      "0.611306342957\n",
      "Iter 1610 ---- Process: 20.12%\n",
      "0.616195645543\n",
      "Iter 1620 ---- Process: 20.25%\n",
      "0.616885374187\n",
      "Iter 1630 ---- Process: 20.38%\n",
      "0.616964509281\n",
      "Iter 1640 ---- Process: 20.50%\n",
      "0.615767628965\n",
      "Iter 1650 ---- Process: 20.62%\n",
      "0.613562063488\n",
      "Iter 1660 ---- Process: 20.75%\n",
      "0.617269180336\n",
      "Iter 1670 ---- Process: 20.88%\n",
      "0.616674267879\n",
      "Iter 1680 ---- Process: 21.00%\n",
      "0.61259187848\n",
      "Iter 1690 ---- Process: 21.12%\n",
      "0.616107131235\n",
      "Iter 1700 ---- Process: 21.25%\n",
      "0.618587219764\n",
      "Iter 1710 ---- Process: 21.38%\n",
      "0.617623432604\n",
      "Iter 1720 ---- Process: 21.50%\n",
      "0.618105132964\n",
      "Iter 1730 ---- Process: 21.62%\n",
      "0.616821980214\n",
      "Iter 1740 ---- Process: 21.75%\n",
      "0.618837554413\n",
      "Iter 1750 ---- Process: 21.88%\n",
      "0.617594985022\n",
      "Iter 1760 ---- Process: 22.00%\n",
      "0.616660011962\n",
      "Iter 1770 ---- Process: 22.12%\n",
      "0.618521135576\n",
      "Iter 1780 ---- Process: 22.25%\n",
      "0.618206915771\n",
      "Iter 1790 ---- Process: 22.38%\n",
      "0.619182474936\n",
      "Iter 1800 ---- Process: 22.50%\n",
      "0.619172920841\n",
      "Iter 1810 ---- Process: 22.62%\n",
      "0.613702242797\n",
      "Iter 1820 ---- Process: 22.75%\n",
      "0.618151858717\n",
      "Iter 1830 ---- Process: 22.88%\n",
      "0.618540367264\n",
      "Iter 1840 ---- Process: 23.00%\n",
      "0.615464638497\n",
      "Iter 1850 ---- Process: 23.12%\n",
      "0.619332190121\n",
      "Iter 1860 ---- Process: 23.25%\n",
      "0.619587583673\n",
      "Iter 1870 ---- Process: 23.38%\n",
      "0.617723173555\n",
      "Iter 1880 ---- Process: 23.50%\n",
      "0.620761277449\n",
      "Iter 1890 ---- Process: 23.62%\n",
      "0.621595597119\n",
      "Iter 1900 ---- Process: 23.75%\n",
      "0.619709715154\n",
      "Iter 1910 ---- Process: 23.88%\n",
      "0.620236055035\n",
      "Iter 1920 ---- Process: 24.00%\n",
      "0.617609564526\n",
      "Iter 1930 ---- Process: 24.12%\n",
      "0.61827397391\n",
      "Iter 1940 ---- Process: 24.25%\n",
      "0.620131210832\n",
      "Iter 1950 ---- Process: 24.38%\n",
      "0.61957936739\n",
      "Iter 1960 ---- Process: 24.50%\n",
      "0.618970168589\n",
      "Iter 1970 ---- Process: 24.62%\n",
      "0.617017250886\n",
      "Iter 1980 ---- Process: 24.75%\n",
      "0.620880679375\n",
      "Iter 1990 ---- Process: 24.88%\n",
      "0.618854371852\n",
      "Iter 2000 ---- Process: 25.00%\n",
      "0.620661052363\n",
      "Iter 2010 ---- Process: 25.12%\n",
      "0.620546751709\n",
      "Iter 2020 ---- Process: 25.25%\n",
      "0.621954205889\n",
      "Iter 2030 ---- Process: 25.38%\n",
      "0.621267995925\n",
      "Iter 2040 ---- Process: 25.50%\n",
      "0.618685239429\n",
      "Iter 2050 ---- Process: 25.62%\n",
      "0.619621577314\n",
      "Iter 2060 ---- Process: 25.75%\n",
      "0.621303766295\n",
      "Iter 2070 ---- Process: 25.88%\n",
      "0.618239695072\n",
      "Iter 2080 ---- Process: 26.00%\n",
      "0.620466950293\n",
      "Iter 2090 ---- Process: 26.12%\n",
      "0.61994575809\n",
      "Iter 2100 ---- Process: 26.25%\n",
      "0.620548311945\n",
      "Iter 2110 ---- Process: 26.38%\n",
      "0.621919668913\n",
      "Iter 2120 ---- Process: 26.50%\n",
      "0.620278009248\n",
      "Iter 2130 ---- Process: 26.62%\n",
      "0.620949823611\n",
      "Iter 2140 ---- Process: 26.75%\n",
      "0.619887592842\n",
      "Iter 2150 ---- Process: 26.88%\n",
      "0.621941525517\n",
      "Iter 2160 ---- Process: 27.00%\n",
      "0.61978257929\n",
      "Iter 2170 ---- Process: 27.12%\n",
      "0.62140933003\n",
      "Iter 2180 ---- Process: 27.25%\n",
      "0.622135221122\n",
      "Iter 2190 ---- Process: 27.38%\n",
      "0.620777408701\n",
      "Iter 2200 ---- Process: 27.50%\n",
      "0.620578203275\n",
      "Iter 2210 ---- Process: 27.62%\n",
      "0.620339897039\n",
      "Iter 2220 ---- Process: 27.75%\n",
      "0.622361998412\n",
      "Iter 2230 ---- Process: 27.88%\n",
      "0.620199569029\n",
      "Iter 2240 ---- Process: 28.00%\n",
      "0.618000393646\n",
      "Iter 2250 ---- Process: 28.12%\n",
      "0.623126678264\n",
      "Iter 2260 ---- Process: 28.25%\n",
      "0.61999050709\n",
      "Iter 2270 ---- Process: 28.38%\n",
      "0.61997175036\n",
      "Iter 2280 ---- Process: 28.50%\n",
      "0.622547504691\n",
      "Iter 2290 ---- Process: 28.62%\n",
      "0.621646597953\n",
      "Iter 2300 ---- Process: 28.75%\n",
      "0.621764883905\n",
      "Iter 2310 ---- Process: 28.88%\n",
      "0.622754260921\n",
      "Iter 2320 ---- Process: 29.00%\n",
      "0.622521154984\n",
      "Iter 2330 ---- Process: 29.12%\n",
      "0.620258108582\n",
      "Iter 2340 ---- Process: 29.25%\n",
      "0.621857161354\n",
      "Iter 2350 ---- Process: 29.38%\n",
      "0.622121121542\n",
      "Iter 2360 ---- Process: 29.50%\n",
      "0.623290480957\n",
      "Iter 2370 ---- Process: 29.62%\n",
      "0.621329792307\n",
      "Iter 2380 ---- Process: 29.75%\n",
      "0.622892745967\n",
      "Iter 2390 ---- Process: 29.88%\n",
      "0.622844145225\n",
      "Iter 2400 ---- Process: 30.00%\n",
      "0.620615414702\n",
      "Iter 2410 ---- Process: 30.12%\n",
      "0.619551037314\n",
      "Iter 2420 ---- Process: 30.25%\n",
      "0.618512170945\n",
      "Iter 2430 ---- Process: 30.38%\n",
      "0.621683855771\n",
      "Iter 2440 ---- Process: 30.50%\n",
      "0.621188707719\n",
      "Iter 2450 ---- Process: 30.62%\n",
      "0.623965393061\n",
      "Iter 2460 ---- Process: 30.75%\n",
      "0.622940081942\n",
      "Iter 2470 ---- Process: 30.88%\n",
      "0.622193607053\n",
      "Iter 2480 ---- Process: 31.00%\n",
      "0.620334618014\n",
      "Iter 2490 ---- Process: 31.12%\n",
      "0.623950075533\n",
      "Iter 2500 ---- Process: 31.25%\n",
      "0.622216586823\n",
      "Iter 2510 ---- Process: 31.38%\n",
      "0.621757338709\n",
      "Iter 2520 ---- Process: 31.50%\n",
      "0.622550179234\n",
      "Iter 2530 ---- Process: 31.62%\n",
      "0.620865826046\n",
      "Iter 2540 ---- Process: 31.75%\n",
      "0.61986022381\n",
      "Iter 2550 ---- Process: 31.88%\n",
      "0.622177856575\n",
      "Iter 2560 ---- Process: 32.00%\n",
      "0.622815956473\n",
      "Iter 2570 ---- Process: 32.12%\n",
      "0.619958331605\n",
      "Iter 2580 ---- Process: 32.25%\n",
      "0.619868861327\n",
      "Iter 2590 ---- Process: 32.38%\n",
      "0.621528214064\n",
      "Iter 2600 ---- Process: 32.50%\n",
      "0.621145405016\n",
      "Iter 2610 ---- Process: 32.62%\n",
      "0.620845387688\n",
      "Iter 2620 ---- Process: 32.75%\n",
      "0.623111810978\n",
      "Iter 2630 ---- Process: 32.88%\n",
      "0.621426195584\n",
      "Iter 2640 ---- Process: 33.00%\n",
      "0.622961655516\n",
      "Iter 2650 ---- Process: 33.12%\n",
      "0.621705374749\n",
      "Iter 2660 ---- Process: 33.25%\n",
      "0.621781137193\n",
      "Iter 2670 ---- Process: 33.38%\n",
      "0.623312542373\n",
      "Iter 2680 ---- Process: 33.50%\n",
      "0.623665932607\n",
      "Iter 2690 ---- Process: 33.62%\n",
      "0.622218931221\n",
      "Iter 2700 ---- Process: 33.75%\n",
      "0.618979865883\n",
      "Iter 2710 ---- Process: 33.88%\n",
      "0.624089999037\n",
      "Iter 2720 ---- Process: 34.00%\n",
      "0.622681872295\n",
      "Iter 2730 ---- Process: 34.12%\n",
      "0.624788530487\n",
      "Iter 2740 ---- Process: 34.25%\n",
      "0.623992810889\n",
      "Iter 2750 ---- Process: 34.38%\n",
      "0.618886327625\n",
      "Iter 2760 ---- Process: 34.50%\n",
      "0.624330199723\n",
      "Iter 2770 ---- Process: 34.62%\n",
      "0.622373104099\n",
      "Iter 2780 ---- Process: 34.75%\n",
      "0.624530017888\n",
      "Iter 2790 ---- Process: 34.88%\n",
      "0.623119654886\n",
      "Iter 2800 ---- Process: 35.00%\n",
      "0.622629852452\n",
      "Iter 2810 ---- Process: 35.12%\n",
      "0.62273100636\n",
      "Iter 2820 ---- Process: 35.25%\n",
      "0.623994567758\n",
      "Iter 2830 ---- Process: 35.38%\n",
      "0.623406711826\n",
      "Iter 2840 ---- Process: 35.50%\n",
      "0.623450019411\n",
      "Iter 2850 ---- Process: 35.62%\n",
      "0.621897223103\n",
      "Iter 2860 ---- Process: 35.75%\n",
      "0.623994409726\n",
      "Iter 2870 ---- Process: 35.88%\n",
      "0.623066742447\n",
      "Iter 2880 ---- Process: 36.00%\n",
      "0.624633128644\n",
      "Iter 2890 ---- Process: 36.12%\n",
      "0.621813409465\n",
      "Iter 2900 ---- Process: 36.25%\n",
      "0.618966389921\n",
      "Iter 2910 ---- Process: 36.38%\n",
      "0.624214302281\n",
      "Iter 2920 ---- Process: 36.50%\n",
      "0.621280426555\n",
      "Iter 2930 ---- Process: 36.62%\n",
      "0.622326137923\n",
      "Iter 2940 ---- Process: 36.75%\n",
      "0.620685901788\n",
      "Iter 2950 ---- Process: 36.88%\n",
      "0.618863811497\n",
      "Iter 2960 ---- Process: 37.00%\n",
      "0.621238370047\n",
      "Iter 2970 ---- Process: 37.12%\n",
      "0.623498135756\n",
      "Iter 2980 ---- Process: 37.25%\n",
      "0.623687170306\n",
      "Iter 2990 ---- Process: 37.38%\n",
      "0.623941106092\n",
      "Iter 3000 ---- Process: 37.50%\n",
      "0.622555448432\n",
      "Iter 3010 ---- Process: 37.62%\n",
      "0.624657412565\n",
      "Iter 3020 ---- Process: 37.75%\n",
      "0.622008216592\n",
      "Iter 3030 ---- Process: 37.88%\n",
      "0.625259685512\n",
      "Iter 3040 ---- Process: 38.00%\n",
      "0.618826911365\n",
      "Iter 3050 ---- Process: 38.12%\n",
      "0.623767466625\n",
      "Iter 3060 ---- Process: 38.25%\n",
      "0.625339333522\n",
      "Iter 3070 ---- Process: 38.38%\n",
      "0.624465707126\n",
      "Iter 3080 ---- Process: 38.50%\n",
      "0.621825338974\n",
      "Iter 3090 ---- Process: 38.62%\n",
      "0.623524365436\n",
      "Iter 3100 ---- Process: 38.75%\n",
      "0.620723904563\n",
      "Iter 3110 ---- Process: 38.88%\n",
      "0.62493368087\n",
      "Iter 3120 ---- Process: 39.00%\n",
      "0.624095583179\n",
      "Iter 3130 ---- Process: 39.12%\n",
      "0.624412756367\n",
      "Iter 3140 ---- Process: 39.25%\n",
      "0.624521736496\n",
      "Iter 3150 ---- Process: 39.38%\n",
      "0.624080937964\n",
      "Iter 3160 ---- Process: 39.50%\n",
      "0.622737612153\n",
      "Iter 3170 ---- Process: 39.62%\n",
      "0.624271661288\n",
      "Iter 3180 ---- Process: 39.75%\n",
      "0.62099777181\n",
      "Iter 3190 ---- Process: 39.88%\n",
      "0.623697976914\n",
      "Iter 3200 ---- Process: 40.00%\n",
      "0.622563208201\n",
      "Iter 3210 ---- Process: 40.12%\n",
      "0.623789228416\n",
      "Iter 3220 ---- Process: 40.25%\n",
      "0.625416316541\n",
      "Iter 3230 ---- Process: 40.38%\n",
      "0.621983600573\n",
      "Iter 3240 ---- Process: 40.50%\n",
      "0.623889660661\n",
      "Iter 3250 ---- Process: 40.62%\n",
      "0.625302326513\n",
      "Iter 3260 ---- Process: 40.75%\n",
      "0.623519061094\n",
      "Iter 3270 ---- Process: 40.88%\n",
      "0.621368751187\n",
      "Iter 3280 ---- Process: 41.00%\n",
      "0.623186996129\n",
      "Iter 3290 ---- Process: 41.12%\n",
      "0.623243858391\n",
      "Iter 3300 ---- Process: 41.25%\n",
      "0.62195862685\n",
      "Iter 3310 ---- Process: 41.38%\n",
      "0.625592704195\n",
      "Iter 3320 ---- Process: 41.50%\n",
      "0.62385508108\n",
      "Iter 3330 ---- Process: 41.62%\n",
      "0.620905113057\n",
      "Iter 3340 ---- Process: 41.75%\n",
      "0.620381191176\n",
      "Iter 3350 ---- Process: 41.88%\n",
      "0.621681861354\n",
      "Iter 3360 ---- Process: 42.00%\n",
      "0.621550936255\n",
      "Iter 3370 ---- Process: 42.12%\n",
      "0.623203453425\n",
      "Iter 3380 ---- Process: 42.25%\n",
      "0.625168638956\n",
      "Iter 3390 ---- Process: 42.38%\n",
      "0.623071391511\n",
      "Iter 3400 ---- Process: 42.50%\n",
      "0.622463178943\n",
      "Iter 3410 ---- Process: 42.62%\n",
      "0.622681124545\n",
      "Iter 3420 ---- Process: 42.75%\n",
      "0.622847238148\n",
      "Iter 3430 ---- Process: 42.88%\n",
      "0.624007111016\n",
      "Iter 3440 ---- Process: 43.00%\n",
      "0.622471067203\n",
      "Iter 3450 ---- Process: 43.12%\n",
      "0.622332340107\n",
      "Iter 3460 ---- Process: 43.25%\n",
      "0.621022503383\n",
      "Iter 3470 ---- Process: 43.38%\n",
      "0.62202399537\n",
      "Iter 3480 ---- Process: 43.50%\n",
      "0.624836093663\n",
      "Iter 3490 ---- Process: 43.62%\n",
      "0.62120134734\n",
      "Iter 3500 ---- Process: 43.75%\n",
      "0.622423532555\n",
      "Iter 3510 ---- Process: 43.88%\n",
      "0.621385602953\n",
      "Iter 3520 ---- Process: 44.00%\n",
      "0.619658583989\n",
      "Iter 3530 ---- Process: 44.12%\n",
      "0.624268038855\n",
      "Iter 3540 ---- Process: 44.25%\n",
      "0.622474026926\n",
      "Iter 3550 ---- Process: 44.38%\n",
      "0.622885588655\n",
      "Iter 3560 ---- Process: 44.50%\n",
      "0.620167605966\n",
      "Iter 3570 ---- Process: 44.62%\n",
      "0.624837828294\n",
      "Iter 3580 ---- Process: 44.75%\n",
      "0.621838107306\n",
      "Iter 3590 ---- Process: 44.88%\n",
      "0.624400630098\n",
      "Iter 3600 ---- Process: 45.00%\n",
      "0.622520245638\n",
      "Iter 3610 ---- Process: 45.12%\n",
      "0.620397138367\n",
      "Iter 3620 ---- Process: 45.25%\n",
      "0.623539791363\n",
      "Iter 3630 ---- Process: 45.38%\n",
      "0.619357900369\n",
      "Iter 3640 ---- Process: 45.50%\n",
      "0.622793866945\n",
      "Iter 3650 ---- Process: 45.62%\n",
      "0.622503298939\n",
      "Iter 3660 ---- Process: 45.75%\n",
      "0.620722167152\n",
      "Iter 3670 ---- Process: 45.88%\n",
      "0.625408877573\n",
      "Iter 3680 ---- Process: 46.00%\n",
      "0.625192574224\n",
      "Iter 3690 ---- Process: 46.12%\n",
      "0.618952900438\n",
      "Iter 3700 ---- Process: 46.25%\n",
      "0.62148421661\n",
      "Iter 3710 ---- Process: 46.38%\n",
      "0.621945272703\n",
      "Iter 3720 ---- Process: 46.50%\n",
      "0.623296582658\n",
      "Iter 3730 ---- Process: 46.62%\n",
      "0.618912066532\n",
      "Iter 3740 ---- Process: 46.75%\n",
      "0.621459418873\n",
      "Iter 3750 ---- Process: 46.88%\n",
      "0.623283074773\n",
      "Iter 3760 ---- Process: 47.00%\n",
      "0.62248174797\n",
      "Iter 3770 ---- Process: 47.12%\n",
      "0.62234407494\n",
      "Iter 3780 ---- Process: 47.25%\n",
      "0.622958987971\n",
      "Iter 3790 ---- Process: 47.38%\n",
      "0.624092394561\n",
      "Iter 3800 ---- Process: 47.50%\n",
      "0.61944800277\n",
      "Iter 3810 ---- Process: 47.62%\n",
      "0.618314075405\n",
      "Iter 3820 ---- Process: 47.75%\n",
      "0.623265565489\n",
      "Iter 3830 ---- Process: 47.88%\n",
      "0.621037397286\n",
      "Iter 3840 ---- Process: 48.00%\n",
      "0.621577488036\n",
      "Iter 3850 ---- Process: 48.12%\n",
      "0.621791911798\n",
      "Iter 3860 ---- Process: 48.25%\n",
      "0.620918352777\n",
      "Iter 3870 ---- Process: 48.38%\n",
      "0.620844920698\n",
      "Iter 3880 ---- Process: 48.50%\n",
      "0.623119314062\n",
      "Iter 3890 ---- Process: 48.62%\n",
      "0.620695811128\n",
      "Iter 3900 ---- Process: 48.75%\n",
      "0.620048579727\n",
      "Iter 3910 ---- Process: 48.88%\n",
      "0.623195335689\n",
      "Iter 3920 ---- Process: 49.00%\n",
      "0.621080815674\n",
      "Iter 3930 ---- Process: 49.12%\n",
      "0.622021586159\n",
      "Iter 3940 ---- Process: 49.25%\n",
      "0.619623981034\n",
      "Iter 3950 ---- Process: 49.38%\n",
      "0.62071162047\n",
      "Iter 3960 ---- Process: 49.50%\n",
      "0.623444023651\n",
      "Iter 3970 ---- Process: 49.62%\n",
      "0.621926418248\n",
      "Iter 3980 ---- Process: 49.75%\n",
      "0.623034581982\n",
      "Iter 3990 ---- Process: 49.88%\n",
      "0.623078950738\n",
      "Iter 4000 ---- Process: 50.00%\n",
      "0.621784391372\n",
      "Iter 4010 ---- Process: 50.12%\n",
      "0.618276946272\n",
      "Iter 4020 ---- Process: 50.25%\n",
      "0.622286961289\n",
      "Iter 4030 ---- Process: 50.38%\n",
      "0.617538238532\n",
      "Iter 4040 ---- Process: 50.50%\n",
      "0.617488325706\n",
      "Iter 4050 ---- Process: 50.62%\n",
      "0.621185671925\n",
      "Iter 4060 ---- Process: 50.75%\n",
      "0.622543037225\n",
      "Iter 4070 ---- Process: 50.88%\n",
      "0.619509252174\n",
      "Iter 4080 ---- Process: 51.00%\n",
      "0.622012302936\n",
      "Iter 4090 ---- Process: 51.12%\n",
      "0.622515556103\n",
      "Iter 4100 ---- Process: 51.25%\n",
      "0.618844135913\n",
      "Iter 4110 ---- Process: 51.38%\n",
      "0.61859764677\n",
      "Iter 4120 ---- Process: 51.50%\n",
      "0.621120287259\n",
      "Iter 4130 ---- Process: 51.62%\n",
      "0.621780753312\n",
      "Iter 4140 ---- Process: 51.75%\n",
      "0.617461257311\n",
      "Iter 4150 ---- Process: 51.88%\n",
      "0.623205968382\n",
      "Iter 4160 ---- Process: 52.00%\n",
      "0.624511809469\n",
      "Iter 4170 ---- Process: 52.12%\n",
      "0.620744655381\n",
      "Iter 4180 ---- Process: 52.25%\n",
      "0.620297049541\n",
      "Iter 4190 ---- Process: 52.38%\n",
      "0.621482551698\n",
      "Iter 4200 ---- Process: 52.50%\n",
      "0.618737917205\n",
      "Iter 4210 ---- Process: 52.62%\n",
      "0.619551937066\n",
      "Iter 4220 ---- Process: 52.75%\n",
      "0.623799245732\n",
      "Iter 4230 ---- Process: 52.88%\n",
      "0.621190252561\n",
      "Iter 4240 ---- Process: 53.00%\n",
      "0.622314792209\n",
      "Iter 4250 ---- Process: 53.12%\n",
      "0.617536355873\n",
      "Iter 4260 ---- Process: 53.25%\n",
      "0.619851409394\n",
      "Iter 4270 ---- Process: 53.38%\n",
      "0.61840740777\n",
      "Iter 4280 ---- Process: 53.50%\n",
      "0.622479460907\n",
      "Iter 4290 ---- Process: 53.62%\n",
      "0.620919688814\n",
      "Iter 4300 ---- Process: 53.75%\n",
      "0.621981538658\n",
      "Iter 4310 ---- Process: 53.88%\n",
      "0.619155921402\n",
      "Iter 4320 ---- Process: 54.00%\n",
      "0.617942436856\n",
      "Iter 4330 ---- Process: 54.12%\n",
      "0.618621977965\n",
      "Iter 4340 ---- Process: 54.25%\n",
      "0.621316791777\n",
      "Iter 4350 ---- Process: 54.38%\n",
      "0.621597847057\n",
      "Iter 4360 ---- Process: 54.50%\n",
      "0.623688873686\n",
      "Iter 4370 ---- Process: 54.62%\n",
      "0.621436253203\n",
      "Iter 4380 ---- Process: 54.75%\n",
      "0.622562006946\n",
      "Iter 4390 ---- Process: 54.88%\n",
      "0.622197406222\n",
      "Iter 4400 ---- Process: 55.00%\n",
      "0.620053313059\n",
      "Iter 4410 ---- Process: 55.12%\n",
      "0.621549007297\n",
      "Iter 4420 ---- Process: 55.25%\n",
      "0.619589171766\n",
      "Iter 4430 ---- Process: 55.38%\n",
      "0.623218249157\n",
      "Iter 4440 ---- Process: 55.50%\n",
      "0.621180302806\n",
      "Iter 4450 ---- Process: 55.62%\n",
      "0.622753790324\n",
      "Iter 4460 ---- Process: 55.75%\n",
      "0.620697877583\n",
      "Iter 4470 ---- Process: 55.88%\n",
      "0.620295254435\n",
      "Iter 4480 ---- Process: 56.00%\n",
      "0.622704025421\n",
      "Iter 4490 ---- Process: 56.12%\n",
      "0.619683988023\n",
      "Iter 4500 ---- Process: 56.25%\n",
      "0.62057403341\n",
      "Iter 4510 ---- Process: 56.38%\n",
      "0.624060346623\n",
      "Iter 4520 ---- Process: 56.50%\n",
      "0.618522363001\n",
      "Iter 4530 ---- Process: 56.62%\n",
      "0.62166448407\n",
      "Iter 4540 ---- Process: 56.75%\n",
      "0.621473444603\n",
      "Iter 4550 ---- Process: 56.88%\n",
      "0.621828600985\n",
      "Iter 4560 ---- Process: 57.00%\n",
      "0.62014246101\n",
      "Iter 4570 ---- Process: 57.12%\n",
      "0.621455946117\n",
      "Iter 4580 ---- Process: 57.25%\n",
      "0.621246900056\n",
      "Iter 4590 ---- Process: 57.38%\n",
      "0.623516976945\n",
      "Iter 4600 ---- Process: 57.50%\n",
      "0.620896090714\n",
      "Iter 4610 ---- Process: 57.62%\n",
      "0.619161776831\n",
      "Iter 4620 ---- Process: 57.75%\n",
      "0.623357209699\n",
      "Iter 4630 ---- Process: 57.88%\n",
      "0.61937346241\n",
      "Iter 4640 ---- Process: 58.00%\n",
      "0.619341613014\n",
      "Iter 4650 ---- Process: 58.12%\n",
      "0.620215386898\n",
      "Iter 4660 ---- Process: 58.25%\n",
      "0.621128034603\n",
      "Iter 4670 ---- Process: 58.38%\n",
      "0.620701510643\n",
      "Iter 4680 ---- Process: 58.50%\n",
      "0.618204095526\n",
      "Iter 4690 ---- Process: 58.62%\n",
      "0.620166676294\n",
      "Iter 4700 ---- Process: 58.75%\n",
      "0.622378240052\n",
      "Iter 4710 ---- Process: 58.88%\n",
      "0.6232678913\n",
      "Iter 4720 ---- Process: 59.00%\n",
      "0.621437869591\n",
      "Iter 4730 ---- Process: 59.12%\n",
      "0.617693898262\n",
      "Iter 4740 ---- Process: 59.25%\n",
      "0.619022111832\n",
      "Iter 4750 ---- Process: 59.38%\n",
      "0.61867277055\n",
      "Iter 4760 ---- Process: 59.50%\n",
      "0.622279163639\n",
      "Iter 4770 ---- Process: 59.62%\n",
      "0.619676227512\n",
      "Iter 4780 ---- Process: 59.75%\n",
      "0.62032790924\n",
      "Iter 4790 ---- Process: 59.88%\n",
      "0.621694674028\n",
      "Iter 4800 ---- Process: 60.00%\n",
      "0.621338986482\n",
      "Iter 4810 ---- Process: 60.12%\n",
      "0.617457452754\n",
      "Iter 4820 ---- Process: 60.25%\n",
      "0.617245897731\n",
      "Iter 4830 ---- Process: 60.38%\n",
      "0.617791747431\n",
      "Iter 4840 ---- Process: 60.50%\n",
      "0.617770599071\n",
      "Iter 4850 ---- Process: 60.62%\n",
      "0.620752116918\n",
      "Iter 4860 ---- Process: 60.75%\n",
      "0.618355293906\n",
      "Iter 4870 ---- Process: 60.88%\n",
      "0.620321184344\n",
      "Iter 4880 ---- Process: 61.00%\n",
      "0.619007142538\n",
      "Iter 4890 ---- Process: 61.12%\n",
      "0.618411468451\n",
      "Iter 4900 ---- Process: 61.25%\n",
      "0.617606329071\n",
      "Iter 4910 ---- Process: 61.38%\n",
      "0.620661224308\n",
      "Iter 4920 ---- Process: 61.50%\n",
      "0.619524395464\n",
      "Iter 4930 ---- Process: 61.62%\n",
      "0.618772120678\n",
      "Iter 4940 ---- Process: 61.75%\n",
      "0.619235499071\n",
      "Iter 4950 ---- Process: 61.88%\n",
      "0.620323219979\n",
      "Iter 4960 ---- Process: 62.00%\n",
      "0.620323102655\n",
      "Iter 4970 ---- Process: 62.12%\n",
      "0.62043041902\n",
      "Iter 4980 ---- Process: 62.25%\n",
      "0.617535546315\n",
      "Iter 4990 ---- Process: 62.38%\n",
      "0.619537473661\n",
      "Iter 5000 ---- Process: 62.50%\n",
      "0.620317715602\n",
      "Iter 5010 ---- Process: 62.62%\n",
      "0.619555964903\n",
      "Iter 5020 ---- Process: 62.75%\n",
      "0.621091330259\n",
      "Iter 5030 ---- Process: 62.88%\n",
      "0.62026031108\n",
      "Iter 5040 ---- Process: 63.00%\n",
      "0.620865157963\n",
      "Iter 5050 ---- Process: 63.12%\n",
      "0.618269016472\n",
      "Iter 5060 ---- Process: 63.25%\n",
      "0.617257684698\n",
      "Iter 5070 ---- Process: 63.38%\n",
      "0.622409437965\n",
      "Iter 5080 ---- Process: 63.50%\n",
      "0.621047238565\n",
      "Iter 5090 ---- Process: 63.62%\n",
      "0.618898627045\n",
      "Iter 5100 ---- Process: 63.75%\n",
      "0.617075671048\n",
      "Iter 5110 ---- Process: 63.88%\n",
      "0.620867618567\n",
      "Iter 5120 ---- Process: 64.00%\n",
      "0.620435720867\n",
      "Iter 5130 ---- Process: 64.12%\n",
      "0.621632725232\n",
      "Iter 5140 ---- Process: 64.25%\n",
      "0.622390609456\n",
      "Iter 5150 ---- Process: 64.38%\n",
      "0.617242469872\n",
      "Iter 5160 ---- Process: 64.50%\n",
      "0.61978777887\n",
      "Iter 5170 ---- Process: 64.62%\n",
      "0.622352762233\n",
      "Iter 5180 ---- Process: 64.75%\n",
      "0.620331386416\n",
      "Iter 5190 ---- Process: 64.88%\n",
      "0.616150891641\n",
      "Iter 5200 ---- Process: 65.00%\n",
      "0.619666155812\n",
      "Iter 5210 ---- Process: 65.12%\n",
      "0.614945705151\n",
      "Iter 5220 ---- Process: 65.25%\n",
      "0.61852820823\n",
      "Iter 5230 ---- Process: 65.38%\n",
      "0.618284683034\n",
      "Iter 5240 ---- Process: 65.50%\n",
      "0.621613157961\n",
      "Iter 5250 ---- Process: 65.62%\n",
      "0.618796196529\n",
      "Iter 5260 ---- Process: 65.75%\n",
      "0.619204899325\n",
      "Iter 5270 ---- Process: 65.88%\n",
      "0.618327035616\n",
      "Iter 5280 ---- Process: 66.00%\n",
      "0.618012493569\n",
      "Iter 5290 ---- Process: 66.12%\n",
      "0.619375355989\n",
      "Iter 5300 ---- Process: 66.25%\n",
      "0.615650070639\n",
      "Iter 5310 ---- Process: 66.38%\n",
      "0.618786859954\n",
      "Iter 5320 ---- Process: 66.50%\n",
      "0.619019237084\n",
      "Iter 5330 ---- Process: 66.62%\n",
      "0.613225867865\n",
      "Iter 5340 ---- Process: 66.75%\n",
      "0.61773448748\n",
      "Iter 5350 ---- Process: 66.88%\n",
      "0.616007012781\n",
      "Iter 5360 ---- Process: 67.00%\n",
      "0.617780541127\n",
      "Iter 5370 ---- Process: 67.12%\n",
      "0.617977216242\n",
      "Iter 5380 ---- Process: 67.25%\n",
      "0.619552486225\n",
      "Iter 5390 ---- Process: 67.38%\n",
      "0.616160624485\n",
      "Iter 5400 ---- Process: 67.50%\n",
      "0.617345425567\n",
      "Iter 5410 ---- Process: 67.62%\n",
      "0.614630629959\n",
      "Iter 5420 ---- Process: 67.75%\n",
      "0.618902593658\n",
      "Iter 5430 ---- Process: 67.88%\n",
      "0.617317797337\n",
      "Iter 5440 ---- Process: 68.00%\n",
      "0.617291586597\n",
      "Iter 5450 ---- Process: 68.12%\n",
      "0.619567471888\n",
      "Iter 5460 ---- Process: 68.25%\n",
      "0.619506426611\n",
      "Iter 5470 ---- Process: 68.38%\n",
      "0.617235380662\n",
      "Iter 5480 ---- Process: 68.50%\n",
      "0.619185953473\n",
      "Iter 5490 ---- Process: 68.62%\n",
      "0.618940752242\n",
      "Iter 5500 ---- Process: 68.75%\n",
      "0.620009208424\n",
      "Iter 5510 ---- Process: 68.88%\n",
      "0.620436462073\n",
      "Iter 5520 ---- Process: 69.00%\n",
      "0.618962518536\n",
      "Iter 5530 ---- Process: 69.12%\n",
      "0.620052342204\n",
      "Iter 5540 ---- Process: 69.25%\n",
      "0.616720683087\n",
      "Iter 5550 ---- Process: 69.38%\n",
      "0.616273049451\n",
      "Iter 5560 ---- Process: 69.50%\n",
      "0.618217229078\n",
      "Iter 5570 ---- Process: 69.62%\n",
      "0.615072349306\n",
      "Iter 5580 ---- Process: 69.75%\n",
      "0.618882190987\n",
      "Iter 5590 ---- Process: 69.88%\n",
      "0.616250908868\n",
      "Iter 5600 ---- Process: 70.00%\n",
      "0.617884103951\n",
      "Iter 5610 ---- Process: 70.12%\n",
      "0.61966637283\n",
      "Iter 5620 ---- Process: 70.25%\n",
      "0.616293151205\n",
      "Iter 5630 ---- Process: 70.38%\n",
      "0.618936702\n",
      "Iter 5640 ---- Process: 70.50%\n",
      "0.619970728547\n",
      "Iter 5650 ---- Process: 70.62%\n",
      "0.61915588284\n",
      "Iter 5660 ---- Process: 70.75%\n",
      "0.620518072028\n",
      "Iter 5670 ---- Process: 70.88%\n",
      "0.617741072947\n",
      "Iter 5680 ---- Process: 71.00%\n",
      "0.617106104563\n",
      "Iter 5690 ---- Process: 71.12%\n",
      "0.617727647302\n",
      "Iter 5700 ---- Process: 71.25%\n",
      "0.616859871053\n",
      "Iter 5710 ---- Process: 71.38%\n",
      "0.617945763392\n",
      "Iter 5720 ---- Process: 71.50%\n",
      "0.613821487073\n",
      "Iter 5730 ---- Process: 71.62%\n",
      "0.617599491195\n",
      "Iter 5740 ---- Process: 71.75%\n",
      "0.619129537955\n",
      "Iter 5750 ---- Process: 71.88%\n",
      "0.616461670446\n",
      "Iter 5760 ---- Process: 72.00%\n",
      "0.620989526898\n",
      "Iter 5770 ---- Process: 72.12%\n",
      "0.617159016517\n",
      "Iter 5780 ---- Process: 72.25%\n",
      "0.618340477558\n",
      "Iter 5790 ---- Process: 72.38%\n",
      "0.612986624737\n",
      "Iter 5800 ---- Process: 72.50%\n",
      "0.616437625397\n",
      "Iter 5810 ---- Process: 72.62%\n",
      "0.614062537896\n",
      "Iter 5820 ---- Process: 72.75%\n",
      "0.615797195235\n",
      "Iter 5830 ---- Process: 72.88%\n",
      "0.616147709618\n",
      "Iter 5840 ---- Process: 73.00%\n",
      "0.612350734185\n",
      "Iter 5850 ---- Process: 73.12%\n",
      "0.616848284589\n",
      "Iter 5860 ---- Process: 73.25%\n",
      "0.616861930472\n",
      "Iter 5870 ---- Process: 73.38%\n",
      "0.614204835484\n",
      "Iter 5880 ---- Process: 73.50%\n",
      "0.617515955158\n",
      "Iter 5890 ---- Process: 73.62%\n",
      "0.615058804642\n",
      "Iter 5900 ---- Process: 73.75%\n",
      "0.618747393436\n",
      "Iter 5910 ---- Process: 73.88%\n",
      "0.617459625396\n",
      "Iter 5920 ---- Process: 74.00%\n",
      "0.617590945763\n",
      "Iter 5930 ---- Process: 74.12%\n",
      "0.615625732475\n",
      "Iter 5940 ---- Process: 74.25%\n",
      "0.618238942434\n",
      "Iter 5950 ---- Process: 74.38%\n",
      "0.614983525049\n",
      "Iter 5960 ---- Process: 74.50%\n",
      "0.618385028064\n",
      "Iter 5970 ---- Process: 74.62%\n",
      "0.614701179923\n",
      "Iter 5980 ---- Process: 74.75%\n",
      "0.617606277446\n",
      "Iter 5990 ---- Process: 74.88%\n",
      "0.615518153059\n",
      "Iter 6000 ---- Process: 75.00%\n",
      "0.617252669031\n",
      "Iter 6010 ---- Process: 75.12%\n",
      "0.614783806772\n",
      "Iter 6020 ---- Process: 75.25%\n",
      "0.616281019176\n",
      "Iter 6030 ---- Process: 75.38%\n",
      "0.611480667809\n",
      "Iter 6040 ---- Process: 75.50%\n",
      "0.616762117724\n",
      "Iter 6050 ---- Process: 75.62%\n",
      "0.617145205162\n",
      "Iter 6060 ---- Process: 75.75%\n",
      "0.618682638181\n",
      "Iter 6070 ---- Process: 75.88%\n",
      "0.613204152777\n",
      "Iter 6080 ---- Process: 76.00%\n",
      "0.615099627887\n",
      "Iter 6090 ---- Process: 76.12%\n",
      "0.613612651265\n",
      "Iter 6100 ---- Process: 76.25%\n",
      "0.615992874368\n",
      "Iter 6110 ---- Process: 76.38%\n",
      "0.618103180322\n",
      "Iter 6120 ---- Process: 76.50%\n",
      "0.614474815961\n",
      "Iter 6130 ---- Process: 76.62%\n",
      "0.616256743706\n",
      "Iter 6140 ---- Process: 76.75%\n",
      "0.615355916833\n",
      "Iter 6150 ---- Process: 76.88%\n",
      "0.617162222564\n",
      "Iter 6160 ---- Process: 77.00%\n",
      "0.61467643766\n",
      "Iter 6170 ---- Process: 77.12%\n",
      "0.617178841247\n",
      "Iter 6180 ---- Process: 77.25%\n",
      "0.615330293001\n",
      "Iter 6190 ---- Process: 77.38%\n",
      "0.615187479104\n",
      "Iter 6200 ---- Process: 77.50%\n",
      "0.61400957183\n",
      "Iter 6210 ---- Process: 77.62%\n",
      "0.616815083636\n",
      "Iter 6220 ---- Process: 77.75%\n",
      "0.614616852144\n",
      "Iter 6230 ---- Process: 77.88%\n",
      "0.614162814962\n",
      "Iter 6240 ---- Process: 78.00%\n",
      "0.613305783793\n",
      "Iter 6250 ---- Process: 78.12%\n",
      "0.617324920486\n",
      "Iter 6260 ---- Process: 78.25%\n",
      "0.617282266155\n",
      "Iter 6270 ---- Process: 78.38%\n",
      "0.61747342331\n",
      "Iter 6280 ---- Process: 78.50%\n",
      "0.616342529025\n",
      "Iter 6290 ---- Process: 78.62%\n",
      "0.615731626208\n",
      "Iter 6300 ---- Process: 78.75%\n",
      "0.616951281702\n",
      "Iter 6310 ---- Process: 78.88%\n",
      "0.616841302337\n",
      "Iter 6320 ---- Process: 79.00%\n",
      "0.615596192047\n",
      "Iter 6330 ---- Process: 79.12%\n",
      "0.614744468447\n",
      "Iter 6340 ---- Process: 79.25%\n",
      "0.615747596905\n",
      "Iter 6350 ---- Process: 79.38%\n",
      "0.61484352897\n",
      "Iter 6360 ---- Process: 79.50%\n",
      "0.618234678017\n",
      "Iter 6370 ---- Process: 79.62%\n",
      "0.613887329778\n",
      "Iter 6380 ---- Process: 79.75%\n",
      "0.613464609354\n",
      "Iter 6390 ---- Process: 79.88%\n",
      "0.615021234354\n",
      "Iter 6400 ---- Process: 80.00%\n",
      "0.615304208241\n",
      "Iter 6410 ---- Process: 80.12%\n",
      "0.611307045442\n",
      "Iter 6420 ---- Process: 80.25%\n",
      "0.6150516176\n",
      "Iter 6430 ---- Process: 80.38%\n",
      "0.614563278326\n",
      "Iter 6440 ---- Process: 80.50%\n",
      "0.614240492066\n",
      "Iter 6450 ---- Process: 80.62%\n",
      "0.616409326015\n",
      "Iter 6460 ---- Process: 80.75%\n",
      "0.617948232232\n",
      "Iter 6470 ---- Process: 80.88%\n",
      "0.616358035495\n",
      "Iter 6480 ---- Process: 81.00%\n",
      "0.616021979895\n",
      "Iter 6490 ---- Process: 81.12%\n",
      "0.61605027222\n",
      "Iter 6500 ---- Process: 81.25%\n",
      "0.616188684139\n",
      "Iter 6510 ---- Process: 81.38%\n",
      "0.614057128471\n",
      "Iter 6520 ---- Process: 81.50%\n",
      "0.617593113413\n",
      "Iter 6530 ---- Process: 81.62%\n",
      "0.618186343192\n",
      "Iter 6540 ---- Process: 81.75%\n",
      "0.612058586372\n",
      "Iter 6550 ---- Process: 81.88%\n",
      "0.616399546573\n",
      "Iter 6560 ---- Process: 82.00%\n",
      "0.614255560829\n",
      "Iter 6570 ---- Process: 82.12%\n",
      "0.613335551876\n",
      "Iter 6580 ---- Process: 82.25%\n",
      "0.618383933305\n",
      "Iter 6590 ---- Process: 82.38%\n",
      "0.615829023899\n",
      "Iter 6600 ---- Process: 82.50%\n",
      "0.615750156749\n",
      "Iter 6610 ---- Process: 82.62%\n",
      "0.616002807869\n",
      "Iter 6620 ---- Process: 82.75%\n",
      "0.616472680217\n",
      "Iter 6630 ---- Process: 82.88%\n",
      "0.617633041405\n",
      "Iter 6640 ---- Process: 83.00%\n",
      "0.613699656006\n",
      "Iter 6650 ---- Process: 83.12%\n",
      "0.618308820946\n",
      "Iter 6660 ---- Process: 83.25%\n",
      "0.616207462858\n",
      "Iter 6670 ---- Process: 83.38%\n",
      "0.615398982611\n",
      "Iter 6680 ---- Process: 83.50%\n",
      "0.613390444532\n",
      "Iter 6690 ---- Process: 83.62%\n",
      "0.615015967769\n",
      "Iter 6700 ---- Process: 83.75%\n",
      "0.613197155225\n",
      "Iter 6710 ---- Process: 83.88%\n",
      "0.616652138874\n",
      "Iter 6720 ---- Process: 84.00%\n",
      "0.614588894764\n",
      "Iter 6730 ---- Process: 84.12%\n",
      "0.615470276512\n",
      "Iter 6740 ---- Process: 84.25%\n",
      "0.611865248317\n",
      "Iter 6750 ---- Process: 84.38%\n",
      "0.611542601716\n",
      "Iter 6760 ---- Process: 84.50%\n",
      "0.611484787954\n",
      "Iter 6770 ---- Process: 84.62%\n",
      "0.612340264684\n",
      "Iter 6780 ---- Process: 84.75%\n",
      "0.614162546874\n",
      "Iter 6790 ---- Process: 84.88%\n",
      "0.613900958742\n",
      "Iter 6800 ---- Process: 85.00%\n",
      "0.615007174591\n",
      "Iter 6810 ---- Process: 85.12%\n",
      "0.612251576906\n",
      "Iter 6820 ---- Process: 85.25%\n",
      "0.615084442099\n",
      "Iter 6830 ---- Process: 85.38%\n",
      "0.614207244473\n",
      "Iter 6840 ---- Process: 85.50%\n",
      "0.614523563588\n",
      "Iter 6850 ---- Process: 85.62%\n",
      "0.611154639989\n",
      "Iter 6860 ---- Process: 85.75%\n",
      "0.613571082201\n",
      "Iter 6870 ---- Process: 85.88%\n",
      "0.61359053495\n",
      "Iter 6880 ---- Process: 86.00%\n",
      "0.612318942176\n",
      "Iter 6890 ---- Process: 86.12%\n",
      "0.608716070647\n",
      "Iter 6900 ---- Process: 86.25%\n",
      "0.61582008814\n",
      "Iter 6910 ---- Process: 86.38%\n",
      "0.613948818806\n",
      "Iter 6920 ---- Process: 86.50%\n",
      "0.615798563837\n",
      "Iter 6930 ---- Process: 86.62%\n",
      "0.61429943988\n",
      "Iter 6940 ---- Process: 86.75%\n",
      "0.612387977553\n",
      "Iter 6950 ---- Process: 86.88%\n",
      "0.615787119631\n",
      "Iter 6960 ---- Process: 87.00%\n",
      "0.614963160056\n",
      "Iter 6970 ---- Process: 87.12%\n",
      "0.615180705995\n",
      "Iter 6980 ---- Process: 87.25%\n",
      "0.616045038697\n",
      "Iter 6990 ---- Process: 87.38%\n",
      "0.614273856344\n",
      "Iter 7000 ---- Process: 87.50%\n",
      "0.613187694084\n",
      "Iter 7010 ---- Process: 87.62%\n",
      "0.614267669405\n",
      "Iter 7020 ---- Process: 87.75%\n",
      "0.61499999514\n",
      "Iter 7030 ---- Process: 87.88%\n",
      "0.61413883456\n",
      "Iter 7040 ---- Process: 88.00%\n",
      "0.612938622596\n",
      "Iter 7050 ---- Process: 88.12%\n",
      "0.61380266337\n",
      "Iter 7060 ---- Process: 88.25%\n",
      "0.611558573944\n",
      "Iter 7070 ---- Process: 88.38%\n",
      "0.613889280945\n",
      "Iter 7080 ---- Process: 88.50%\n",
      "0.615660791614\n",
      "Iter 7090 ---- Process: 88.62%\n",
      "0.609444753647\n",
      "Iter 7100 ---- Process: 88.75%\n",
      "0.61521714572\n",
      "Iter 7110 ---- Process: 88.88%\n",
      "0.613377128939\n",
      "Iter 7120 ---- Process: 89.00%\n",
      "0.613801825744\n",
      "Iter 7130 ---- Process: 89.12%\n",
      "0.614310592681\n",
      "Iter 7140 ---- Process: 89.25%\n",
      "0.613515469799\n",
      "Iter 7150 ---- Process: 89.38%\n",
      "0.612746216405\n",
      "Iter 7160 ---- Process: 89.50%\n",
      "0.615429809103\n",
      "Iter 7170 ---- Process: 89.62%\n",
      "0.612655336709\n",
      "Iter 7180 ---- Process: 89.75%\n",
      "0.616483645643\n",
      "Iter 7190 ---- Process: 89.88%\n",
      "0.611478646882\n",
      "Iter 7200 ---- Process: 90.00%\n",
      "0.612978948821\n",
      "Iter 7210 ---- Process: 90.12%\n",
      "0.613760721041\n",
      "Iter 7220 ---- Process: 90.25%\n",
      "0.613610378372\n",
      "Iter 7230 ---- Process: 90.38%\n",
      "0.613712348247\n",
      "Iter 7240 ---- Process: 90.50%\n",
      "0.613759750081\n",
      "Iter 7250 ---- Process: 90.62%\n",
      "0.613124466174\n",
      "Iter 7260 ---- Process: 90.75%\n",
      "0.61311308705\n",
      "Iter 7270 ---- Process: 90.88%\n",
      "0.61560484339\n",
      "Iter 7280 ---- Process: 91.00%\n",
      "0.611927214519\n",
      "Iter 7290 ---- Process: 91.12%\n",
      "0.608669356852\n",
      "Iter 7300 ---- Process: 91.25%\n",
      "0.611118550376\n",
      "Iter 7310 ---- Process: 91.38%\n",
      "0.612396673771\n",
      "Iter 7320 ---- Process: 91.50%\n",
      "0.614706486335\n",
      "Iter 7330 ---- Process: 91.62%\n",
      "0.609817188124\n",
      "Iter 7340 ---- Process: 91.75%\n",
      "0.609797859182\n",
      "Iter 7350 ---- Process: 91.88%\n",
      "0.60934237498\n",
      "Iter 7360 ---- Process: 92.00%\n",
      "0.612086115778\n",
      "Iter 7370 ---- Process: 92.12%\n",
      "0.612148648349\n",
      "Iter 7380 ---- Process: 92.25%\n",
      "0.610343789021\n",
      "Iter 7390 ---- Process: 92.38%\n",
      "0.611051046633\n",
      "Iter 7400 ---- Process: 92.50%\n",
      "0.61043794875\n",
      "Iter 7410 ---- Process: 92.62%\n",
      "0.610571196636\n",
      "Iter 7420 ---- Process: 92.75%\n",
      "0.61183973183\n",
      "Iter 7430 ---- Process: 92.88%\n",
      "0.61162337447\n",
      "Iter 7440 ---- Process: 93.00%\n",
      "0.61159725498\n",
      "Iter 7450 ---- Process: 93.12%\n",
      "0.604429105307\n",
      "Iter 7460 ---- Process: 93.25%\n",
      "0.610057521439\n",
      "Iter 7470 ---- Process: 93.38%\n",
      "0.609519745093\n",
      "Iter 7480 ---- Process: 93.50%\n",
      "0.608236582695\n",
      "Iter 7490 ---- Process: 93.62%\n",
      "0.6126809709\n",
      "Iter 7500 ---- Process: 93.75%\n",
      "0.610814037378\n",
      "Iter 7510 ---- Process: 93.88%\n",
      "0.610218119157\n",
      "Iter 7520 ---- Process: 94.00%\n",
      "0.608657024705\n",
      "Iter 7530 ---- Process: 94.12%\n",
      "0.61108872357\n",
      "Iter 7540 ---- Process: 94.25%\n",
      "0.612302893528\n",
      "Iter 7550 ---- Process: 94.38%\n",
      "0.612522272732\n",
      "Iter 7560 ---- Process: 94.50%\n",
      "0.604667972908\n",
      "Iter 7570 ---- Process: 94.62%\n",
      "0.610845994025\n",
      "Iter 7580 ---- Process: 94.75%\n",
      "0.611133839895\n",
      "Iter 7590 ---- Process: 94.88%\n",
      "0.610766060866\n",
      "Iter 7600 ---- Process: 95.00%\n",
      "0.609535596598\n",
      "Iter 7610 ---- Process: 95.12%\n",
      "0.607825933858\n",
      "Iter 7620 ---- Process: 95.25%\n",
      "0.611582095127\n",
      "Iter 7630 ---- Process: 95.38%\n",
      "0.609250062034\n",
      "Iter 7640 ---- Process: 95.50%\n",
      "0.607227069246\n",
      "Iter 7650 ---- Process: 95.62%\n",
      "0.611953572916\n",
      "Iter 7660 ---- Process: 95.75%\n",
      "0.61374637595\n",
      "Iter 7670 ---- Process: 95.88%\n",
      "0.611103597999\n",
      "Iter 7680 ---- Process: 96.00%\n",
      "0.608143443829\n",
      "Iter 7690 ---- Process: 96.12%\n",
      "0.614308602886\n",
      "Iter 7700 ---- Process: 96.25%\n",
      "0.608699224291\n",
      "Iter 7710 ---- Process: 96.38%\n",
      "0.609361770743\n",
      "Iter 7720 ---- Process: 96.50%\n",
      "0.612700339771\n",
      "Iter 7730 ---- Process: 96.62%\n",
      "0.609599153381\n",
      "Iter 7740 ---- Process: 96.75%\n",
      "0.610408818381\n",
      "Iter 7750 ---- Process: 96.88%\n",
      "0.610260493097\n",
      "Iter 7760 ---- Process: 97.00%\n",
      "0.612660524203\n",
      "Iter 7770 ---- Process: 97.12%\n",
      "0.608970679802\n",
      "Iter 7780 ---- Process: 97.25%\n",
      "0.609640889477\n",
      "Iter 7790 ---- Process: 97.38%\n",
      "0.610464047887\n",
      "Iter 7800 ---- Process: 97.50%\n",
      "0.610164543253\n",
      "Iter 7810 ---- Process: 97.62%\n",
      "0.611140635782\n",
      "Iter 7820 ---- Process: 97.75%\n",
      "0.614113013573\n",
      "Iter 7830 ---- Process: 97.88%\n",
      "0.609716450401\n",
      "Iter 7840 ---- Process: 98.00%\n",
      "0.610181420857\n",
      "Iter 7850 ---- Process: 98.12%\n",
      "0.610101104933\n",
      "Iter 7860 ---- Process: 98.25%\n",
      "0.61130699275\n",
      "Iter 7870 ---- Process: 98.38%\n",
      "0.610196601543\n",
      "Iter 7880 ---- Process: 98.50%\n",
      "0.610719709117\n",
      "Iter 7890 ---- Process: 98.62%\n",
      "0.61548332833\n",
      "Iter 7900 ---- Process: 98.75%\n",
      "0.611441568898\n",
      "Iter 7910 ---- Process: 98.88%\n",
      "0.608851712048\n",
      "Iter 7920 ---- Process: 99.00%\n",
      "0.612769878765\n",
      "Iter 7930 ---- Process: 99.12%\n",
      "0.608964161447\n",
      "Iter 7940 ---- Process: 99.25%\n",
      "0.609139400278\n",
      "Iter 7950 ---- Process: 99.38%\n",
      "0.613048215308\n",
      "Iter 7960 ---- Process: 99.50%\n",
      "0.610995060409\n",
      "Iter 7970 ---- Process: 99.62%\n",
      "0.609597792173\n",
      "Iter 7980 ---- Process: 99.75%\n",
      "0.609124180106\n",
      "Iter 7990 ---- Process: 99.88%\n"
     ]
    }
   ],
   "source": [
    "R = np.zeros((Rs,cus_num))\n",
    "accuracy = []\n",
    "for i in range(0,1):\n",
    "    # generate test data\n",
    "    [test_x,test_y,test_z] = test_data_gen(test_x_data,test_y_data,n_steps,test_batch_size)\n",
    "    test_x = test_x.reshape(test_batch_size,n_steps,feature_size)\n",
    "    print test_x.shape,test_z.shape\n",
    "    test_z = test_z.reshape(test_batch_size,n_steps,cus_num)\n",
    "    ### Execute\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    outp = []\n",
    "    outlist = np.zeros([Rs,test_batch_size])\n",
    "    with tf.Session() as sess:\n",
    "        # Create a summary to monitor cost function\n",
    "        #tf.scalar_summary(\"loss\", cost)\n",
    "        #tf.scalar_summary(\"loss2\",cost2)\n",
    "        # Merge all summaries to a single operator\n",
    "        #merged_summary_op = tf.merge_all_summaries()\n",
    "\n",
    "        # tensorboard info.# Set logs writer into folder /tmp/tensorflow_logs\n",
    "        #summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=sess.graph_def)\n",
    "\n",
    "        #initialize all variables in the model\n",
    "        sess.run(init)\n",
    "        for k in range(num_epoches):\n",
    "            #Generate Data for each epoch\n",
    "            #What this does is it creates a list of of elements of length seq_len, each of size [batch_size,input_size]\n",
    "            #this is required to feed data into rnn.rnn\n",
    "            #print traindays\n",
    "            [X,Y,Z] = train_data_gen(traindays,train_x_data,train_y_data,n_steps,train_batch_size)\n",
    "            X = X.reshape(train_batch_size,n_steps,feature_size)\n",
    "            Z = Z.reshape(train_batch_size,n_steps,cus_num)\n",
    "\n",
    "            #Create the dictionary of inputs to feed into sess.run\n",
    "            \n",
    "            sess.run(optimizer,feed_dict={x:X,z:Z,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))})   \n",
    "            #perform an update on the parameters\n",
    "\n",
    "            #loss1 = sess.run(cost, feed_dict = {x:X,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))} )\n",
    "            #loss2 = sess.run(cost, feed_dict = {x:test_x,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )            #compute the cost on the validation set\n",
    "            #output_tmp = sess.run(pred,feed_dict = {x:X,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))} )\n",
    "            #outp_train = output_tmp\n",
    "            if k >= num_epoches-Rs:\n",
    "                output_tmp = sess.run(pred,feed_dict = {x:test_x,z:test_z,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )\n",
    "                outp_test = output_tmp\n",
    "            if k >= num_epoches-Rs:\n",
    "                outlist[k-num_epoches+Rs,:] = outp_test.copy().T\n",
    "            \n",
    "            # Write logs at every iteration\n",
    "            #summary_str = sess.run(merged_summary_op, feed_dict={x:test_x,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )\n",
    "            #summary_writer.add_summary(summary_str, k)\n",
    "            #print \"Iter \" + str(k) + \", Minibatch Loss ---- Train = \" + \"{:.6f}\".format(loss1)# + \"; Test = \" + \"{:.6f}\".format(loss2)\n",
    "            if k % 10 == 0:\n",
    "                tmp = sess.run(pred,feed_dict = {x:test_x,z:test_z,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )\n",
    "                #tmp = output_tmp_ex.T.reshape((1,test_batch_size))\n",
    "                #print tmp.T.shape\n",
    "                #print test_y.T.shape\n",
    "                Rit = np.zeros((cus_num,1))\n",
    "                for j in range(cus_num):\n",
    "                    KKK = np.corrcoef(tmp.T[0,test_minibatch_size*j:test_minibatch_size*(j+1)],test_y.T[0,test_minibatch_size*j:test_minibatch_size*(j+1)])[0,1] \n",
    "                    Rit[j,0] = KKK\n",
    "                print np.mean(Rit)\n",
    "                accuracy.append(np.mean(Rit))\n",
    "                print \"Iter \" + str(k) + \" ---- Process: \" + \"{:.2f}\".format(100*float(k)/float(num_epoches)) + \"%\"\n",
    "        #print \"haha{}\".format(outp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.76059158  0.74870189  0.60877172 ...,  0.64031368  0.54440407\n",
      "   0.54417539]\n",
      " [ 0.75851998  0.75065983  0.60832744 ...,  0.63646337  0.55016157\n",
      "   0.53804992]\n",
      " [ 0.75864216  0.74991121  0.61606924 ...,  0.64144677  0.54902837\n",
      "   0.53707572]\n",
      " ..., \n",
      " [ 0.77169673  0.75445862  0.53615599 ...,  0.63154197  0.53920437\n",
      "   0.54480378]\n",
      " [ 0.77343005  0.756984    0.54144926 ...,  0.6341443   0.53915181\n",
      "   0.54434686]\n",
      " [ 0.77052586  0.75383615  0.55260555 ...,  0.62832044  0.53664209\n",
      "   0.54565982]]\n",
      "[ 0.76721965  0.75244693  0.57525126  0.52264627  0.66561365  0.63900677\n",
      "  0.38021847  0.66656722  0.61765875  0.68868498  0.62680045  0.63507684\n",
      "  0.54967648  0.53947376]\n",
      "0.616167248733\n"
     ]
    }
   ],
   "source": [
    "for i in range(Rs):\n",
    "    for j in range(cus_num):\n",
    "        out = np.array(outlist[i])\n",
    "        tmp = out.T.reshape((1,test_batch_size))\n",
    "        R[i,j] = np.corrcoef(tmp[0,test_minibatch_size*j:test_minibatch_size*(j+1)],test_y.T[0,test_minibatch_size*j:test_minibatch_size*(j+1)])[0,1]\n",
    "print R\n",
    "R1 = np.mean(R,axis=0)\n",
    "print R1\n",
    "print np.mean(R1)\n",
    "accuracy.append(np.mean(R1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame(accuracy).to_csv('accuracy_multi_houses_5_30_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame(R1).to_csv('Rmean_multi_houses_5_30_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame(R).to_csv('Rlist_multi_houses_5_30_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time2 = time.time()\n",
    "time = time2-time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95928.23799085617"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76721965,  0.75244693,  0.57525126,  0.52264627,  0.66561365,\n",
       "        0.63900677,  0.38021847,  0.66656722,  0.61765875,  0.68868498,\n",
       "        0.62680045,  0.63507684,  0.54967648,  0.53947376])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
