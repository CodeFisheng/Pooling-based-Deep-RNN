{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Vector Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import all the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn, rnn_cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import argparse\n",
    "import os, sys\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1: setting all global parameters -- sec 1 data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "data_path = './input.csv'\n",
    "total_days = 350\n",
    "train_days = 280\n",
    "test_days = 70\n",
    "data_length = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2: setting all global parameters -- sec 2 network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epoches = 10\n",
    "n_steps = 4*7 # input size\n",
    "batch_size = 70 # days of a batch\n",
    "feature_size = 48 # same time of a week\n",
    "n_hidden = 10 # input size\n",
    "num_layers = 2\n",
    "n_output = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (280, 48), test data shape: (98, 48)\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(data_path)\n",
    "dat = np.array(dataframe)\n",
    "date_list = dat[:,1]\n",
    "dat = dat[:,2:]# drop the first two cols --- index and date\n",
    "nrows,ncols = dat.shape\n",
    "#print nrows,ncols\n",
    "data = dat.reshape((1,nrows*ncols))\n",
    "data_length = data.shape[1]\n",
    "\n",
    "# construct training data\n",
    "train_len = train_days*feature_size\n",
    "train_data = data[0,0:train_len]\n",
    "train_data = train_data.reshape([train_len/feature_size,feature_size])#days * 48 points\n",
    "\n",
    "# construct testing data\n",
    "## test size = input_size + test days size. since, the output should be \n",
    "## from first test sample to last. prefix is input-size data\n",
    "test_len = test_days*feature_size\n",
    "test_data = np.zeros(test_len+n_steps*feature_size)\n",
    "test_data[n_steps*feature_size:] = data[0,train_len:train_len+test_len]\n",
    "test_data[0:n_steps*feature_size] = data[0,train_len-n_steps*feature_size:train_len]\n",
    "test_data = test_data.reshape([test_days+n_steps,feature_size])\n",
    "print \"train data shape: {}, test data shape: {}\".format(train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check data\n",
    "xxx = np.arange(0,48*70)\n",
    "pl.plot(xxx,train_data[0:70,:].reshape([-1,1]),label = \"train\",color = \"red\")\n",
    "pl.plot(xxx,test_data[28:98,:].reshape([-1,1]),label = \"test\",color = \"purple\")\n",
    "pl.grid()\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 4: define data generating function code. \n",
    "which generate a batch of batch-size large sequence data. the data is feature_size dims width and is a time series of float32 of steps steps. inputs and outputs are:\n",
    "\n",
    "inputs:\n",
    "----n_batch: number of samples in a batch\n",
    "----steps: the sequence length of a sample data\n",
    "----feature_size: dimensions of a single time step data frame\n",
    "\n",
    "outputs:\n",
    "----X inputs, shape(n_batch,steps,feature_size)\n",
    "----Y outputs should be, shape(n_batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_data_gen(steps = 28, n_batch = 70):\n",
    "    X = np.zeros((n_batch,steps,feature_size))\n",
    "    Y = np.zeros((n_batch,feature_size))\n",
    "    #for each n, compute X and correct y values\n",
    "    for n in range(n_batch):\n",
    "        # randomly pick a sample's y, between acceptable range\n",
    "        index = np.random.randint(steps,train_days)\n",
    "        # update y\n",
    "        Y[n] = train_data[index,:]\n",
    "        # update X from index-steps to index-1\n",
    "        X[n,:,:] = train_data[index-steps:index,:]\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_data_gen(steps = 28, n_batch = 70):\n",
    "    X = np.zeros((n_batch,steps,feature_size))\n",
    "    Y = np.zeros((n_batch,feature_size))\n",
    "    #for each n, compute X and correct y values\n",
    "    for n in range(n_batch):\n",
    "        # update y\n",
    "        Y[n] = test_data[steps+n,:]\n",
    "        # update X from index-steps to index-1\n",
    "        X[n,:,:] = test_data[n:n+steps,:]\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: construct RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create placeholder for x and y\n",
    "x = tf.placeholder(\"float\",[None,n_steps,feature_size])\n",
    "istate = tf.placeholder(\"float\",[None,num_layers*2*n_hidden])\n",
    "y = tf.placeholder(\"float\",[None,n_output])\n",
    "\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([feature_size, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(_X, _istate, _weights, _biases):\n",
    "\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, feature_size]) # (n_steps*batch_size, n_input)\n",
    "    # Linear activation\n",
    "    _X = tf.matmul(_X, _weights['hidden']) + _biases['hidden']\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    stacked_lstm_cell = rnn_cell.MultiRNNCell([lstm_cell]*num_layers)\n",
    "    \n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(0, n_steps, _X) # n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(stacked_lstm_cell, _X, initial_state=_istate)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get inner loop last output\n",
    "    return tf.matmul(outputs[-1], _weights['out']) + _biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = RNN(x, istate, weights, biases)\n",
    "\n",
    "#cost function \n",
    "cost = tf.reduce_mean(tf.pow(pred-y,2)) # cost function of this batch of data\n",
    "#cost2 = tf.abs(cost1)\n",
    "#compute parameter updates\n",
    "#train_op = tf.train.GradientDescentOptimizer(0.008).minimize(cost)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.005, 0.3).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: generate validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: x_val shape - (70, 28, 48); y_val shape - (70, 48)\n"
     ]
    }
   ],
   "source": [
    "x_val,y_val = test_data_gen(n_steps,batch_size)\n",
    "print \"test data: x_val shape - {}; y_val shape - {}\".format(x_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 7: run rnn network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Minibatch Loss ---- Train = 1.106178; Test = 1.198850\n",
      "Iter 1, Minibatch Loss ---- Train = 1.052538; Test = 1.158478\n",
      "Iter 2, Minibatch Loss ---- Train = 1.002313; Test = 1.109926\n",
      "Iter 3, Minibatch Loss ---- Train = 0.933537; Test = 1.053651\n",
      "Iter 4, Minibatch Loss ---- Train = 0.873730; Test = 0.990542\n",
      "Iter 5, Minibatch Loss ---- Train = 0.804134; Test = 0.926600\n",
      "Iter 6, Minibatch Loss ---- Train = 0.736910; Test = 0.868168\n",
      "Iter 7, Minibatch Loss ---- Train = 0.669794; Test = 0.817586\n",
      "Iter 8, Minibatch Loss ---- Train = 0.640141; Test = 0.775528\n",
      "Iter 9, Minibatch Loss ---- Train = 0.597042; Test = 0.748017\n"
     ]
    }
   ],
   "source": [
    "### Execute\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "outp = []\n",
    "with tf.Session() as sess:\n",
    "    # Create a summary to monitor cost function\n",
    "    tf.scalar_summary(\"loss\", cost)\n",
    "    #tf.scalar_summary(\"loss2\",cost2)\n",
    "    # Merge all summaries to a single operator\n",
    "    merged_summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    # tensorboard info.# Set logs writer into folder /tmp/tensorflow_logs\n",
    "    summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=sess.graph_def)\n",
    "    \n",
    "    #initialize all variables in the model\n",
    "    sess.run(init)\n",
    "    for k in range(num_epoches):\n",
    "        #Generate Data for each epoch\n",
    "        #What this does is it creates a list of of elements of length seq_len, each of size [batch_size,input_size]\n",
    "        #this is required to feed data into rnn.rnn\n",
    "        X,Y = train_data_gen(n_steps,batch_size)\n",
    "        X = X.reshape(batch_size,n_steps,feature_size)\n",
    "        #Create the dictionary of inputs to feed into sess.run\n",
    "        sess.run(optimizer,feed_dict={x:X,y:Y,istate:np.zeros((batch_size,num_layers*2*n_hidden))})   \n",
    "        #perform an update on the parameters\n",
    "        \n",
    "        loss1 = sess.run(cost, feed_dict = {x:X,y:Y,istate:np.zeros((batch_size,num_layers*2*n_hidden))} )\n",
    "        loss2 = sess.run(cost, feed_dict = {x:x_val,y:y_val,istate:np.zeros((batch_size,num_layers*2*n_hidden))} )            #compute the cost on the validation set\n",
    "        output_tmp = sess.run(pred,feed_dict = {x:X,y:Y,istate:np.zeros((batch_size,num_layers*2*n_hidden))} )\n",
    "        outp_train = output_tmp\n",
    "        output_tmp = sess.run(pred,feed_dict = {x:x_val,y:y_val,istate:np.zeros((batch_size,num_layers*2*n_hidden))} )\n",
    "        outp_test = output_tmp\n",
    "            \n",
    "        # Write logs at every iteration\n",
    "        summary_str = sess.run(merged_summary_op, feed_dict={x:x_val,y:y_val,istate:np.zeros((batch_size,num_layers*2*n_hidden))} )\n",
    "        summary_writer.add_summary(summary_str, k)\n",
    "        print \"Iter \" + str(k) + \", Minibatch Loss ---- Train = \" + \"{:.6f}\".format(loss1) + \"; Test = \" + \"{:.6f}\".format(loss2)\n",
    "    #print \"haha{}\".format(outp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.array(outp_test)\n",
    "out = out.reshape([-1,1])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = y_val.reshape([-1,1])\n",
    "y_val.dtype = float\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R = np.corrcoef(out.T,y_val.T)\n",
    "RR = R**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.       ,  0.1195277],\n",
       "       [ 0.1195277,  1.       ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final R\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.01428687],\n",
       "       [ 0.01428687,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final R-square\n",
    "RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xxx = np.arange(0,test_len)\n",
    "pl.plot(xxx,out,label = \"predict\",color = \"red\")\n",
    "pl.plot(xxx,y_val,label = \"reality\",color = \"purple\")\n",
    "pl.grid()\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.748017512806611"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final MSE\n",
    "sq = pow(out-y_val,2)\n",
    "np.mean(sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.5641560555\n"
     ]
    }
   ],
   "source": [
    "# run time\n",
    "time2 = time.time()\n",
    "print time2-time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
