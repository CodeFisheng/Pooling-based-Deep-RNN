{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Learning (RNN) Demo for Load Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import all the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn, rnn_cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import random as rd\n",
    "import argparse\n",
    "import os, sys\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: setting all global parameters -- sec 2 network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time1 = time.time() # set up counter to record run time\n",
    "data_dir = './data/' # directory contains input data\n",
    "num_epoches = 800 # training epoches for each customer samples\n",
    "n_steps = 48 # input size\n",
    "test_batch_size = 70*48 # days of a batch\n",
    "train_batch_size = 50*48\n",
    "feature_size = 1 # same time of a week\n",
    "n_hidden = 5 # input size\n",
    "num_layers = 2\n",
    "n_output = 1\n",
    "Rs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 4: define data generating function code. \n",
    "which generate a batch of batch-size large sequence data. the data is feature_size dims width and is a time series of float32 of steps steps. inputs and outputs are:\n",
    "\n",
    "inputs:\n",
    "----n_batch: number of samples in a batch\n",
    "----steps: the sequence length of a sample data\n",
    "----feature_size: dimensions of a single time step data frame\n",
    "\n",
    "outputs:\n",
    "----X inputs, shape(n_batch,steps,feature_size)\n",
    "----Y outputs should be, shape(n_batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_data_gen(totaltraindays,x_data,y_data,steps = 48, n_batch = train_batch_size):\n",
    "    X = np.zeros((n_batch,steps,feature_size))\n",
    "    Y = np.zeros((n_batch,feature_size))\n",
    "    rang = range(totaltraindays) # test day sample range\n",
    "    train_days_list = rd.sample(rang,n_batch) # pick unduplicated n indexes as examples\n",
    "    tmpX = [x_data[i,0-steps:] for i in train_days_list]\n",
    "    tmpY = [y_data[i,:] for i in train_days_list]\n",
    "    X = np.array(tmpX).reshape(n_batch,steps,feature_size)\n",
    "    Y = np.array(tmpY).reshape(n_batch,feature_size)\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_data_gen(x_data,y_data,steps = 48, n_batch = test_batch_size):\n",
    "    X = np.zeros((n_batch,steps,feature_size))\n",
    "    Y = np.zeros((n_batch,feature_size))\n",
    "    #print x_data[:,0-steps:].shape,y_data.shape\n",
    "    #print n_batch, steps\n",
    "    X = x_data[:,0-steps:].reshape(n_batch,steps,feature_size)\n",
    "    Y = y_data.reshape(n_batch,feature_size)\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: construct RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create placeholder for x and y\n",
    "x = tf.placeholder(\"float\",[None,n_steps,feature_size])\n",
    "istate = tf.placeholder(\"float\",[None,num_layers*2*n_hidden])\n",
    "y = tf.placeholder(\"float\",[None,n_output])\n",
    "\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([feature_size, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(_X, _istate, _weights, _biases):\n",
    "\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, feature_size]) # (n_steps*batch_size, n_input)\n",
    "    # Linear activation\n",
    "    _X = tf.matmul(_X, _weights['hidden']) + _biases['hidden']\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    stacked_lstm_cell = rnn_cell.MultiRNNCell([lstm_cell]*num_layers)\n",
    "    \n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(0, n_steps, _X) # n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(stacked_lstm_cell, _X, initial_state=_istate)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get inner loop last output\n",
    "    return tf.matmul(outputs[-1], _weights['out']) + _biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = RNN(x, istate, weights, biases)\n",
    "\n",
    "#cost function \n",
    "cost = tf.reduce_mean(tf.pow(pred-y,2)) # cost function of this batch of data\n",
    "cost2 = tf.abs(pred-y) # \n",
    "#compute parameter updates\n",
    "#train_op = tf.train.GradientDescentOptimizer(0.008).minimize(cost)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.005, 0.3).minimize(cost)\n",
    "optimizer2 = tf.train.RMSPropOptimizer(0.005, 0.3).minimize(cost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Minibatch Loss ---- Train = 0.381251; Test = 0.373224\n",
      "Iter 1, Minibatch Loss ---- Train = 0.246432; Test = 0.237156\n",
      "Iter 2, Minibatch Loss ---- Train = 0.193494; Test = 0.150495\n",
      "Iter 3, Minibatch Loss ---- Train = 0.105268; Test = 0.094208\n",
      "Iter 4, Minibatch Loss ---- Train = 0.104659; Test = 0.063726\n",
      "Iter 5, Minibatch Loss ---- Train = 0.082713; Test = 0.059110\n",
      "Iter 6, Minibatch Loss ---- Train = 0.085428; Test = 0.062208\n",
      "Iter 7, Minibatch Loss ---- Train = 0.070953; Test = 0.054379\n",
      "Iter 8, Minibatch Loss ---- Train = 0.109769; Test = 0.073886\n",
      "Iter 9, Minibatch Loss ---- Train = 0.076573; Test = 0.053481\n",
      "Iter 10, Minibatch Loss ---- Train = 0.067629; Test = 0.061641\n",
      "Iter 11, Minibatch Loss ---- Train = 0.060152; Test = 0.053721\n",
      "Iter 12, Minibatch Loss ---- Train = 0.092295; Test = 0.072815\n",
      "Iter 13, Minibatch Loss ---- Train = 0.064719; Test = 0.052988\n",
      "Iter 14, Minibatch Loss ---- Train = 0.086826; Test = 0.062348\n",
      "Iter 15, Minibatch Loss ---- Train = 0.071608; Test = 0.052739\n",
      "Iter 16, Minibatch Loss ---- Train = 0.071772; Test = 0.068974\n",
      "Iter 17, Minibatch Loss ---- Train = 0.067110; Test = 0.052339\n",
      "Iter 18, Minibatch Loss ---- Train = 0.071053; Test = 0.061591\n",
      "Iter 19, Minibatch Loss ---- Train = 0.051898; Test = 0.052354\n",
      "Iter 20, Minibatch Loss ---- Train = 0.062285; Test = 0.067827\n",
      "Iter 21, Minibatch Loss ---- Train = 0.052166; Test = 0.051858\n",
      "Iter 22, Minibatch Loss ---- Train = 0.076950; Test = 0.060305\n",
      "Iter 23, Minibatch Loss ---- Train = 0.062005; Test = 0.051856\n",
      "Iter 24, Minibatch Loss ---- Train = 0.077449; Test = 0.068864\n",
      "Iter 25, Minibatch Loss ---- Train = 0.071253; Test = 0.051507\n",
      "Iter 26, Minibatch Loss ---- Train = 0.070647; Test = 0.061390\n",
      "Iter 27, Minibatch Loss ---- Train = 0.064853; Test = 0.051210\n",
      "Iter 28, Minibatch Loss ---- Train = 0.094258; Test = 0.063839\n",
      "Iter 29, Minibatch Loss ---- Train = 0.094918; Test = 0.050922\n",
      "Iter 30, Minibatch Loss ---- Train = 0.071933; Test = 0.060903\n",
      "Iter 31, Minibatch Loss ---- Train = 0.072632; Test = 0.050761\n",
      "Iter 32, Minibatch Loss ---- Train = 0.093433; Test = 0.063600\n",
      "Iter 33, Minibatch Loss ---- Train = 0.085491; Test = 0.050529\n",
      "Iter 34, Minibatch Loss ---- Train = 0.070791; Test = 0.060392\n",
      "Iter 35, Minibatch Loss ---- Train = 0.068102; Test = 0.050304\n",
      "Iter 36, Minibatch Loss ---- Train = 0.075179; Test = 0.061876\n",
      "Iter 37, Minibatch Loss ---- Train = 0.064497; Test = 0.050120\n",
      "Iter 38, Minibatch Loss ---- Train = 0.064624; Test = 0.060151\n",
      "Iter 39, Minibatch Loss ---- Train = 0.064487; Test = 0.049919\n",
      "Iter 40, Minibatch Loss ---- Train = 0.076623; Test = 0.061376\n",
      "Iter 41, Minibatch Loss ---- Train = 0.072322; Test = 0.049725\n",
      "Iter 42, Minibatch Loss ---- Train = 0.073307; Test = 0.060588\n",
      "Iter 43, Minibatch Loss ---- Train = 0.069743; Test = 0.049427\n",
      "Iter 44, Minibatch Loss ---- Train = 0.075241; Test = 0.059798\n",
      "Iter 45, Minibatch Loss ---- Train = 0.067483; Test = 0.049203\n",
      "Iter 46, Minibatch Loss ---- Train = 0.084611; Test = 0.060915\n",
      "Iter 47, Minibatch Loss ---- Train = 0.071737; Test = 0.048971\n",
      "Iter 48, Minibatch Loss ---- Train = 0.084605; Test = 0.059112\n",
      "Iter 49, Minibatch Loss ---- Train = 0.059590; Test = 0.048728\n",
      "Iter 50, Minibatch Loss ---- Train = 0.054014; Test = 0.048720\n",
      "Iter 51, Minibatch Loss ---- Train = 0.065366; Test = 0.048700\n",
      "Iter 52, Minibatch Loss ---- Train = 0.061330; Test = 0.048670\n",
      "Iter 53, Minibatch Loss ---- Train = 0.069218; Test = 0.048688\n",
      "Iter 54, Minibatch Loss ---- Train = 0.058706; Test = 0.048612\n",
      "Iter 55, Minibatch Loss ---- Train = 0.050017; Test = 0.048543\n",
      "Iter 56, Minibatch Loss ---- Train = 0.054323; Test = 0.048806\n",
      "Iter 57, Minibatch Loss ---- Train = 0.083480; Test = 0.051880\n",
      "Iter 58, Minibatch Loss ---- Train = 0.068267; Test = 0.049784\n",
      "Iter 59, Minibatch Loss ---- Train = 0.055582; Test = 0.049837\n",
      "Iter 60, Minibatch Loss ---- Train = 0.061079; Test = 0.050353\n",
      "Iter 61, Minibatch Loss ---- Train = 0.071743; Test = 0.050741\n",
      "Iter 62, Minibatch Loss ---- Train = 0.067191; Test = 0.049169\n",
      "Iter 63, Minibatch Loss ---- Train = 0.065057; Test = 0.049915\n",
      "Iter 64, Minibatch Loss ---- Train = 0.070549; Test = 0.049253\n",
      "Iter 65, Minibatch Loss ---- Train = 0.066365; Test = 0.049680\n",
      "Iter 66, Minibatch Loss ---- Train = 0.046531; Test = 0.048676\n",
      "Iter 67, Minibatch Loss ---- Train = 0.062923; Test = 0.048457\n",
      "Iter 68, Minibatch Loss ---- Train = 0.055338; Test = 0.048556\n",
      "Iter 69, Minibatch Loss ---- Train = 0.063803; Test = 0.048595\n",
      "Iter 70, Minibatch Loss ---- Train = 0.065763; Test = 0.047394\n",
      "Iter 71, Minibatch Loss ---- Train = 0.042044; Test = 0.047541\n",
      "Iter 72, Minibatch Loss ---- Train = 0.064535; Test = 0.047299\n",
      "Iter 73, Minibatch Loss ---- Train = 0.045658; Test = 0.047511\n",
      "Iter 74, Minibatch Loss ---- Train = 0.047719; Test = 0.047656\n",
      "Iter 75, Minibatch Loss ---- Train = 0.046519; Test = 0.046251\n",
      "Iter 76, Minibatch Loss ---- Train = 0.056818; Test = 0.046221\n",
      "Iter 77, Minibatch Loss ---- Train = 0.046837; Test = 0.046223\n",
      "Iter 78, Minibatch Loss ---- Train = 0.066276; Test = 0.045664\n",
      "Iter 79, Minibatch Loss ---- Train = 0.048473; Test = 0.046203\n",
      "Iter 80, Minibatch Loss ---- Train = 0.049949; Test = 0.045683\n",
      "Iter 81, Minibatch Loss ---- Train = 0.055962; Test = 0.045131\n",
      "Iter 82, Minibatch Loss ---- Train = 0.064259; Test = 0.044300\n",
      "Iter 83, Minibatch Loss ---- Train = 0.058219; Test = 0.045051\n",
      "Iter 84, Minibatch Loss ---- Train = 0.062827; Test = 0.044625\n",
      "Iter 85, Minibatch Loss ---- Train = 0.052610; Test = 0.044339\n",
      "Iter 86, Minibatch Loss ---- Train = 0.047681; Test = 0.043858\n",
      "Iter 87, Minibatch Loss ---- Train = 0.042553; Test = 0.042841\n",
      "Iter 88, Minibatch Loss ---- Train = 0.048266; Test = 0.044534\n",
      "Iter 89, Minibatch Loss ---- Train = 0.055892; Test = 0.043129\n",
      "Iter 90, Minibatch Loss ---- Train = 0.041181; Test = 0.043117\n",
      "Iter 91, Minibatch Loss ---- Train = 0.052723; Test = 0.042320\n",
      "Iter 92, Minibatch Loss ---- Train = 0.054055; Test = 0.042814\n",
      "Iter 93, Minibatch Loss ---- Train = 0.054147; Test = 0.042677\n",
      "Iter 94, Minibatch Loss ---- Train = 0.050354; Test = 0.041192\n",
      "Iter 95, Minibatch Loss ---- Train = 0.041854; Test = 0.041813\n",
      "Iter 96, Minibatch Loss ---- Train = 0.048080; Test = 0.042371\n",
      "Iter 97, Minibatch Loss ---- Train = 0.055692; Test = 0.041106\n",
      "Iter 98, Minibatch Loss ---- Train = 0.038334; Test = 0.041300\n",
      "Iter 99, Minibatch Loss ---- Train = 0.043751; Test = 0.040809\n",
      "Iter 100, Minibatch Loss ---- Train = 0.055091; Test = 0.040301\n",
      "Iter 101, Minibatch Loss ---- Train = 0.046994; Test = 0.041090\n",
      "Iter 102, Minibatch Loss ---- Train = 0.052728; Test = 0.040463\n",
      "Iter 103, Minibatch Loss ---- Train = 0.045567; Test = 0.039992\n",
      "Iter 104, Minibatch Loss ---- Train = 0.040898; Test = 0.040083\n",
      "Iter 105, Minibatch Loss ---- Train = 0.054065; Test = 0.039690\n",
      "Iter 106, Minibatch Loss ---- Train = 0.060168; Test = 0.038593\n",
      "Iter 107, Minibatch Loss ---- Train = 0.050262; Test = 0.039744\n",
      "Iter 108, Minibatch Loss ---- Train = 0.045348; Test = 0.039492\n",
      "Iter 109, Minibatch Loss ---- Train = 0.043800; Test = 0.038636\n",
      "Iter 110, Minibatch Loss ---- Train = 0.041104; Test = 0.038419\n",
      "Iter 111, Minibatch Loss ---- Train = 0.047938; Test = 0.038775\n",
      "Iter 112, Minibatch Loss ---- Train = 0.040670; Test = 0.038321\n",
      "Iter 113, Minibatch Loss ---- Train = 0.058332; Test = 0.038369\n",
      "Iter 114, Minibatch Loss ---- Train = 0.053889; Test = 0.037230\n",
      "Iter 115, Minibatch Loss ---- Train = 0.041487; Test = 0.037506\n",
      "Iter 116, Minibatch Loss ---- Train = 0.047680; Test = 0.037450\n",
      "Iter 117, Minibatch Loss ---- Train = 0.060209; Test = 0.038163\n",
      "Iter 118, Minibatch Loss ---- Train = 0.044112; Test = 0.036538\n",
      "Iter 119, Minibatch Loss ---- Train = 0.050156; Test = 0.037343\n",
      "Iter 120, Minibatch Loss ---- Train = 0.043129; Test = 0.036645\n",
      "Iter 121, Minibatch Loss ---- Train = 0.047139; Test = 0.036595\n",
      "Iter 122, Minibatch Loss ---- Train = 0.041487; Test = 0.036452\n",
      "Iter 123, Minibatch Loss ---- Train = 0.054235; Test = 0.036594\n",
      "Iter 124, Minibatch Loss ---- Train = 0.054164; Test = 0.036054\n",
      "Iter 125, Minibatch Loss ---- Train = 0.041031; Test = 0.036045\n",
      "Iter 126, Minibatch Loss ---- Train = 0.041942; Test = 0.035473\n",
      "Iter 127, Minibatch Loss ---- Train = 0.038213; Test = 0.036160\n",
      "Iter 128, Minibatch Loss ---- Train = 0.041694; Test = 0.035359\n",
      "Iter 129, Minibatch Loss ---- Train = 0.045417; Test = 0.035663\n",
      "Iter 130, Minibatch Loss ---- Train = 0.047968; Test = 0.035143\n",
      "Iter 131, Minibatch Loss ---- Train = 0.041405; Test = 0.035267\n",
      "Iter 132, Minibatch Loss ---- Train = 0.035409; Test = 0.035468\n",
      "Iter 133, Minibatch Loss ---- Train = 0.038118; Test = 0.034580\n",
      "Iter 134, Minibatch Loss ---- Train = 0.043256; Test = 0.034094\n",
      "Iter 135, Minibatch Loss ---- Train = 0.039245; Test = 0.035273\n",
      "Iter 136, Minibatch Loss ---- Train = 0.040553; Test = 0.034860\n",
      "Iter 137, Minibatch Loss ---- Train = 0.042288; Test = 0.034312\n",
      "Iter 138, Minibatch Loss ---- Train = 0.037036; Test = 0.033806\n",
      "Iter 139, Minibatch Loss ---- Train = 0.048047; Test = 0.034989\n",
      "Iter 140, Minibatch Loss ---- Train = 0.051843; Test = 0.033621\n",
      "Iter 141, Minibatch Loss ---- Train = 0.036536; Test = 0.034892\n",
      "Iter 142, Minibatch Loss ---- Train = 0.044276; Test = 0.033624\n",
      "Iter 143, Minibatch Loss ---- Train = 0.033926; Test = 0.033884\n",
      "Iter 144, Minibatch Loss ---- Train = 0.039552; Test = 0.033891\n",
      "Iter 145, Minibatch Loss ---- Train = 0.044624; Test = 0.033906\n",
      "Iter 146, Minibatch Loss ---- Train = 0.033944; Test = 0.033453\n",
      "Iter 147, Minibatch Loss ---- Train = 0.036670; Test = 0.033021\n",
      "Iter 148, Minibatch Loss ---- Train = 0.050275; Test = 0.033512\n",
      "Iter 149, Minibatch Loss ---- Train = 0.028937; Test = 0.033527\n",
      "Iter 150, Minibatch Loss ---- Train = 0.035433; Test = 0.033320\n",
      "Iter 151, Minibatch Loss ---- Train = 0.038649; Test = 0.033423\n",
      "Iter 152, Minibatch Loss ---- Train = 0.040013; Test = 0.033339\n",
      "Iter 153, Minibatch Loss ---- Train = 0.038311; Test = 0.032751\n",
      "Iter 154, Minibatch Loss ---- Train = 0.038020; Test = 0.032505\n",
      "Iter 155, Minibatch Loss ---- Train = 0.029549; Test = 0.033144\n",
      "Iter 156, Minibatch Loss ---- Train = 0.034190; Test = 0.033390\n",
      "Iter 157, Minibatch Loss ---- Train = 0.046435; Test = 0.032631\n",
      "Iter 158, Minibatch Loss ---- Train = 0.031172; Test = 0.032216\n",
      "Iter 159, Minibatch Loss ---- Train = 0.039817; Test = 0.033142\n",
      "Iter 160, Minibatch Loss ---- Train = 0.040870; Test = 0.032628\n",
      "Iter 161, Minibatch Loss ---- Train = 0.043459; Test = 0.032751\n",
      "Iter 162, Minibatch Loss ---- Train = 0.037003; Test = 0.031892\n",
      "Iter 163, Minibatch Loss ---- Train = 0.035297; Test = 0.032763\n",
      "Iter 164, Minibatch Loss ---- Train = 0.047285; Test = 0.032019\n",
      "Iter 165, Minibatch Loss ---- Train = 0.034855; Test = 0.033409\n",
      "Iter 166, Minibatch Loss ---- Train = 0.037165; Test = 0.032084\n",
      "Iter 167, Minibatch Loss ---- Train = 0.038151; Test = 0.032224\n",
      "Iter 168, Minibatch Loss ---- Train = 0.036978; Test = 0.032465\n",
      "Iter 169, Minibatch Loss ---- Train = 0.050458; Test = 0.032243\n",
      "Iter 170, Minibatch Loss ---- Train = 0.035589; Test = 0.031769\n",
      "Iter 171, Minibatch Loss ---- Train = 0.033137; Test = 0.031983\n",
      "Iter 172, Minibatch Loss ---- Train = 0.040195; Test = 0.032267\n",
      "Iter 173, Minibatch Loss ---- Train = 0.035077; Test = 0.032330\n",
      "Iter 174, Minibatch Loss ---- Train = 0.048083; Test = 0.031534\n",
      "Iter 175, Minibatch Loss ---- Train = 0.051119; Test = 0.033030\n",
      "Iter 176, Minibatch Loss ---- Train = 0.043921; Test = 0.031503\n",
      "Iter 177, Minibatch Loss ---- Train = 0.041749; Test = 0.032037\n",
      "Iter 178, Minibatch Loss ---- Train = 0.045665; Test = 0.031863\n",
      "Iter 179, Minibatch Loss ---- Train = 0.056985; Test = 0.032351\n",
      "Iter 180, Minibatch Loss ---- Train = 0.027226; Test = 0.031704\n",
      "Iter 181, Minibatch Loss ---- Train = 0.038613; Test = 0.031420\n",
      "Iter 182, Minibatch Loss ---- Train = 0.043393; Test = 0.031724\n",
      "Iter 183, Minibatch Loss ---- Train = 0.040331; Test = 0.032150\n",
      "Iter 184, Minibatch Loss ---- Train = 0.044141; Test = 0.031645\n",
      "Iter 185, Minibatch Loss ---- Train = 0.044146; Test = 0.032298\n",
      "Iter 186, Minibatch Loss ---- Train = 0.036637; Test = 0.031496\n",
      "Iter 187, Minibatch Loss ---- Train = 0.041871; Test = 0.032133\n",
      "Iter 188, Minibatch Loss ---- Train = 0.038019; Test = 0.031561\n",
      "Iter 189, Minibatch Loss ---- Train = 0.035475; Test = 0.031943\n",
      "Iter 190, Minibatch Loss ---- Train = 0.033826; Test = 0.031528\n",
      "Iter 191, Minibatch Loss ---- Train = 0.038087; Test = 0.031759\n",
      "Iter 192, Minibatch Loss ---- Train = 0.047598; Test = 0.031513\n",
      "Iter 193, Minibatch Loss ---- Train = 0.034344; Test = 0.032359\n",
      "Iter 194, Minibatch Loss ---- Train = 0.035719; Test = 0.031382\n",
      "Iter 195, Minibatch Loss ---- Train = 0.042706; Test = 0.032022\n",
      "Iter 196, Minibatch Loss ---- Train = 0.025023; Test = 0.031784\n",
      "Iter 197, Minibatch Loss ---- Train = 0.034545; Test = 0.031417\n",
      "Iter 198, Minibatch Loss ---- Train = 0.028983; Test = 0.031419\n",
      "Iter 199, Minibatch Loss ---- Train = 0.039366; Test = 0.031900\n",
      "Iter 200, Minibatch Loss ---- Train = 0.036885; Test = 0.031385\n",
      "Iter 201, Minibatch Loss ---- Train = 0.037656; Test = 0.031605\n",
      "Iter 202, Minibatch Loss ---- Train = 0.033035; Test = 0.031538\n",
      "Iter 203, Minibatch Loss ---- Train = 0.040758; Test = 0.031643\n",
      "Iter 204, Minibatch Loss ---- Train = 0.035422; Test = 0.031219\n",
      "Iter 205, Minibatch Loss ---- Train = 0.044359; Test = 0.032006\n",
      "Iter 206, Minibatch Loss ---- Train = 0.044484; Test = 0.031266\n",
      "Iter 207, Minibatch Loss ---- Train = 0.028823; Test = 0.031302\n",
      "Iter 208, Minibatch Loss ---- Train = 0.035739; Test = 0.031652\n",
      "Iter 209, Minibatch Loss ---- Train = 0.037664; Test = 0.031889\n",
      "Iter 210, Minibatch Loss ---- Train = 0.035857; Test = 0.031378\n",
      "Iter 211, Minibatch Loss ---- Train = 0.035827; Test = 0.031051\n",
      "Iter 212, Minibatch Loss ---- Train = 0.042406; Test = 0.031483\n",
      "Iter 213, Minibatch Loss ---- Train = 0.037544; Test = 0.031705\n",
      "Iter 214, Minibatch Loss ---- Train = 0.042686; Test = 0.031418\n",
      "Iter 215, Minibatch Loss ---- Train = 0.052389; Test = 0.031833\n",
      "Iter 216, Minibatch Loss ---- Train = 0.037595; Test = 0.030772\n",
      "Iter 217, Minibatch Loss ---- Train = 0.047884; Test = 0.032133\n",
      "Iter 218, Minibatch Loss ---- Train = 0.041292; Test = 0.030943\n",
      "Iter 219, Minibatch Loss ---- Train = 0.045011; Test = 0.032143\n",
      "Iter 220, Minibatch Loss ---- Train = 0.035291; Test = 0.031274\n",
      "Iter 221, Minibatch Loss ---- Train = 0.035059; Test = 0.031240\n",
      "Iter 222, Minibatch Loss ---- Train = 0.040222; Test = 0.030956\n",
      "Iter 223, Minibatch Loss ---- Train = 0.041341; Test = 0.032020\n",
      "Iter 224, Minibatch Loss ---- Train = 0.044825; Test = 0.030962\n",
      "Iter 225, Minibatch Loss ---- Train = 0.044351; Test = 0.032605\n",
      "Iter 226, Minibatch Loss ---- Train = 0.032455; Test = 0.031132\n",
      "Iter 227, Minibatch Loss ---- Train = 0.030392; Test = 0.031048\n",
      "Iter 228, Minibatch Loss ---- Train = 0.034043; Test = 0.031598\n",
      "Iter 229, Minibatch Loss ---- Train = 0.057813; Test = 0.031809\n",
      "Iter 230, Minibatch Loss ---- Train = 0.044246; Test = 0.030658\n",
      "Iter 231, Minibatch Loss ---- Train = 0.039246; Test = 0.031461\n",
      "Iter 232, Minibatch Loss ---- Train = 0.037167; Test = 0.031546\n",
      "Iter 233, Minibatch Loss ---- Train = 0.034899; Test = 0.031380\n",
      "Iter 234, Minibatch Loss ---- Train = 0.030544; Test = 0.031414\n",
      "Iter 235, Minibatch Loss ---- Train = 0.046572; Test = 0.031188\n",
      "Iter 236, Minibatch Loss ---- Train = 0.038921; Test = 0.030974\n",
      "Iter 237, Minibatch Loss ---- Train = 0.035267; Test = 0.031355\n",
      "Iter 238, Minibatch Loss ---- Train = 0.036377; Test = 0.031435\n",
      "Iter 239, Minibatch Loss ---- Train = 0.029809; Test = 0.031117\n",
      "Iter 240, Minibatch Loss ---- Train = 0.037749; Test = 0.030987\n",
      "Iter 241, Minibatch Loss ---- Train = 0.041007; Test = 0.031240\n",
      "Iter 242, Minibatch Loss ---- Train = 0.040731; Test = 0.031398\n",
      "Iter 243, Minibatch Loss ---- Train = 0.034272; Test = 0.031187\n",
      "Iter 244, Minibatch Loss ---- Train = 0.031593; Test = 0.031357\n",
      "Iter 245, Minibatch Loss ---- Train = 0.034517; Test = 0.030755\n",
      "Iter 246, Minibatch Loss ---- Train = 0.040856; Test = 0.030970\n",
      "Iter 247, Minibatch Loss ---- Train = 0.044593; Test = 0.031822\n",
      "Iter 248, Minibatch Loss ---- Train = 0.032181; Test = 0.030796\n",
      "Iter 249, Minibatch Loss ---- Train = 0.037708; Test = 0.031308\n",
      "Iter 250, Minibatch Loss ---- Train = 0.034630; Test = 0.031031\n",
      "Iter 251, Minibatch Loss ---- Train = 0.034544; Test = 0.031308\n",
      "Iter 252, Minibatch Loss ---- Train = 0.033410; Test = 0.031084\n",
      "Iter 253, Minibatch Loss ---- Train = 0.038047; Test = 0.031706\n",
      "Iter 254, Minibatch Loss ---- Train = 0.032712; Test = 0.030944\n",
      "Iter 255, Minibatch Loss ---- Train = 0.036520; Test = 0.030948\n",
      "Iter 256, Minibatch Loss ---- Train = 0.044417; Test = 0.031158\n",
      "Iter 257, Minibatch Loss ---- Train = 0.039889; Test = 0.031449\n",
      "Iter 258, Minibatch Loss ---- Train = 0.045994; Test = 0.030716\n",
      "Iter 259, Minibatch Loss ---- Train = 0.044646; Test = 0.031592\n",
      "Iter 260, Minibatch Loss ---- Train = 0.028497; Test = 0.031005\n",
      "Iter 261, Minibatch Loss ---- Train = 0.036049; Test = 0.030847\n",
      "Iter 262, Minibatch Loss ---- Train = 0.042805; Test = 0.030929\n",
      "Iter 263, Minibatch Loss ---- Train = 0.031676; Test = 0.031570\n",
      "Iter 264, Minibatch Loss ---- Train = 0.034851; Test = 0.030959\n",
      "Iter 265, Minibatch Loss ---- Train = 0.028408; Test = 0.030974\n",
      "Iter 266, Minibatch Loss ---- Train = 0.038333; Test = 0.031228\n",
      "Iter 267, Minibatch Loss ---- Train = 0.046168; Test = 0.031242\n",
      "Iter 268, Minibatch Loss ---- Train = 0.042974; Test = 0.030530\n",
      "Iter 269, Minibatch Loss ---- Train = 0.034364; Test = 0.031587\n",
      "Iter 270, Minibatch Loss ---- Train = 0.043020; Test = 0.030986\n",
      "Iter 271, Minibatch Loss ---- Train = 0.032829; Test = 0.031038\n",
      "Iter 272, Minibatch Loss ---- Train = 0.030245; Test = 0.031083\n",
      "Iter 273, Minibatch Loss ---- Train = 0.033218; Test = 0.030893\n",
      "Iter 274, Minibatch Loss ---- Train = 0.031426; Test = 0.030710\n",
      "Iter 275, Minibatch Loss ---- Train = 0.045364; Test = 0.031270\n",
      "Iter 276, Minibatch Loss ---- Train = 0.045943; Test = 0.030389\n",
      "Iter 277, Minibatch Loss ---- Train = 0.039840; Test = 0.031821\n",
      "Iter 278, Minibatch Loss ---- Train = 0.041447; Test = 0.030633\n",
      "Iter 279, Minibatch Loss ---- Train = 0.031418; Test = 0.030778\n",
      "Iter 280, Minibatch Loss ---- Train = 0.037614; Test = 0.031158\n",
      "Iter 281, Minibatch Loss ---- Train = 0.042062; Test = 0.030526\n",
      "Iter 282, Minibatch Loss ---- Train = 0.032406; Test = 0.030889\n",
      "Iter 283, Minibatch Loss ---- Train = 0.029459; Test = 0.030964\n",
      "Iter 284, Minibatch Loss ---- Train = 0.038034; Test = 0.030765\n",
      "Iter 285, Minibatch Loss ---- Train = 0.029327; Test = 0.030787\n",
      "Iter 286, Minibatch Loss ---- Train = 0.031195; Test = 0.031017\n",
      "Iter 287, Minibatch Loss ---- Train = 0.028272; Test = 0.030845\n",
      "Iter 288, Minibatch Loss ---- Train = 0.040643; Test = 0.030511\n",
      "Iter 289, Minibatch Loss ---- Train = 0.025631; Test = 0.031258\n",
      "Iter 290, Minibatch Loss ---- Train = 0.048230; Test = 0.030769\n",
      "Iter 291, Minibatch Loss ---- Train = 0.030693; Test = 0.030596\n",
      "Iter 292, Minibatch Loss ---- Train = 0.035811; Test = 0.031132\n",
      "Iter 293, Minibatch Loss ---- Train = 0.033156; Test = 0.030553\n",
      "Iter 294, Minibatch Loss ---- Train = 0.033464; Test = 0.030805\n",
      "Iter 295, Minibatch Loss ---- Train = 0.031307; Test = 0.031106\n",
      "Iter 296, Minibatch Loss ---- Train = 0.030556; Test = 0.030512\n",
      "Iter 297, Minibatch Loss ---- Train = 0.044854; Test = 0.031276\n",
      "Iter 298, Minibatch Loss ---- Train = 0.028713; Test = 0.030259\n",
      "Iter 299, Minibatch Loss ---- Train = 0.040989; Test = 0.030877\n",
      "Iter 300, Minibatch Loss ---- Train = 0.031726; Test = 0.030756\n",
      "Iter 301, Minibatch Loss ---- Train = 0.038727; Test = 0.030700\n",
      "Iter 302, Minibatch Loss ---- Train = 0.036697; Test = 0.030846\n",
      "Iter 303, Minibatch Loss ---- Train = 0.044018; Test = 0.031111\n",
      "Iter 304, Minibatch Loss ---- Train = 0.041353; Test = 0.030379\n",
      "Iter 305, Minibatch Loss ---- Train = 0.033894; Test = 0.030785\n",
      "Iter 306, Minibatch Loss ---- Train = 0.037642; Test = 0.030929\n",
      "Iter 307, Minibatch Loss ---- Train = 0.032849; Test = 0.030572\n",
      "Iter 308, Minibatch Loss ---- Train = 0.036825; Test = 0.030511\n",
      "Iter 309, Minibatch Loss ---- Train = 0.038640; Test = 0.030577\n",
      "Iter 310, Minibatch Loss ---- Train = 0.029608; Test = 0.031182\n",
      "Iter 311, Minibatch Loss ---- Train = 0.045879; Test = 0.030517\n",
      "Iter 312, Minibatch Loss ---- Train = 0.038094; Test = 0.030034\n",
      "Iter 313, Minibatch Loss ---- Train = 0.034264; Test = 0.030733\n",
      "Iter 314, Minibatch Loss ---- Train = 0.035869; Test = 0.030903\n",
      "Iter 315, Minibatch Loss ---- Train = 0.040730; Test = 0.030647\n",
      "Iter 316, Minibatch Loss ---- Train = 0.042170; Test = 0.030031\n",
      "Iter 317, Minibatch Loss ---- Train = 0.041769; Test = 0.031526\n",
      "Iter 318, Minibatch Loss ---- Train = 0.035021; Test = 0.030670\n",
      "Iter 319, Minibatch Loss ---- Train = 0.041947; Test = 0.030589\n",
      "Iter 320, Minibatch Loss ---- Train = 0.048288; Test = 0.030255\n",
      "Iter 321, Minibatch Loss ---- Train = 0.033071; Test = 0.030705\n",
      "Iter 322, Minibatch Loss ---- Train = 0.035902; Test = 0.030994\n",
      "Iter 323, Minibatch Loss ---- Train = 0.039342; Test = 0.030707\n",
      "Iter 324, Minibatch Loss ---- Train = 0.037823; Test = 0.030355\n",
      "Iter 325, Minibatch Loss ---- Train = 0.028877; Test = 0.030867\n",
      "Iter 326, Minibatch Loss ---- Train = 0.036540; Test = 0.030816\n",
      "Iter 327, Minibatch Loss ---- Train = 0.041616; Test = 0.030628\n",
      "Iter 328, Minibatch Loss ---- Train = 0.037223; Test = 0.030264\n",
      "Iter 329, Minibatch Loss ---- Train = 0.036569; Test = 0.030941\n",
      "Iter 330, Minibatch Loss ---- Train = 0.039413; Test = 0.030295\n",
      "Iter 331, Minibatch Loss ---- Train = 0.026514; Test = 0.030179\n",
      "Iter 332, Minibatch Loss ---- Train = 0.036560; Test = 0.030614\n",
      "Iter 333, Minibatch Loss ---- Train = 0.037552; Test = 0.031025\n",
      "Iter 334, Minibatch Loss ---- Train = 0.035734; Test = 0.030253\n",
      "Iter 335, Minibatch Loss ---- Train = 0.040215; Test = 0.030835\n",
      "Iter 336, Minibatch Loss ---- Train = 0.030118; Test = 0.030511\n",
      "Iter 337, Minibatch Loss ---- Train = 0.032108; Test = 0.030383\n",
      "Iter 338, Minibatch Loss ---- Train = 0.042899; Test = 0.030018\n",
      "Iter 339, Minibatch Loss ---- Train = 0.035016; Test = 0.030585\n",
      "Iter 340, Minibatch Loss ---- Train = 0.031574; Test = 0.030840\n",
      "Iter 341, Minibatch Loss ---- Train = 0.029232; Test = 0.030339\n",
      "Iter 342, Minibatch Loss ---- Train = 0.038381; Test = 0.030185\n",
      "Iter 343, Minibatch Loss ---- Train = 0.037172; Test = 0.030796\n",
      "Iter 344, Minibatch Loss ---- Train = 0.040869; Test = 0.030255\n",
      "Iter 345, Minibatch Loss ---- Train = 0.035629; Test = 0.030802\n",
      "Iter 346, Minibatch Loss ---- Train = 0.032804; Test = 0.030444\n",
      "Iter 347, Minibatch Loss ---- Train = 0.051064; Test = 0.030564\n",
      "Iter 348, Minibatch Loss ---- Train = 0.039016; Test = 0.029949\n",
      "Iter 349, Minibatch Loss ---- Train = 0.029307; Test = 0.030490\n",
      "Iter 350, Minibatch Loss ---- Train = 0.034701; Test = 0.030745\n",
      "Iter 351, Minibatch Loss ---- Train = 0.035088; Test = 0.030533\n",
      "Iter 352, Minibatch Loss ---- Train = 0.044316; Test = 0.030020\n",
      "Iter 353, Minibatch Loss ---- Train = 0.043845; Test = 0.031012\n",
      "Iter 354, Minibatch Loss ---- Train = 0.039516; Test = 0.030248\n",
      "Iter 355, Minibatch Loss ---- Train = 0.036305; Test = 0.030906\n",
      "Iter 356, Minibatch Loss ---- Train = 0.035948; Test = 0.030289\n",
      "Iter 357, Minibatch Loss ---- Train = 0.034580; Test = 0.030705\n",
      "Iter 358, Minibatch Loss ---- Train = 0.034791; Test = 0.030174\n",
      "Iter 359, Minibatch Loss ---- Train = 0.047806; Test = 0.030432\n",
      "Iter 360, Minibatch Loss ---- Train = 0.029978; Test = 0.030279\n",
      "Iter 361, Minibatch Loss ---- Train = 0.039698; Test = 0.030276\n",
      "Iter 362, Minibatch Loss ---- Train = 0.040106; Test = 0.030275\n",
      "Iter 363, Minibatch Loss ---- Train = 0.029361; Test = 0.030222\n",
      "Iter 364, Minibatch Loss ---- Train = 0.037779; Test = 0.030114\n",
      "Iter 365, Minibatch Loss ---- Train = 0.026580; Test = 0.030570\n",
      "Iter 366, Minibatch Loss ---- Train = 0.034683; Test = 0.030261\n",
      "Iter 367, Minibatch Loss ---- Train = 0.037398; Test = 0.030651\n",
      "Iter 368, Minibatch Loss ---- Train = 0.030173; Test = 0.030232\n",
      "Iter 369, Minibatch Loss ---- Train = 0.042877; Test = 0.030432\n",
      "Iter 370, Minibatch Loss ---- Train = 0.039337; Test = 0.030091\n",
      "Iter 371, Minibatch Loss ---- Train = 0.029414; Test = 0.030265\n",
      "Iter 372, Minibatch Loss ---- Train = 0.043202; Test = 0.030490\n",
      "Iter 373, Minibatch Loss ---- Train = 0.029691; Test = 0.030232\n",
      "Iter 374, Minibatch Loss ---- Train = 0.041089; Test = 0.030185\n",
      "Iter 375, Minibatch Loss ---- Train = 0.040621; Test = 0.030589\n",
      "Iter 376, Minibatch Loss ---- Train = 0.025906; Test = 0.030192\n",
      "Iter 377, Minibatch Loss ---- Train = 0.026260; Test = 0.029698\n",
      "Iter 378, Minibatch Loss ---- Train = 0.037893; Test = 0.030492\n",
      "Iter 379, Minibatch Loss ---- Train = 0.035072; Test = 0.030334\n",
      "Iter 380, Minibatch Loss ---- Train = 0.031630; Test = 0.029936\n",
      "Iter 381, Minibatch Loss ---- Train = 0.049397; Test = 0.030236\n",
      "Iter 382, Minibatch Loss ---- Train = 0.029643; Test = 0.030395\n",
      "Iter 383, Minibatch Loss ---- Train = 0.032052; Test = 0.030016\n",
      "Iter 384, Minibatch Loss ---- Train = 0.033506; Test = 0.030088\n",
      "Iter 385, Minibatch Loss ---- Train = 0.031926; Test = 0.030417\n",
      "Iter 386, Minibatch Loss ---- Train = 0.029757; Test = 0.030407\n",
      "Iter 387, Minibatch Loss ---- Train = 0.037025; Test = 0.029995\n",
      "Iter 388, Minibatch Loss ---- Train = 0.044382; Test = 0.029859\n",
      "Iter 389, Minibatch Loss ---- Train = 0.042436; Test = 0.030481\n",
      "Iter 390, Minibatch Loss ---- Train = 0.030254; Test = 0.030055\n",
      "Iter 391, Minibatch Loss ---- Train = 0.032763; Test = 0.030302\n",
      "Iter 392, Minibatch Loss ---- Train = 0.030412; Test = 0.030055\n",
      "Iter 393, Minibatch Loss ---- Train = 0.032430; Test = 0.030208\n",
      "Iter 394, Minibatch Loss ---- Train = 0.030307; Test = 0.030157\n",
      "Iter 395, Minibatch Loss ---- Train = 0.035278; Test = 0.030152\n",
      "Iter 396, Minibatch Loss ---- Train = 0.041569; Test = 0.029778\n",
      "Iter 397, Minibatch Loss ---- Train = 0.037643; Test = 0.030598\n",
      "Iter 398, Minibatch Loss ---- Train = 0.055584; Test = 0.029820\n",
      "Iter 399, Minibatch Loss ---- Train = 0.046358; Test = 0.030589\n",
      "Iter 400, Minibatch Loss ---- Train = 0.033011; Test = 0.030046\n",
      "Iter 401, Minibatch Loss ---- Train = 0.031475; Test = 0.029992\n",
      "Iter 402, Minibatch Loss ---- Train = 0.034408; Test = 0.029763\n",
      "Iter 403, Minibatch Loss ---- Train = 0.035615; Test = 0.030986\n",
      "Iter 404, Minibatch Loss ---- Train = 0.021974; Test = 0.030154\n",
      "Iter 405, Minibatch Loss ---- Train = 0.030109; Test = 0.029784\n",
      "Iter 406, Minibatch Loss ---- Train = 0.030344; Test = 0.030229\n",
      "Iter 407, Minibatch Loss ---- Train = 0.019864; Test = 0.029850\n",
      "Iter 408, Minibatch Loss ---- Train = 0.037680; Test = 0.030144\n",
      "Iter 409, Minibatch Loss ---- Train = 0.039052; Test = 0.030418\n",
      "Iter 410, Minibatch Loss ---- Train = 0.032441; Test = 0.029823\n",
      "Iter 411, Minibatch Loss ---- Train = 0.034731; Test = 0.030052\n",
      "Iter 412, Minibatch Loss ---- Train = 0.035817; Test = 0.030108\n",
      "Iter 413, Minibatch Loss ---- Train = 0.028201; Test = 0.029866\n",
      "Iter 414, Minibatch Loss ---- Train = 0.045027; Test = 0.030169\n",
      "Iter 415, Minibatch Loss ---- Train = 0.036493; Test = 0.030059\n",
      "Iter 416, Minibatch Loss ---- Train = 0.031509; Test = 0.029960\n",
      "Iter 417, Minibatch Loss ---- Train = 0.034570; Test = 0.030291\n",
      "Iter 418, Minibatch Loss ---- Train = 0.031489; Test = 0.030051\n",
      "Iter 419, Minibatch Loss ---- Train = 0.036210; Test = 0.029954\n",
      "Iter 420, Minibatch Loss ---- Train = 0.043692; Test = 0.029836\n",
      "Iter 421, Minibatch Loss ---- Train = 0.047134; Test = 0.030015\n",
      "Iter 422, Minibatch Loss ---- Train = 0.030803; Test = 0.029809\n",
      "Iter 423, Minibatch Loss ---- Train = 0.030768; Test = 0.030052\n",
      "Iter 424, Minibatch Loss ---- Train = 0.047089; Test = 0.029702\n",
      "Iter 425, Minibatch Loss ---- Train = 0.027148; Test = 0.030285\n",
      "Iter 426, Minibatch Loss ---- Train = 0.027767; Test = 0.030145\n",
      "Iter 427, Minibatch Loss ---- Train = 0.025502; Test = 0.029707\n",
      "Iter 428, Minibatch Loss ---- Train = 0.043870; Test = 0.029913\n",
      "Iter 429, Minibatch Loss ---- Train = 0.028821; Test = 0.030488\n",
      "Iter 430, Minibatch Loss ---- Train = 0.026436; Test = 0.029969\n",
      "Iter 431, Minibatch Loss ---- Train = 0.032606; Test = 0.029958\n",
      "Iter 432, Minibatch Loss ---- Train = 0.037645; Test = 0.029779\n",
      "Iter 433, Minibatch Loss ---- Train = 0.034335; Test = 0.030378\n",
      "Iter 434, Minibatch Loss ---- Train = 0.040771; Test = 0.029714\n",
      "Iter 435, Minibatch Loss ---- Train = 0.037249; Test = 0.030187\n",
      "Iter 436, Minibatch Loss ---- Train = 0.033786; Test = 0.029881\n",
      "Iter 437, Minibatch Loss ---- Train = 0.033479; Test = 0.029997\n",
      "Iter 438, Minibatch Loss ---- Train = 0.034540; Test = 0.029834\n",
      "Iter 439, Minibatch Loss ---- Train = 0.039551; Test = 0.030073\n",
      "Iter 440, Minibatch Loss ---- Train = 0.037205; Test = 0.029599\n",
      "Iter 441, Minibatch Loss ---- Train = 0.038572; Test = 0.030241\n",
      "Iter 442, Minibatch Loss ---- Train = 0.041977; Test = 0.029887\n",
      "Iter 443, Minibatch Loss ---- Train = 0.035413; Test = 0.029551\n",
      "Iter 444, Minibatch Loss ---- Train = 0.043929; Test = 0.029961\n",
      "Iter 445, Minibatch Loss ---- Train = 0.039694; Test = 0.029991\n",
      "Iter 446, Minibatch Loss ---- Train = 0.027571; Test = 0.029698\n",
      "Iter 447, Minibatch Loss ---- Train = 0.021868; Test = 0.029653\n",
      "Iter 448, Minibatch Loss ---- Train = 0.044562; Test = 0.029587\n",
      "Iter 449, Minibatch Loss ---- Train = 0.037717; Test = 0.030897\n",
      "Iter 450, Minibatch Loss ---- Train = 0.036232; Test = 0.029766\n",
      "Iter 451, Minibatch Loss ---- Train = 0.040254; Test = 0.029638\n",
      "Iter 452, Minibatch Loss ---- Train = 0.038240; Test = 0.029986\n",
      "Iter 453, Minibatch Loss ---- Train = 0.023724; Test = 0.029590\n",
      "Iter 454, Minibatch Loss ---- Train = 0.040277; Test = 0.029710\n",
      "Iter 455, Minibatch Loss ---- Train = 0.030907; Test = 0.029877\n",
      "Iter 456, Minibatch Loss ---- Train = 0.033968; Test = 0.029878\n",
      "Iter 457, Minibatch Loss ---- Train = 0.037985; Test = 0.029947\n",
      "Iter 458, Minibatch Loss ---- Train = 0.032383; Test = 0.029738\n",
      "Iter 459, Minibatch Loss ---- Train = 0.043936; Test = 0.029695\n",
      "Iter 460, Minibatch Loss ---- Train = 0.023848; Test = 0.029739\n",
      "Iter 461, Minibatch Loss ---- Train = 0.042235; Test = 0.029919\n",
      "Iter 462, Minibatch Loss ---- Train = 0.036953; Test = 0.029574\n",
      "Iter 463, Minibatch Loss ---- Train = 0.031440; Test = 0.029477\n",
      "Iter 464, Minibatch Loss ---- Train = 0.029198; Test = 0.029777\n",
      "Iter 465, Minibatch Loss ---- Train = 0.028736; Test = 0.030230\n",
      "Iter 466, Minibatch Loss ---- Train = 0.035798; Test = 0.029697\n",
      "Iter 467, Minibatch Loss ---- Train = 0.027347; Test = 0.029685\n",
      "Iter 468, Minibatch Loss ---- Train = 0.034834; Test = 0.029625\n",
      "Iter 469, Minibatch Loss ---- Train = 0.031480; Test = 0.029771\n",
      "Iter 470, Minibatch Loss ---- Train = 0.052010; Test = 0.029567\n",
      "Iter 471, Minibatch Loss ---- Train = 0.034476; Test = 0.029978\n",
      "Iter 472, Minibatch Loss ---- Train = 0.038615; Test = 0.029690\n",
      "Iter 473, Minibatch Loss ---- Train = 0.028865; Test = 0.029620\n",
      "Iter 474, Minibatch Loss ---- Train = 0.037299; Test = 0.029530\n",
      "Iter 475, Minibatch Loss ---- Train = 0.054040; Test = 0.030320\n",
      "Iter 476, Minibatch Loss ---- Train = 0.037659; Test = 0.029399\n",
      "Iter 477, Minibatch Loss ---- Train = 0.036513; Test = 0.029420\n",
      "Iter 478, Minibatch Loss ---- Train = 0.037695; Test = 0.029656\n",
      "Iter 479, Minibatch Loss ---- Train = 0.050561; Test = 0.030278\n",
      "Iter 480, Minibatch Loss ---- Train = 0.042663; Test = 0.029370\n",
      "Iter 481, Minibatch Loss ---- Train = 0.032798; Test = 0.029498\n",
      "Iter 482, Minibatch Loss ---- Train = 0.041280; Test = 0.029782\n",
      "Iter 483, Minibatch Loss ---- Train = 0.042986; Test = 0.030165\n",
      "Iter 484, Minibatch Loss ---- Train = 0.039887; Test = 0.029244\n",
      "Iter 485, Minibatch Loss ---- Train = 0.036479; Test = 0.029760\n",
      "Iter 486, Minibatch Loss ---- Train = 0.041050; Test = 0.029361\n",
      "Iter 487, Minibatch Loss ---- Train = 0.032245; Test = 0.030140\n",
      "Iter 488, Minibatch Loss ---- Train = 0.030353; Test = 0.029537\n",
      "Iter 489, Minibatch Loss ---- Train = 0.028855; Test = 0.029614\n",
      "Iter 490, Minibatch Loss ---- Train = 0.038086; Test = 0.029417\n",
      "Iter 491, Minibatch Loss ---- Train = 0.037133; Test = 0.030002\n",
      "Iter 492, Minibatch Loss ---- Train = 0.030612; Test = 0.029442\n",
      "Iter 493, Minibatch Loss ---- Train = 0.036039; Test = 0.029869\n",
      "Iter 494, Minibatch Loss ---- Train = 0.039123; Test = 0.029207\n",
      "Iter 495, Minibatch Loss ---- Train = 0.034153; Test = 0.029726\n",
      "Iter 496, Minibatch Loss ---- Train = 0.024116; Test = 0.029753\n",
      "Iter 497, Minibatch Loss ---- Train = 0.029504; Test = 0.029660\n",
      "Iter 498, Minibatch Loss ---- Train = 0.032676; Test = 0.029836\n",
      "Iter 499, Minibatch Loss ---- Train = 0.034272; Test = 0.029875\n",
      "Iter 500, Minibatch Loss ---- Train = 0.039948; Test = 0.029431\n",
      "Iter 501, Minibatch Loss ---- Train = 0.037733; Test = 0.029773\n",
      "Iter 502, Minibatch Loss ---- Train = 0.035916; Test = 0.029413\n",
      "Iter 503, Minibatch Loss ---- Train = 0.030798; Test = 0.029666\n",
      "Iter 504, Minibatch Loss ---- Train = 0.028993; Test = 0.029650\n",
      "Iter 505, Minibatch Loss ---- Train = 0.028407; Test = 0.029353\n",
      "Iter 506, Minibatch Loss ---- Train = 0.031260; Test = 0.029792\n",
      "Iter 507, Minibatch Loss ---- Train = 0.030458; Test = 0.029506\n",
      "Iter 508, Minibatch Loss ---- Train = 0.036059; Test = 0.029209\n",
      "Iter 509, Minibatch Loss ---- Train = 0.039915; Test = 0.029764\n",
      "Iter 510, Minibatch Loss ---- Train = 0.030127; Test = 0.029455\n",
      "Iter 511, Minibatch Loss ---- Train = 0.034904; Test = 0.029940\n",
      "Iter 512, Minibatch Loss ---- Train = 0.031649; Test = 0.029370\n",
      "Iter 513, Minibatch Loss ---- Train = 0.026466; Test = 0.029451\n",
      "Iter 514, Minibatch Loss ---- Train = 0.031493; Test = 0.029899\n",
      "Iter 515, Minibatch Loss ---- Train = 0.031742; Test = 0.029370\n",
      "Iter 516, Minibatch Loss ---- Train = 0.025118; Test = 0.029505\n",
      "Iter 517, Minibatch Loss ---- Train = 0.031144; Test = 0.029699\n",
      "Iter 518, Minibatch Loss ---- Train = 0.025699; Test = 0.029610\n",
      "Iter 519, Minibatch Loss ---- Train = 0.047013; Test = 0.029454\n",
      "Iter 520, Minibatch Loss ---- Train = 0.051090; Test = 0.029081\n",
      "Iter 521, Minibatch Loss ---- Train = 0.030959; Test = 0.030111\n",
      "Iter 522, Minibatch Loss ---- Train = 0.042641; Test = 0.029332\n",
      "Iter 523, Minibatch Loss ---- Train = 0.035981; Test = 0.029725\n",
      "Iter 524, Minibatch Loss ---- Train = 0.037985; Test = 0.029351\n",
      "Iter 525, Minibatch Loss ---- Train = 0.038209; Test = 0.029614\n",
      "Iter 526, Minibatch Loss ---- Train = 0.041385; Test = 0.029403\n",
      "Iter 527, Minibatch Loss ---- Train = 0.040249; Test = 0.029552\n",
      "Iter 528, Minibatch Loss ---- Train = 0.027473; Test = 0.029176\n",
      "Iter 529, Minibatch Loss ---- Train = 0.031694; Test = 0.028985\n",
      "Iter 530, Minibatch Loss ---- Train = 0.031924; Test = 0.029772\n",
      "Iter 531, Minibatch Loss ---- Train = 0.029293; Test = 0.029382\n",
      "Iter 532, Minibatch Loss ---- Train = 0.039722; Test = 0.029152\n",
      "Iter 533, Minibatch Loss ---- Train = 0.045505; Test = 0.030142\n",
      "Iter 534, Minibatch Loss ---- Train = 0.035011; Test = 0.029050\n",
      "Iter 535, Minibatch Loss ---- Train = 0.028115; Test = 0.029190\n",
      "Iter 536, Minibatch Loss ---- Train = 0.026275; Test = 0.029689\n",
      "Iter 537, Minibatch Loss ---- Train = 0.038249; Test = 0.029543\n",
      "Iter 538, Minibatch Loss ---- Train = 0.030007; Test = 0.029389\n",
      "Iter 539, Minibatch Loss ---- Train = 0.041658; Test = 0.029527\n",
      "Iter 540, Minibatch Loss ---- Train = 0.044261; Test = 0.029251\n",
      "Iter 541, Minibatch Loss ---- Train = 0.027534; Test = 0.029618\n",
      "Iter 542, Minibatch Loss ---- Train = 0.026366; Test = 0.029737\n",
      "Iter 543, Minibatch Loss ---- Train = 0.042056; Test = 0.029274\n",
      "Iter 544, Minibatch Loss ---- Train = 0.040492; Test = 0.029189\n",
      "Iter 545, Minibatch Loss ---- Train = 0.034060; Test = 0.028967\n",
      "Iter 546, Minibatch Loss ---- Train = 0.036968; Test = 0.029675\n",
      "Iter 547, Minibatch Loss ---- Train = 0.045294; Test = 0.029651\n",
      "Iter 548, Minibatch Loss ---- Train = 0.030554; Test = 0.029206\n",
      "Iter 549, Minibatch Loss ---- Train = 0.029011; Test = 0.029150\n",
      "Iter 550, Minibatch Loss ---- Train = 0.036168; Test = 0.029650\n",
      "Iter 551, Minibatch Loss ---- Train = 0.023358; Test = 0.029181\n",
      "Iter 552, Minibatch Loss ---- Train = 0.041809; Test = 0.028937\n",
      "Iter 553, Minibatch Loss ---- Train = 0.038596; Test = 0.030680\n",
      "Iter 554, Minibatch Loss ---- Train = 0.035789; Test = 0.028959\n",
      "Iter 555, Minibatch Loss ---- Train = 0.044723; Test = 0.029356\n",
      "Iter 556, Minibatch Loss ---- Train = 0.035511; Test = 0.029267\n",
      "Iter 557, Minibatch Loss ---- Train = 0.036700; Test = 0.029121\n",
      "Iter 558, Minibatch Loss ---- Train = 0.032551; Test = 0.029316\n",
      "Iter 559, Minibatch Loss ---- Train = 0.028079; Test = 0.029555\n",
      "Iter 560, Minibatch Loss ---- Train = 0.036585; Test = 0.029246\n",
      "Iter 561, Minibatch Loss ---- Train = 0.030608; Test = 0.029332\n",
      "Iter 562, Minibatch Loss ---- Train = 0.026914; Test = 0.029111\n",
      "Iter 563, Minibatch Loss ---- Train = 0.046504; Test = 0.029682\n",
      "Iter 564, Minibatch Loss ---- Train = 0.033990; Test = 0.028997\n",
      "Iter 565, Minibatch Loss ---- Train = 0.038816; Test = 0.029428\n",
      "Iter 566, Minibatch Loss ---- Train = 0.025295; Test = 0.029406\n",
      "Iter 567, Minibatch Loss ---- Train = 0.038386; Test = 0.029157\n",
      "Iter 568, Minibatch Loss ---- Train = 0.030570; Test = 0.029234\n",
      "Iter 569, Minibatch Loss ---- Train = 0.027972; Test = 0.029035\n",
      "Iter 570, Minibatch Loss ---- Train = 0.042079; Test = 0.028697\n",
      "Iter 571, Minibatch Loss ---- Train = 0.039290; Test = 0.030210\n",
      "Iter 572, Minibatch Loss ---- Train = 0.037328; Test = 0.029064\n",
      "Iter 573, Minibatch Loss ---- Train = 0.037058; Test = 0.029519\n",
      "Iter 574, Minibatch Loss ---- Train = 0.026653; Test = 0.029280\n",
      "Iter 575, Minibatch Loss ---- Train = 0.037025; Test = 0.029354\n",
      "Iter 576, Minibatch Loss ---- Train = 0.035969; Test = 0.028908\n",
      "Iter 577, Minibatch Loss ---- Train = 0.035239; Test = 0.029541\n",
      "Iter 578, Minibatch Loss ---- Train = 0.031051; Test = 0.029222\n",
      "Iter 579, Minibatch Loss ---- Train = 0.033688; Test = 0.029326\n",
      "Iter 580, Minibatch Loss ---- Train = 0.025475; Test = 0.029311\n",
      "Iter 581, Minibatch Loss ---- Train = 0.030788; Test = 0.029195\n",
      "Iter 582, Minibatch Loss ---- Train = 0.032534; Test = 0.029169\n",
      "Iter 583, Minibatch Loss ---- Train = 0.037267; Test = 0.029487\n",
      "Iter 584, Minibatch Loss ---- Train = 0.023001; Test = 0.029068\n",
      "Iter 585, Minibatch Loss ---- Train = 0.031565; Test = 0.029206\n",
      "Iter 586, Minibatch Loss ---- Train = 0.029929; Test = 0.029435\n",
      "Iter 587, Minibatch Loss ---- Train = 0.041762; Test = 0.029340\n",
      "Iter 588, Minibatch Loss ---- Train = 0.044980; Test = 0.028588\n",
      "Iter 589, Minibatch Loss ---- Train = 0.031509; Test = 0.029114\n",
      "Iter 590, Minibatch Loss ---- Train = 0.033845; Test = 0.029911\n",
      "Iter 591, Minibatch Loss ---- Train = 0.033768; Test = 0.029603\n",
      "Iter 592, Minibatch Loss ---- Train = 0.028966; Test = 0.029255\n",
      "Iter 593, Minibatch Loss ---- Train = 0.031785; Test = 0.029826\n",
      "Iter 594, Minibatch Loss ---- Train = 0.029643; Test = 0.029584\n",
      "Iter 595, Minibatch Loss ---- Train = 0.037774; Test = 0.029522\n",
      "Iter 596, Minibatch Loss ---- Train = 0.031289; Test = 0.029000\n",
      "Iter 597, Minibatch Loss ---- Train = 0.029746; Test = 0.029272\n",
      "Iter 598, Minibatch Loss ---- Train = 0.040422; Test = 0.029421\n",
      "Iter 599, Minibatch Loss ---- Train = 0.031949; Test = 0.029375\n",
      "Iter 600, Minibatch Loss ---- Train = 0.034171; Test = 0.028999\n",
      "Iter 601, Minibatch Loss ---- Train = 0.035759; Test = 0.029425\n",
      "Iter 602, Minibatch Loss ---- Train = 0.037136; Test = 0.029100\n",
      "Iter 603, Minibatch Loss ---- Train = 0.030946; Test = 0.029227\n",
      "Iter 604, Minibatch Loss ---- Train = 0.040849; Test = 0.028846\n",
      "Iter 605, Minibatch Loss ---- Train = 0.038379; Test = 0.029724\n",
      "Iter 606, Minibatch Loss ---- Train = 0.037654; Test = 0.028951\n",
      "Iter 607, Minibatch Loss ---- Train = 0.026982; Test = 0.029147\n",
      "Iter 608, Minibatch Loss ---- Train = 0.040851; Test = 0.029020\n",
      "Iter 609, Minibatch Loss ---- Train = 0.037137; Test = 0.030090\n",
      "Iter 610, Minibatch Loss ---- Train = 0.035651; Test = 0.028895\n",
      "Iter 611, Minibatch Loss ---- Train = 0.033855; Test = 0.029262\n",
      "Iter 612, Minibatch Loss ---- Train = 0.028361; Test = 0.029362\n",
      "Iter 613, Minibatch Loss ---- Train = 0.036202; Test = 0.029188\n",
      "Iter 614, Minibatch Loss ---- Train = 0.034627; Test = 0.028922\n",
      "Iter 615, Minibatch Loss ---- Train = 0.046132; Test = 0.029088\n",
      "Iter 616, Minibatch Loss ---- Train = 0.028346; Test = 0.028966\n",
      "Iter 617, Minibatch Loss ---- Train = 0.031832; Test = 0.029220\n",
      "Iter 618, Minibatch Loss ---- Train = 0.044819; Test = 0.028898\n",
      "Iter 619, Minibatch Loss ---- Train = 0.038107; Test = 0.029477\n",
      "Iter 620, Minibatch Loss ---- Train = 0.030254; Test = 0.029006\n",
      "Iter 621, Minibatch Loss ---- Train = 0.024335; Test = 0.028702\n",
      "Iter 622, Minibatch Loss ---- Train = 0.046244; Test = 0.028854\n",
      "Iter 623, Minibatch Loss ---- Train = 0.033181; Test = 0.029895\n",
      "Iter 624, Minibatch Loss ---- Train = 0.027023; Test = 0.028857\n",
      "Iter 625, Minibatch Loss ---- Train = 0.023256; Test = 0.028665\n",
      "Iter 626, Minibatch Loss ---- Train = 0.037535; Test = 0.028934\n",
      "Iter 627, Minibatch Loss ---- Train = 0.033439; Test = 0.029265\n",
      "Iter 628, Minibatch Loss ---- Train = 0.037360; Test = 0.028864\n",
      "Iter 629, Minibatch Loss ---- Train = 0.029065; Test = 0.029211\n",
      "Iter 630, Minibatch Loss ---- Train = 0.032966; Test = 0.029006\n",
      "Iter 631, Minibatch Loss ---- Train = 0.029095; Test = 0.029016\n",
      "Iter 632, Minibatch Loss ---- Train = 0.042160; Test = 0.028797\n",
      "Iter 633, Minibatch Loss ---- Train = 0.039160; Test = 0.029267\n",
      "Iter 634, Minibatch Loss ---- Train = 0.036517; Test = 0.028932\n",
      "Iter 635, Minibatch Loss ---- Train = 0.034144; Test = 0.029030\n",
      "Iter 636, Minibatch Loss ---- Train = 0.026781; Test = 0.028994\n",
      "Iter 637, Minibatch Loss ---- Train = 0.039864; Test = 0.028973\n",
      "Iter 638, Minibatch Loss ---- Train = 0.041289; Test = 0.028742\n",
      "Iter 639, Minibatch Loss ---- Train = 0.036314; Test = 0.029309\n",
      "Iter 640, Minibatch Loss ---- Train = 0.029994; Test = 0.028950\n",
      "Iter 641, Minibatch Loss ---- Train = 0.023777; Test = 0.028782\n",
      "Iter 642, Minibatch Loss ---- Train = 0.043221; Test = 0.028845\n",
      "Iter 643, Minibatch Loss ---- Train = 0.030153; Test = 0.029436\n",
      "Iter 644, Minibatch Loss ---- Train = 0.027612; Test = 0.029033\n",
      "Iter 645, Minibatch Loss ---- Train = 0.036237; Test = 0.028963\n",
      "Iter 646, Minibatch Loss ---- Train = 0.035933; Test = 0.028942\n",
      "Iter 647, Minibatch Loss ---- Train = 0.026415; Test = 0.029077\n",
      "Iter 648, Minibatch Loss ---- Train = 0.037428; Test = 0.029065\n",
      "Iter 649, Minibatch Loss ---- Train = 0.037261; Test = 0.028800\n",
      "Iter 650, Minibatch Loss ---- Train = 0.038060; Test = 0.028602\n",
      "Iter 651, Minibatch Loss ---- Train = 0.032516; Test = 0.029449\n",
      "Iter 652, Minibatch Loss ---- Train = 0.025670; Test = 0.029118\n",
      "Iter 653, Minibatch Loss ---- Train = 0.022601; Test = 0.028686\n",
      "Iter 654, Minibatch Loss ---- Train = 0.027326; Test = 0.029454\n",
      "Iter 655, Minibatch Loss ---- Train = 0.040587; Test = 0.028792\n",
      "Iter 656, Minibatch Loss ---- Train = 0.037078; Test = 0.028618\n",
      "Iter 657, Minibatch Loss ---- Train = 0.035200; Test = 0.029468\n",
      "Iter 658, Minibatch Loss ---- Train = 0.028426; Test = 0.028909\n",
      "Iter 659, Minibatch Loss ---- Train = 0.029032; Test = 0.029033\n",
      "Iter 660, Minibatch Loss ---- Train = 0.031109; Test = 0.029332\n",
      "Iter 661, Minibatch Loss ---- Train = 0.037578; Test = 0.029365\n",
      "Iter 662, Minibatch Loss ---- Train = 0.039168; Test = 0.028806\n",
      "Iter 663, Minibatch Loss ---- Train = 0.036582; Test = 0.029215\n",
      "Iter 664, Minibatch Loss ---- Train = 0.028150; Test = 0.028958\n",
      "Iter 665, Minibatch Loss ---- Train = 0.032764; Test = 0.028832\n",
      "Iter 666, Minibatch Loss ---- Train = 0.037539; Test = 0.028762\n",
      "Iter 667, Minibatch Loss ---- Train = 0.041898; Test = 0.029415\n",
      "Iter 668, Minibatch Loss ---- Train = 0.032007; Test = 0.028736\n",
      "Iter 669, Minibatch Loss ---- Train = 0.026001; Test = 0.028751\n",
      "Iter 670, Minibatch Loss ---- Train = 0.029377; Test = 0.029072\n",
      "Iter 671, Minibatch Loss ---- Train = 0.027195; Test = 0.028985\n",
      "Iter 672, Minibatch Loss ---- Train = 0.033071; Test = 0.028864\n",
      "Iter 673, Minibatch Loss ---- Train = 0.033832; Test = 0.029160\n",
      "Iter 674, Minibatch Loss ---- Train = 0.035606; Test = 0.028811\n",
      "Iter 675, Minibatch Loss ---- Train = 0.029561; Test = 0.028996\n",
      "Iter 676, Minibatch Loss ---- Train = 0.041967; Test = 0.028828\n",
      "Iter 677, Minibatch Loss ---- Train = 0.041804; Test = 0.029581\n",
      "Iter 678, Minibatch Loss ---- Train = 0.031651; Test = 0.028628\n",
      "Iter 679, Minibatch Loss ---- Train = 0.038110; Test = 0.029359\n",
      "Iter 680, Minibatch Loss ---- Train = 0.030709; Test = 0.029058\n",
      "Iter 681, Minibatch Loss ---- Train = 0.030166; Test = 0.029007\n",
      "Iter 682, Minibatch Loss ---- Train = 0.037260; Test = 0.028816\n",
      "Iter 683, Minibatch Loss ---- Train = 0.038041; Test = 0.028995\n",
      "Iter 684, Minibatch Loss ---- Train = 0.032609; Test = 0.028985\n",
      "Iter 685, Minibatch Loss ---- Train = 0.041710; Test = 0.028967\n",
      "Iter 686, Minibatch Loss ---- Train = 0.037434; Test = 0.028702\n",
      "Iter 687, Minibatch Loss ---- Train = 0.050810; Test = 0.029215\n",
      "Iter 688, Minibatch Loss ---- Train = 0.029178; Test = 0.028811\n",
      "Iter 689, Minibatch Loss ---- Train = 0.051661; Test = 0.028891\n",
      "Iter 690, Minibatch Loss ---- Train = 0.032484; Test = 0.028630\n",
      "Iter 691, Minibatch Loss ---- Train = 0.031336; Test = 0.028902\n",
      "Iter 692, Minibatch Loss ---- Train = 0.030752; Test = 0.028674\n",
      "Iter 693, Minibatch Loss ---- Train = 0.029057; Test = 0.028880\n",
      "Iter 694, Minibatch Loss ---- Train = 0.027697; Test = 0.029165\n",
      "Iter 695, Minibatch Loss ---- Train = 0.052064; Test = 0.028951\n",
      "Iter 696, Minibatch Loss ---- Train = 0.037048; Test = 0.028597\n",
      "Iter 697, Minibatch Loss ---- Train = 0.024091; Test = 0.028545\n",
      "Iter 698, Minibatch Loss ---- Train = 0.031429; Test = 0.029264\n",
      "Iter 699, Minibatch Loss ---- Train = 0.030239; Test = 0.028622\n",
      "Iter 700, Minibatch Loss ---- Train = 0.038042; Test = 0.028541\n",
      "Iter 701, Minibatch Loss ---- Train = 0.033690; Test = 0.029208\n",
      "Iter 702, Minibatch Loss ---- Train = 0.038760; Test = 0.028615\n",
      "Iter 703, Minibatch Loss ---- Train = 0.035685; Test = 0.029101\n",
      "Iter 704, Minibatch Loss ---- Train = 0.034527; Test = 0.028795\n",
      "Iter 705, Minibatch Loss ---- Train = 0.034601; Test = 0.028645\n",
      "Iter 706, Minibatch Loss ---- Train = 0.030145; Test = 0.028753\n",
      "Iter 707, Minibatch Loss ---- Train = 0.033934; Test = 0.029024\n",
      "Iter 708, Minibatch Loss ---- Train = 0.044305; Test = 0.028597\n",
      "Iter 709, Minibatch Loss ---- Train = 0.034837; Test = 0.028961\n",
      "Iter 710, Minibatch Loss ---- Train = 0.028397; Test = 0.028827\n",
      "Iter 711, Minibatch Loss ---- Train = 0.029996; Test = 0.028670\n",
      "Iter 712, Minibatch Loss ---- Train = 0.040058; Test = 0.028461\n",
      "Iter 713, Minibatch Loss ---- Train = 0.031864; Test = 0.028877\n",
      "Iter 714, Minibatch Loss ---- Train = 0.027411; Test = 0.029036\n",
      "Iter 715, Minibatch Loss ---- Train = 0.034246; Test = 0.028714\n",
      "Iter 716, Minibatch Loss ---- Train = 0.040260; Test = 0.028483\n",
      "Iter 717, Minibatch Loss ---- Train = 0.034420; Test = 0.028806\n",
      "Iter 718, Minibatch Loss ---- Train = 0.034828; Test = 0.028971\n",
      "Iter 719, Minibatch Loss ---- Train = 0.036453; Test = 0.028870\n",
      "Iter 720, Minibatch Loss ---- Train = 0.028231; Test = 0.028614\n",
      "Iter 721, Minibatch Loss ---- Train = 0.038357; Test = 0.028723\n",
      "Iter 722, Minibatch Loss ---- Train = 0.038979; Test = 0.028802\n",
      "Iter 723, Minibatch Loss ---- Train = 0.026166; Test = 0.028856\n",
      "Iter 724, Minibatch Loss ---- Train = 0.035440; Test = 0.028676\n",
      "Iter 725, Minibatch Loss ---- Train = 0.030137; Test = 0.029010\n",
      "Iter 726, Minibatch Loss ---- Train = 0.034299; Test = 0.028757\n",
      "Iter 727, Minibatch Loss ---- Train = 0.035582; Test = 0.028725\n",
      "Iter 728, Minibatch Loss ---- Train = 0.020193; Test = 0.029115\n",
      "Iter 729, Minibatch Loss ---- Train = 0.021099; Test = 0.028403\n",
      "Iter 730, Minibatch Loss ---- Train = 0.039943; Test = 0.028291\n",
      "Iter 731, Minibatch Loss ---- Train = 0.034799; Test = 0.029436\n",
      "Iter 732, Minibatch Loss ---- Train = 0.026272; Test = 0.028617\n",
      "Iter 733, Minibatch Loss ---- Train = 0.048496; Test = 0.028744\n",
      "Iter 734, Minibatch Loss ---- Train = 0.026840; Test = 0.028835\n",
      "Iter 735, Minibatch Loss ---- Train = 0.037361; Test = 0.028813\n",
      "Iter 736, Minibatch Loss ---- Train = 0.023697; Test = 0.028801\n",
      "Iter 737, Minibatch Loss ---- Train = 0.035795; Test = 0.028527\n",
      "Iter 738, Minibatch Loss ---- Train = 0.034902; Test = 0.028518\n",
      "Iter 739, Minibatch Loss ---- Train = 0.032509; Test = 0.029190\n",
      "Iter 740, Minibatch Loss ---- Train = 0.047547; Test = 0.028684\n",
      "Iter 741, Minibatch Loss ---- Train = 0.037117; Test = 0.028991\n",
      "Iter 742, Minibatch Loss ---- Train = 0.026857; Test = 0.028747\n",
      "Iter 743, Minibatch Loss ---- Train = 0.032194; Test = 0.028729\n",
      "Iter 744, Minibatch Loss ---- Train = 0.028276; Test = 0.028691\n",
      "Iter 745, Minibatch Loss ---- Train = 0.033363; Test = 0.028823\n",
      "Iter 746, Minibatch Loss ---- Train = 0.028394; Test = 0.028745\n",
      "Iter 747, Minibatch Loss ---- Train = 0.041502; Test = 0.028709\n",
      "Iter 748, Minibatch Loss ---- Train = 0.038140; Test = 0.028445\n",
      "Iter 749, Minibatch Loss ---- Train = 0.031885; Test = 0.028651\n",
      "Iter 750, Minibatch Loss ---- Train = 0.036823; Test = 0.028806\n",
      "Iter 751, Minibatch Loss ---- Train = 0.028752; Test = 0.028668\n",
      "Iter 752, Minibatch Loss ---- Train = 0.025661; Test = 0.028820\n",
      "Iter 753, Minibatch Loss ---- Train = 0.036220; Test = 0.028844\n",
      "Iter 754, Minibatch Loss ---- Train = 0.045154; Test = 0.028441\n",
      "Iter 755, Minibatch Loss ---- Train = 0.039956; Test = 0.028956\n",
      "Iter 756, Minibatch Loss ---- Train = 0.043655; Test = 0.028695\n",
      "Iter 757, Minibatch Loss ---- Train = 0.036045; Test = 0.028556\n",
      "Iter 758, Minibatch Loss ---- Train = 0.031952; Test = 0.028468\n",
      "Iter 759, Minibatch Loss ---- Train = 0.041863; Test = 0.029167\n",
      "Iter 760, Minibatch Loss ---- Train = 0.029748; Test = 0.028615\n",
      "Iter 761, Minibatch Loss ---- Train = 0.028942; Test = 0.028636\n",
      "Iter 762, Minibatch Loss ---- Train = 0.039686; Test = 0.028838\n",
      "Iter 763, Minibatch Loss ---- Train = 0.026580; Test = 0.028726\n",
      "Iter 764, Minibatch Loss ---- Train = 0.033118; Test = 0.028543\n",
      "Iter 765, Minibatch Loss ---- Train = 0.032550; Test = 0.029166\n",
      "Iter 766, Minibatch Loss ---- Train = 0.040326; Test = 0.028595\n",
      "Iter 767, Minibatch Loss ---- Train = 0.036295; Test = 0.028820\n",
      "Iter 768, Minibatch Loss ---- Train = 0.033527; Test = 0.028559\n",
      "Iter 769, Minibatch Loss ---- Train = 0.037623; Test = 0.028936\n",
      "Iter 770, Minibatch Loss ---- Train = 0.025611; Test = 0.028866\n",
      "Iter 771, Minibatch Loss ---- Train = 0.028931; Test = 0.028566\n",
      "Iter 772, Minibatch Loss ---- Train = 0.028564; Test = 0.028675\n",
      "Iter 773, Minibatch Loss ---- Train = 0.025225; Test = 0.028691\n",
      "Iter 774, Minibatch Loss ---- Train = 0.032986; Test = 0.028781\n",
      "Iter 775, Minibatch Loss ---- Train = 0.033207; Test = 0.028831\n",
      "Iter 776, Minibatch Loss ---- Train = 0.039132; Test = 0.028480\n",
      "Iter 777, Minibatch Loss ---- Train = 0.041620; Test = 0.029031\n",
      "Iter 778, Minibatch Loss ---- Train = 0.047367; Test = 0.028438\n",
      "Iter 779, Minibatch Loss ---- Train = 0.041973; Test = 0.028750\n",
      "Iter 780, Minibatch Loss ---- Train = 0.043452; Test = 0.028494\n",
      "Iter 781, Minibatch Loss ---- Train = 0.034136; Test = 0.028996\n",
      "Iter 782, Minibatch Loss ---- Train = 0.028910; Test = 0.028459\n",
      "Iter 783, Minibatch Loss ---- Train = 0.036390; Test = 0.028942\n",
      "Iter 784, Minibatch Loss ---- Train = 0.025932; Test = 0.028623\n",
      "Iter 785, Minibatch Loss ---- Train = 0.036857; Test = 0.028814\n",
      "Iter 786, Minibatch Loss ---- Train = 0.034636; Test = 0.028626\n",
      "Iter 787, Minibatch Loss ---- Train = 0.023612; Test = 0.028802\n",
      "Iter 788, Minibatch Loss ---- Train = 0.043162; Test = 0.028939\n",
      "Iter 789, Minibatch Loss ---- Train = 0.032377; Test = 0.029000\n",
      "Iter 790, Minibatch Loss ---- Train = 0.027701; Test = 0.028682\n",
      "Iter 791, Minibatch Loss ---- Train = 0.029407; Test = 0.028920\n",
      "Iter 792, Minibatch Loss ---- Train = 0.037635; Test = 0.028771\n",
      "Iter 793, Minibatch Loss ---- Train = 0.030936; Test = 0.028807\n",
      "Iter 794, Minibatch Loss ---- Train = 0.035425; Test = 0.028651\n",
      "Iter 795, Minibatch Loss ---- Train = 0.035905; Test = 0.028709\n",
      "Iter 796, Minibatch Loss ---- Train = 0.033084; Test = 0.028593\n",
      "Iter 797, Minibatch Loss ---- Train = 0.034404; Test = 0.028949\n",
      "Iter 798, Minibatch Loss ---- Train = 0.043975; Test = 0.028371\n",
      "Iter 799, Minibatch Loss ---- Train = 0.032708; Test = 0.029012\n",
      "[0.69938693888244474, 0.69891636147451153, 0.69951909857932082, 0.70004119916328711, 0.70042083873392691, 0.70029389149717425, 0.70050266039460507, 0.70036022735580816, 0.70022593850862891, 0.70066849861698144]\n",
      "total running time cost:434.460000038s\n",
      "Iter 0, Minibatch Loss ---- Train = 0.692857; Test = 0.579695\n",
      "Iter 1, Minibatch Loss ---- Train = 0.540767; Test = 0.493302\n",
      "Iter 2, Minibatch Loss ---- Train = 0.545827; Test = 0.466915\n",
      "Iter 3, Minibatch Loss ---- Train = 0.567510; Test = 0.442284\n",
      "Iter 4, Minibatch Loss ---- Train = 0.526838; Test = 0.449427\n",
      "Iter 5, Minibatch Loss ---- Train = 0.476967; Test = 0.405960\n",
      "Iter 6, Minibatch Loss ---- Train = 0.527504; Test = 0.444631\n",
      "Iter 7, Minibatch Loss ---- Train = 0.438275; Test = 0.374205\n",
      "Iter 8, Minibatch Loss ---- Train = 0.485119; Test = 0.401467\n",
      "Iter 9, Minibatch Loss ---- Train = 0.426210; Test = 0.352514\n",
      "Iter 10, Minibatch Loss ---- Train = 0.416376; Test = 0.400985\n",
      "Iter 11, Minibatch Loss ---- Train = 0.409756; Test = 0.336518\n",
      "Iter 12, Minibatch Loss ---- Train = 0.414551; Test = 0.366588\n",
      "Iter 13, Minibatch Loss ---- Train = 0.369136; Test = 0.329170\n",
      "Iter 14, Minibatch Loss ---- Train = 0.401949; Test = 0.378700\n",
      "Iter 15, Minibatch Loss ---- Train = 0.351592; Test = 0.319718\n",
      "Iter 16, Minibatch Loss ---- Train = 0.365057; Test = 0.354648\n",
      "Iter 17, Minibatch Loss ---- Train = 0.377526; Test = 0.313119\n",
      "Iter 18, Minibatch Loss ---- Train = 0.403628; Test = 0.351291\n",
      "Iter 19, Minibatch Loss ---- Train = 0.359823; Test = 0.306490\n",
      "Iter 20, Minibatch Loss ---- Train = 0.368544; Test = 0.335059\n",
      "Iter 21, Minibatch Loss ---- Train = 0.309905; Test = 0.300722\n",
      "Iter 22, Minibatch Loss ---- Train = 0.371618; Test = 0.336970\n",
      "Iter 23, Minibatch Loss ---- Train = 0.313562; Test = 0.293663\n",
      "Iter 24, Minibatch Loss ---- Train = 0.350754; Test = 0.324469\n",
      "Iter 25, Minibatch Loss ---- Train = 0.343920; Test = 0.288722\n",
      "Iter 26, Minibatch Loss ---- Train = 0.398842; Test = 0.321651\n",
      "Iter 27, Minibatch Loss ---- Train = 0.366128; Test = 0.281930\n",
      "Iter 28, Minibatch Loss ---- Train = 0.362263; Test = 0.306927\n",
      "Iter 29, Minibatch Loss ---- Train = 0.298992; Test = 0.275270\n",
      "Iter 30, Minibatch Loss ---- Train = 0.338487; Test = 0.300731\n",
      "Iter 31, Minibatch Loss ---- Train = 0.341718; Test = 0.270977\n",
      "Iter 32, Minibatch Loss ---- Train = 0.337315; Test = 0.300907\n",
      "Iter 33, Minibatch Loss ---- Train = 0.324397; Test = 0.266705\n",
      "Iter 34, Minibatch Loss ---- Train = 0.338167; Test = 0.289090\n",
      "Iter 35, Minibatch Loss ---- Train = 0.312351; Test = 0.259964\n",
      "Iter 36, Minibatch Loss ---- Train = 0.319651; Test = 0.288428\n",
      "Iter 37, Minibatch Loss ---- Train = 0.292829; Test = 0.258065\n",
      "Iter 38, Minibatch Loss ---- Train = 0.327308; Test = 0.287367\n",
      "Iter 39, Minibatch Loss ---- Train = 0.286156; Test = 0.252967\n",
      "Iter 40, Minibatch Loss ---- Train = 0.345451; Test = 0.277549\n",
      "Iter 41, Minibatch Loss ---- Train = 0.266527; Test = 0.248151\n",
      "Iter 42, Minibatch Loss ---- Train = 0.295293; Test = 0.274023\n",
      "Iter 43, Minibatch Loss ---- Train = 0.251326; Test = 0.246042\n",
      "Iter 44, Minibatch Loss ---- Train = 0.298057; Test = 0.272812\n",
      "Iter 45, Minibatch Loss ---- Train = 0.273091; Test = 0.242318\n",
      "Iter 46, Minibatch Loss ---- Train = 0.341788; Test = 0.270101\n",
      "Iter 47, Minibatch Loss ---- Train = 0.309453; Test = 0.238999\n",
      "Iter 48, Minibatch Loss ---- Train = 0.338033; Test = 0.264419\n",
      "Iter 49, Minibatch Loss ---- Train = 0.301367; Test = 0.235590\n",
      "Iter 50, Minibatch Loss ---- Train = 0.291053; Test = 0.235226\n",
      "Iter 51, Minibatch Loss ---- Train = 0.267463; Test = 0.234884\n",
      "Iter 52, Minibatch Loss ---- Train = 0.237469; Test = 0.234598\n",
      "Iter 53, Minibatch Loss ---- Train = 0.300680; Test = 0.234010\n",
      "Iter 54, Minibatch Loss ---- Train = 0.336661; Test = 0.236551\n",
      "Iter 55, Minibatch Loss ---- Train = 0.245002; Test = 0.236728\n",
      "Iter 56, Minibatch Loss ---- Train = 0.269784; Test = 0.237240\n",
      "Iter 57, Minibatch Loss ---- Train = 0.253489; Test = 0.234089\n",
      "Iter 58, Minibatch Loss ---- Train = 0.258716; Test = 0.236937\n",
      "Iter 59, Minibatch Loss ---- Train = 0.269525; Test = 0.231415\n",
      "Iter 60, Minibatch Loss ---- Train = 0.245959; Test = 0.232661\n",
      "Iter 61, Minibatch Loss ---- Train = 0.237027; Test = 0.230148\n",
      "Iter 62, Minibatch Loss ---- Train = 0.283605; Test = 0.232378\n",
      "Iter 63, Minibatch Loss ---- Train = 0.303719; Test = 0.224526\n",
      "Iter 64, Minibatch Loss ---- Train = 0.288082; Test = 0.232589\n",
      "Iter 65, Minibatch Loss ---- Train = 0.253650; Test = 0.224107\n",
      "Iter 66, Minibatch Loss ---- Train = 0.257896; Test = 0.225244\n",
      "Iter 67, Minibatch Loss ---- Train = 0.209642; Test = 0.226359\n",
      "Iter 68, Minibatch Loss ---- Train = 0.271925; Test = 0.222738\n",
      "Iter 69, Minibatch Loss ---- Train = 0.240540; Test = 0.220662\n",
      "Iter 70, Minibatch Loss ---- Train = 0.240948; Test = 0.222502\n",
      "Iter 71, Minibatch Loss ---- Train = 0.230715; Test = 0.222314\n",
      "Iter 72, Minibatch Loss ---- Train = 0.253587; Test = 0.219636\n",
      "Iter 73, Minibatch Loss ---- Train = 0.254957; Test = 0.218077\n",
      "Iter 74, Minibatch Loss ---- Train = 0.267169; Test = 0.220530\n",
      "Iter 75, Minibatch Loss ---- Train = 0.217161; Test = 0.215229\n",
      "Iter 76, Minibatch Loss ---- Train = 0.226928; Test = 0.217873\n",
      "Iter 77, Minibatch Loss ---- Train = 0.241905; Test = 0.215383\n",
      "Iter 78, Minibatch Loss ---- Train = 0.230912; Test = 0.217036\n",
      "Iter 79, Minibatch Loss ---- Train = 0.300841; Test = 0.211683\n",
      "Iter 80, Minibatch Loss ---- Train = 0.239491; Test = 0.217460\n",
      "Iter 81, Minibatch Loss ---- Train = 0.246090; Test = 0.210888\n",
      "Iter 82, Minibatch Loss ---- Train = 0.253094; Test = 0.214137\n",
      "Iter 83, Minibatch Loss ---- Train = 0.224172; Test = 0.211370\n",
      "Iter 84, Minibatch Loss ---- Train = 0.218661; Test = 0.211718\n",
      "Iter 85, Minibatch Loss ---- Train = 0.257095; Test = 0.208681\n",
      "Iter 86, Minibatch Loss ---- Train = 0.245071; Test = 0.213130\n",
      "Iter 87, Minibatch Loss ---- Train = 0.260399; Test = 0.208330\n",
      "Iter 88, Minibatch Loss ---- Train = 0.225146; Test = 0.210231\n",
      "Iter 89, Minibatch Loss ---- Train = 0.215547; Test = 0.207266\n",
      "Iter 90, Minibatch Loss ---- Train = 0.237270; Test = 0.207999\n",
      "Iter 91, Minibatch Loss ---- Train = 0.204826; Test = 0.208721\n",
      "Iter 92, Minibatch Loss ---- Train = 0.261608; Test = 0.206759\n",
      "Iter 93, Minibatch Loss ---- Train = 0.249965; Test = 0.204070\n",
      "Iter 94, Minibatch Loss ---- Train = 0.212260; Test = 0.206105\n",
      "Iter 95, Minibatch Loss ---- Train = 0.232587; Test = 0.207504\n",
      "Iter 96, Minibatch Loss ---- Train = 0.246428; Test = 0.205575\n",
      "Iter 97, Minibatch Loss ---- Train = 0.246136; Test = 0.203107\n",
      "Iter 98, Minibatch Loss ---- Train = 0.211791; Test = 0.205316\n",
      "Iter 99, Minibatch Loss ---- Train = 0.262093; Test = 0.204653\n",
      "Iter 100, Minibatch Loss ---- Train = 0.219858; Test = 0.206316\n",
      "Iter 101, Minibatch Loss ---- Train = 0.244499; Test = 0.202019\n",
      "Iter 102, Minibatch Loss ---- Train = 0.254107; Test = 0.205425\n",
      "Iter 103, Minibatch Loss ---- Train = 0.220912; Test = 0.203382\n",
      "Iter 104, Minibatch Loss ---- Train = 0.232480; Test = 0.204579\n",
      "Iter 105, Minibatch Loss ---- Train = 0.264889; Test = 0.200523\n",
      "Iter 106, Minibatch Loss ---- Train = 0.252147; Test = 0.208507\n",
      "Iter 107, Minibatch Loss ---- Train = 0.226391; Test = 0.199953\n",
      "Iter 108, Minibatch Loss ---- Train = 0.242866; Test = 0.205307\n",
      "Iter 109, Minibatch Loss ---- Train = 0.239841; Test = 0.201070\n",
      "Iter 110, Minibatch Loss ---- Train = 0.257042; Test = 0.205033\n",
      "Iter 111, Minibatch Loss ---- Train = 0.222997; Test = 0.199686\n",
      "Iter 112, Minibatch Loss ---- Train = 0.210267; Test = 0.206739\n",
      "Iter 113, Minibatch Loss ---- Train = 0.228004; Test = 0.200861\n",
      "Iter 114, Minibatch Loss ---- Train = 0.216671; Test = 0.200869\n",
      "Iter 115, Minibatch Loss ---- Train = 0.203198; Test = 0.203512\n",
      "Iter 116, Minibatch Loss ---- Train = 0.257009; Test = 0.202785\n",
      "Iter 117, Minibatch Loss ---- Train = 0.251833; Test = 0.198545\n",
      "Iter 118, Minibatch Loss ---- Train = 0.234870; Test = 0.204505\n",
      "Iter 119, Minibatch Loss ---- Train = 0.233028; Test = 0.201832\n",
      "Iter 120, Minibatch Loss ---- Train = 0.219016; Test = 0.200640\n",
      "Iter 121, Minibatch Loss ---- Train = 0.220069; Test = 0.200126\n",
      "Iter 122, Minibatch Loss ---- Train = 0.227815; Test = 0.202110\n",
      "Iter 123, Minibatch Loss ---- Train = 0.216921; Test = 0.200891\n",
      "Iter 124, Minibatch Loss ---- Train = 0.248945; Test = 0.202036\n",
      "Iter 125, Minibatch Loss ---- Train = 0.203263; Test = 0.200294\n",
      "Iter 126, Minibatch Loss ---- Train = 0.244048; Test = 0.201024\n",
      "Iter 127, Minibatch Loss ---- Train = 0.233716; Test = 0.198822\n",
      "Iter 128, Minibatch Loss ---- Train = 0.257657; Test = 0.203941\n",
      "Iter 129, Minibatch Loss ---- Train = 0.203430; Test = 0.199406\n",
      "Iter 130, Minibatch Loss ---- Train = 0.259966; Test = 0.202120\n",
      "Iter 131, Minibatch Loss ---- Train = 0.243469; Test = 0.198152\n",
      "Iter 132, Minibatch Loss ---- Train = 0.237649; Test = 0.202510\n",
      "Iter 133, Minibatch Loss ---- Train = 0.247225; Test = 0.197197\n",
      "Iter 134, Minibatch Loss ---- Train = 0.238160; Test = 0.203191\n",
      "Iter 135, Minibatch Loss ---- Train = 0.182949; Test = 0.199769\n",
      "Iter 136, Minibatch Loss ---- Train = 0.240581; Test = 0.198517\n",
      "Iter 137, Minibatch Loss ---- Train = 0.238102; Test = 0.199072\n",
      "Iter 138, Minibatch Loss ---- Train = 0.255778; Test = 0.202946\n",
      "Iter 139, Minibatch Loss ---- Train = 0.227536; Test = 0.197479\n",
      "Iter 140, Minibatch Loss ---- Train = 0.234885; Test = 0.201592\n",
      "Iter 141, Minibatch Loss ---- Train = 0.220185; Test = 0.199149\n",
      "Iter 142, Minibatch Loss ---- Train = 0.236539; Test = 0.199357\n",
      "Iter 143, Minibatch Loss ---- Train = 0.241487; Test = 0.198449\n",
      "Iter 144, Minibatch Loss ---- Train = 0.239197; Test = 0.201900\n",
      "Iter 145, Minibatch Loss ---- Train = 0.269984; Test = 0.196952\n",
      "Iter 146, Minibatch Loss ---- Train = 0.233394; Test = 0.200146\n",
      "Iter 147, Minibatch Loss ---- Train = 0.202162; Test = 0.199645\n",
      "Iter 148, Minibatch Loss ---- Train = 0.284450; Test = 0.200694\n",
      "Iter 149, Minibatch Loss ---- Train = 0.210267; Test = 0.195798\n",
      "Iter 150, Minibatch Loss ---- Train = 0.235307; Test = 0.199869\n",
      "Iter 151, Minibatch Loss ---- Train = 0.217725; Test = 0.200624\n",
      "Iter 152, Minibatch Loss ---- Train = 0.221526; Test = 0.198652\n",
      "Iter 153, Minibatch Loss ---- Train = 0.268765; Test = 0.194592\n",
      "Iter 154, Minibatch Loss ---- Train = 0.244960; Test = 0.204945\n",
      "Iter 155, Minibatch Loss ---- Train = 0.230835; Test = 0.196750\n",
      "Iter 156, Minibatch Loss ---- Train = 0.225663; Test = 0.198887\n",
      "Iter 157, Minibatch Loss ---- Train = 0.248384; Test = 0.198320\n",
      "Iter 158, Minibatch Loss ---- Train = 0.235723; Test = 0.199506\n",
      "Iter 159, Minibatch Loss ---- Train = 0.224304; Test = 0.199193\n",
      "Iter 160, Minibatch Loss ---- Train = 0.217313; Test = 0.200085\n",
      "Iter 161, Minibatch Loss ---- Train = 0.206487; Test = 0.197572\n",
      "Iter 162, Minibatch Loss ---- Train = 0.251045; Test = 0.199800\n",
      "Iter 163, Minibatch Loss ---- Train = 0.256091; Test = 0.195138\n",
      "Iter 164, Minibatch Loss ---- Train = 0.223791; Test = 0.200422\n",
      "Iter 165, Minibatch Loss ---- Train = 0.245255; Test = 0.197760\n",
      "Iter 166, Minibatch Loss ---- Train = 0.245693; Test = 0.200668\n",
      "Iter 167, Minibatch Loss ---- Train = 0.231202; Test = 0.195521\n",
      "Iter 168, Minibatch Loss ---- Train = 0.220359; Test = 0.197507\n",
      "Iter 169, Minibatch Loss ---- Train = 0.233326; Test = 0.198922\n",
      "Iter 170, Minibatch Loss ---- Train = 0.189806; Test = 0.196241\n",
      "Iter 171, Minibatch Loss ---- Train = 0.214807; Test = 0.198444\n",
      "Iter 172, Minibatch Loss ---- Train = 0.212284; Test = 0.199323\n",
      "Iter 173, Minibatch Loss ---- Train = 0.213273; Test = 0.197867\n",
      "Iter 174, Minibatch Loss ---- Train = 0.214451; Test = 0.199255\n",
      "Iter 175, Minibatch Loss ---- Train = 0.229512; Test = 0.195877\n",
      "Iter 176, Minibatch Loss ---- Train = 0.260663; Test = 0.200711\n",
      "Iter 177, Minibatch Loss ---- Train = 0.243728; Test = 0.196283\n",
      "Iter 178, Minibatch Loss ---- Train = 0.200200; Test = 0.197492\n",
      "Iter 179, Minibatch Loss ---- Train = 0.217189; Test = 0.198788\n",
      "Iter 180, Minibatch Loss ---- Train = 0.214375; Test = 0.197801\n",
      "Iter 181, Minibatch Loss ---- Train = 0.253149; Test = 0.193096\n",
      "Iter 182, Minibatch Loss ---- Train = 0.218383; Test = 0.202073\n",
      "Iter 183, Minibatch Loss ---- Train = 0.238668; Test = 0.196966\n",
      "Iter 184, Minibatch Loss ---- Train = 0.215166; Test = 0.197965\n",
      "Iter 185, Minibatch Loss ---- Train = 0.259075; Test = 0.195081\n",
      "Iter 186, Minibatch Loss ---- Train = 0.230282; Test = 0.199062\n",
      "Iter 187, Minibatch Loss ---- Train = 0.215137; Test = 0.198374\n",
      "Iter 188, Minibatch Loss ---- Train = 0.217913; Test = 0.195994\n",
      "Iter 189, Minibatch Loss ---- Train = 0.234488; Test = 0.196164\n",
      "Iter 190, Minibatch Loss ---- Train = 0.209154; Test = 0.199492\n",
      "Iter 191, Minibatch Loss ---- Train = 0.236748; Test = 0.195669\n",
      "Iter 192, Minibatch Loss ---- Train = 0.237967; Test = 0.199084\n",
      "Iter 193, Minibatch Loss ---- Train = 0.254451; Test = 0.195311\n",
      "Iter 194, Minibatch Loss ---- Train = 0.224598; Test = 0.198651\n",
      "Iter 195, Minibatch Loss ---- Train = 0.246074; Test = 0.197119\n",
      "Iter 196, Minibatch Loss ---- Train = 0.234962; Test = 0.198110\n",
      "Iter 197, Minibatch Loss ---- Train = 0.216680; Test = 0.195240\n",
      "Iter 198, Minibatch Loss ---- Train = 0.222081; Test = 0.198343\n",
      "Iter 199, Minibatch Loss ---- Train = 0.246751; Test = 0.194928\n",
      "Iter 200, Minibatch Loss ---- Train = 0.201473; Test = 0.197196\n",
      "Iter 201, Minibatch Loss ---- Train = 0.255806; Test = 0.199554\n",
      "Iter 202, Minibatch Loss ---- Train = 0.248711; Test = 0.196753\n",
      "Iter 203, Minibatch Loss ---- Train = 0.211104; Test = 0.196976\n",
      "Iter 204, Minibatch Loss ---- Train = 0.209025; Test = 0.197039\n",
      "Iter 205, Minibatch Loss ---- Train = 0.225623; Test = 0.196769\n",
      "Iter 206, Minibatch Loss ---- Train = 0.223701; Test = 0.198344\n",
      "Iter 207, Minibatch Loss ---- Train = 0.213136; Test = 0.193627\n",
      "Iter 208, Minibatch Loss ---- Train = 0.221167; Test = 0.196465\n",
      "Iter 209, Minibatch Loss ---- Train = 0.235281; Test = 0.196816\n",
      "Iter 210, Minibatch Loss ---- Train = 0.250476; Test = 0.197804\n",
      "Iter 211, Minibatch Loss ---- Train = 0.250829; Test = 0.193183\n",
      "Iter 212, Minibatch Loss ---- Train = 0.201549; Test = 0.196117\n",
      "Iter 213, Minibatch Loss ---- Train = 0.217439; Test = 0.197567\n",
      "Iter 214, Minibatch Loss ---- Train = 0.176787; Test = 0.194716\n",
      "Iter 215, Minibatch Loss ---- Train = 0.211541; Test = 0.198454\n",
      "Iter 216, Minibatch Loss ---- Train = 0.228668; Test = 0.196133\n",
      "Iter 217, Minibatch Loss ---- Train = 0.216588; Test = 0.194265\n",
      "Iter 218, Minibatch Loss ---- Train = 0.207753; Test = 0.197670\n",
      "Iter 219, Minibatch Loss ---- Train = 0.219451; Test = 0.195288\n",
      "Iter 220, Minibatch Loss ---- Train = 0.254503; Test = 0.197310\n",
      "Iter 221, Minibatch Loss ---- Train = 0.211809; Test = 0.194346\n",
      "Iter 222, Minibatch Loss ---- Train = 0.210162; Test = 0.195145\n",
      "Iter 223, Minibatch Loss ---- Train = 0.197343; Test = 0.196826\n",
      "Iter 224, Minibatch Loss ---- Train = 0.222590; Test = 0.197076\n",
      "Iter 225, Minibatch Loss ---- Train = 0.233662; Test = 0.194470\n",
      "Iter 226, Minibatch Loss ---- Train = 0.243232; Test = 0.198022\n",
      "Iter 227, Minibatch Loss ---- Train = 0.218484; Test = 0.192163\n",
      "Iter 228, Minibatch Loss ---- Train = 0.213450; Test = 0.195399\n",
      "Iter 229, Minibatch Loss ---- Train = 0.230985; Test = 0.196684\n",
      "Iter 230, Minibatch Loss ---- Train = 0.227254; Test = 0.197818\n",
      "Iter 231, Minibatch Loss ---- Train = 0.200945; Test = 0.193923\n",
      "Iter 232, Minibatch Loss ---- Train = 0.224896; Test = 0.195632\n",
      "Iter 233, Minibatch Loss ---- Train = 0.217798; Test = 0.196581\n",
      "Iter 234, Minibatch Loss ---- Train = 0.232486; Test = 0.196929\n",
      "Iter 235, Minibatch Loss ---- Train = 0.216230; Test = 0.195063\n",
      "Iter 236, Minibatch Loss ---- Train = 0.203728; Test = 0.195665\n",
      "Iter 237, Minibatch Loss ---- Train = 0.212080; Test = 0.195490\n",
      "Iter 238, Minibatch Loss ---- Train = 0.231860; Test = 0.197227\n",
      "Iter 239, Minibatch Loss ---- Train = 0.214201; Test = 0.194044\n",
      "Iter 240, Minibatch Loss ---- Train = 0.221464; Test = 0.196735\n",
      "Iter 241, Minibatch Loss ---- Train = 0.234531; Test = 0.195027\n",
      "Iter 242, Minibatch Loss ---- Train = 0.214141; Test = 0.195911\n",
      "Iter 243, Minibatch Loss ---- Train = 0.213856; Test = 0.194185\n",
      "Iter 244, Minibatch Loss ---- Train = 0.208395; Test = 0.197778\n",
      "Iter 245, Minibatch Loss ---- Train = 0.205030; Test = 0.194285\n",
      "Iter 246, Minibatch Loss ---- Train = 0.264939; Test = 0.194888\n",
      "Iter 247, Minibatch Loss ---- Train = 0.247849; Test = 0.193829\n",
      "Iter 248, Minibatch Loss ---- Train = 0.250824; Test = 0.198753\n",
      "Iter 249, Minibatch Loss ---- Train = 0.247457; Test = 0.192564\n",
      "Iter 250, Minibatch Loss ---- Train = 0.243099; Test = 0.197598\n",
      "Iter 251, Minibatch Loss ---- Train = 0.225343; Test = 0.193540\n",
      "Iter 252, Minibatch Loss ---- Train = 0.237248; Test = 0.197439\n",
      "Iter 253, Minibatch Loss ---- Train = 0.238304; Test = 0.193596\n",
      "Iter 254, Minibatch Loss ---- Train = 0.214091; Test = 0.193726\n",
      "Iter 255, Minibatch Loss ---- Train = 0.221660; Test = 0.197075\n",
      "Iter 256, Minibatch Loss ---- Train = 0.249900; Test = 0.195273\n",
      "Iter 257, Minibatch Loss ---- Train = 0.201874; Test = 0.195016\n",
      "Iter 258, Minibatch Loss ---- Train = 0.198536; Test = 0.194518\n",
      "Iter 259, Minibatch Loss ---- Train = 0.206749; Test = 0.195278\n",
      "Iter 260, Minibatch Loss ---- Train = 0.246873; Test = 0.196506\n",
      "Iter 261, Minibatch Loss ---- Train = 0.201421; Test = 0.194782\n",
      "Iter 262, Minibatch Loss ---- Train = 0.234797; Test = 0.195650\n",
      "Iter 263, Minibatch Loss ---- Train = 0.204134; Test = 0.194426\n",
      "Iter 264, Minibatch Loss ---- Train = 0.256821; Test = 0.196072\n",
      "Iter 265, Minibatch Loss ---- Train = 0.215414; Test = 0.193158\n",
      "Iter 266, Minibatch Loss ---- Train = 0.205310; Test = 0.195076\n",
      "Iter 267, Minibatch Loss ---- Train = 0.212017; Test = 0.195075\n",
      "Iter 268, Minibatch Loss ---- Train = 0.208919; Test = 0.193661\n",
      "Iter 269, Minibatch Loss ---- Train = 0.271610; Test = 0.195849\n",
      "Iter 270, Minibatch Loss ---- Train = 0.212860; Test = 0.195667\n",
      "Iter 271, Minibatch Loss ---- Train = 0.213231; Test = 0.194339\n",
      "Iter 272, Minibatch Loss ---- Train = 0.229242; Test = 0.194222\n",
      "Iter 273, Minibatch Loss ---- Train = 0.206586; Test = 0.195602\n",
      "Iter 274, Minibatch Loss ---- Train = 0.239989; Test = 0.194552\n",
      "Iter 275, Minibatch Loss ---- Train = 0.238965; Test = 0.196175\n",
      "Iter 276, Minibatch Loss ---- Train = 0.257262; Test = 0.194858\n",
      "Iter 277, Minibatch Loss ---- Train = 0.239552; Test = 0.192851\n",
      "Iter 278, Minibatch Loss ---- Train = 0.216317; Test = 0.193930\n",
      "Iter 279, Minibatch Loss ---- Train = 0.201761; Test = 0.197470\n",
      "Iter 280, Minibatch Loss ---- Train = 0.237055; Test = 0.194819\n",
      "Iter 281, Minibatch Loss ---- Train = 0.203214; Test = 0.192256\n",
      "Iter 282, Minibatch Loss ---- Train = 0.260910; Test = 0.197020\n",
      "Iter 283, Minibatch Loss ---- Train = 0.200253; Test = 0.195518\n",
      "Iter 284, Minibatch Loss ---- Train = 0.189229; Test = 0.192976\n",
      "Iter 285, Minibatch Loss ---- Train = 0.218555; Test = 0.199333\n",
      "Iter 286, Minibatch Loss ---- Train = 0.212988; Test = 0.194654\n",
      "Iter 287, Minibatch Loss ---- Train = 0.223460; Test = 0.193854\n",
      "Iter 288, Minibatch Loss ---- Train = 0.256342; Test = 0.196183\n",
      "Iter 289, Minibatch Loss ---- Train = 0.210639; Test = 0.194159\n",
      "Iter 290, Minibatch Loss ---- Train = 0.240972; Test = 0.194515\n",
      "Iter 291, Minibatch Loss ---- Train = 0.249029; Test = 0.194179\n",
      "Iter 292, Minibatch Loss ---- Train = 0.231805; Test = 0.195299\n",
      "Iter 293, Minibatch Loss ---- Train = 0.204957; Test = 0.193843\n",
      "Iter 294, Minibatch Loss ---- Train = 0.200946; Test = 0.192509\n",
      "Iter 295, Minibatch Loss ---- Train = 0.185801; Test = 0.200275\n",
      "Iter 296, Minibatch Loss ---- Train = 0.205249; Test = 0.191988\n",
      "Iter 297, Minibatch Loss ---- Train = 0.238050; Test = 0.192124\n",
      "Iter 298, Minibatch Loss ---- Train = 0.216441; Test = 0.195343\n",
      "Iter 299, Minibatch Loss ---- Train = 0.230071; Test = 0.193828\n",
      "Iter 300, Minibatch Loss ---- Train = 0.208632; Test = 0.194266\n",
      "Iter 301, Minibatch Loss ---- Train = 0.248800; Test = 0.192116\n",
      "Iter 302, Minibatch Loss ---- Train = 0.230871; Test = 0.193097\n",
      "Iter 303, Minibatch Loss ---- Train = 0.239750; Test = 0.195882\n",
      "Iter 304, Minibatch Loss ---- Train = 0.233478; Test = 0.195039\n",
      "Iter 305, Minibatch Loss ---- Train = 0.191549; Test = 0.192089\n",
      "Iter 306, Minibatch Loss ---- Train = 0.245493; Test = 0.194833\n",
      "Iter 307, Minibatch Loss ---- Train = 0.209892; Test = 0.193847\n",
      "Iter 308, Minibatch Loss ---- Train = 0.206455; Test = 0.193193\n",
      "Iter 309, Minibatch Loss ---- Train = 0.236046; Test = 0.193228\n",
      "Iter 310, Minibatch Loss ---- Train = 0.191206; Test = 0.191632\n",
      "Iter 311, Minibatch Loss ---- Train = 0.210748; Test = 0.200521\n",
      "Iter 312, Minibatch Loss ---- Train = 0.225014; Test = 0.192233\n",
      "Iter 313, Minibatch Loss ---- Train = 0.186380; Test = 0.192370\n",
      "Iter 314, Minibatch Loss ---- Train = 0.194400; Test = 0.191135\n",
      "Iter 315, Minibatch Loss ---- Train = 0.217371; Test = 0.197116\n",
      "Iter 316, Minibatch Loss ---- Train = 0.242646; Test = 0.195065\n",
      "Iter 317, Minibatch Loss ---- Train = 0.249237; Test = 0.191078\n",
      "Iter 318, Minibatch Loss ---- Train = 0.197492; Test = 0.192675\n",
      "Iter 319, Minibatch Loss ---- Train = 0.258720; Test = 0.197095\n",
      "Iter 320, Minibatch Loss ---- Train = 0.215963; Test = 0.194565\n",
      "Iter 321, Minibatch Loss ---- Train = 0.199765; Test = 0.196232\n",
      "Iter 322, Minibatch Loss ---- Train = 0.242460; Test = 0.193754\n",
      "Iter 323, Minibatch Loss ---- Train = 0.197327; Test = 0.194339\n",
      "Iter 324, Minibatch Loss ---- Train = 0.212519; Test = 0.192419\n",
      "Iter 325, Minibatch Loss ---- Train = 0.235509; Test = 0.189850\n",
      "Iter 326, Minibatch Loss ---- Train = 0.195999; Test = 0.196608\n",
      "Iter 327, Minibatch Loss ---- Train = 0.229116; Test = 0.193644\n",
      "Iter 328, Minibatch Loss ---- Train = 0.208876; Test = 0.191819\n",
      "Iter 329, Minibatch Loss ---- Train = 0.210046; Test = 0.196542\n",
      "Iter 330, Minibatch Loss ---- Train = 0.228316; Test = 0.192022\n",
      "Iter 331, Minibatch Loss ---- Train = 0.231698; Test = 0.190758\n",
      "Iter 332, Minibatch Loss ---- Train = 0.219875; Test = 0.192688\n",
      "Iter 333, Minibatch Loss ---- Train = 0.211205; Test = 0.195275\n",
      "Iter 334, Minibatch Loss ---- Train = 0.219021; Test = 0.193605\n",
      "Iter 335, Minibatch Loss ---- Train = 0.229219; Test = 0.194475\n",
      "Iter 336, Minibatch Loss ---- Train = 0.184155; Test = 0.191686\n",
      "Iter 337, Minibatch Loss ---- Train = 0.208424; Test = 0.194791\n",
      "Iter 338, Minibatch Loss ---- Train = 0.222434; Test = 0.193045\n",
      "Iter 339, Minibatch Loss ---- Train = 0.221809; Test = 0.193670\n",
      "Iter 340, Minibatch Loss ---- Train = 0.216418; Test = 0.193767\n",
      "Iter 341, Minibatch Loss ---- Train = 0.241549; Test = 0.193529\n",
      "Iter 342, Minibatch Loss ---- Train = 0.230748; Test = 0.194994\n",
      "Iter 343, Minibatch Loss ---- Train = 0.218162; Test = 0.194056\n",
      "Iter 344, Minibatch Loss ---- Train = 0.208700; Test = 0.191472\n",
      "Iter 345, Minibatch Loss ---- Train = 0.223707; Test = 0.193195\n",
      "Iter 346, Minibatch Loss ---- Train = 0.187219; Test = 0.192930\n",
      "Iter 347, Minibatch Loss ---- Train = 0.232071; Test = 0.194726\n",
      "Iter 348, Minibatch Loss ---- Train = 0.234335; Test = 0.193237\n",
      "Iter 349, Minibatch Loss ---- Train = 0.219052; Test = 0.190664\n",
      "Iter 350, Minibatch Loss ---- Train = 0.222649; Test = 0.194068\n",
      "Iter 351, Minibatch Loss ---- Train = 0.197783; Test = 0.194836\n",
      "Iter 352, Minibatch Loss ---- Train = 0.207677; Test = 0.192643\n",
      "Iter 353, Minibatch Loss ---- Train = 0.263844; Test = 0.189494\n",
      "Iter 354, Minibatch Loss ---- Train = 0.206170; Test = 0.196475\n",
      "Iter 355, Minibatch Loss ---- Train = 0.218848; Test = 0.191337\n",
      "Iter 356, Minibatch Loss ---- Train = 0.219414; Test = 0.193397\n",
      "Iter 357, Minibatch Loss ---- Train = 0.234187; Test = 0.194225\n",
      "Iter 358, Minibatch Loss ---- Train = 0.210332; Test = 0.193126\n",
      "Iter 359, Minibatch Loss ---- Train = 0.187271; Test = 0.194249\n",
      "Iter 360, Minibatch Loss ---- Train = 0.224907; Test = 0.193507\n",
      "Iter 361, Minibatch Loss ---- Train = 0.246464; Test = 0.189172\n",
      "Iter 362, Minibatch Loss ---- Train = 0.218014; Test = 0.191482\n",
      "Iter 363, Minibatch Loss ---- Train = 0.215321; Test = 0.197493\n",
      "Iter 364, Minibatch Loss ---- Train = 0.205187; Test = 0.191679\n",
      "Iter 365, Minibatch Loss ---- Train = 0.217826; Test = 0.192964\n",
      "Iter 366, Minibatch Loss ---- Train = 0.206670; Test = 0.192914\n",
      "Iter 367, Minibatch Loss ---- Train = 0.218845; Test = 0.191827\n",
      "Iter 368, Minibatch Loss ---- Train = 0.218131; Test = 0.193067\n",
      "Iter 369, Minibatch Loss ---- Train = 0.225440; Test = 0.193373\n",
      "Iter 370, Minibatch Loss ---- Train = 0.211607; Test = 0.193127\n",
      "Iter 371, Minibatch Loss ---- Train = 0.211041; Test = 0.192524\n",
      "Iter 372, Minibatch Loss ---- Train = 0.216736; Test = 0.192940\n",
      "Iter 373, Minibatch Loss ---- Train = 0.200631; Test = 0.194641\n",
      "Iter 374, Minibatch Loss ---- Train = 0.216738; Test = 0.191662\n",
      "Iter 375, Minibatch Loss ---- Train = 0.224164; Test = 0.191467\n",
      "Iter 376, Minibatch Loss ---- Train = 0.222482; Test = 0.192580\n",
      "Iter 377, Minibatch Loss ---- Train = 0.203498; Test = 0.194419\n",
      "Iter 378, Minibatch Loss ---- Train = 0.222306; Test = 0.191792\n",
      "Iter 379, Minibatch Loss ---- Train = 0.214534; Test = 0.192579\n",
      "Iter 380, Minibatch Loss ---- Train = 0.201818; Test = 0.192429\n",
      "Iter 381, Minibatch Loss ---- Train = 0.194436; Test = 0.192461\n",
      "Iter 382, Minibatch Loss ---- Train = 0.219887; Test = 0.191299\n",
      "Iter 383, Minibatch Loss ---- Train = 0.209296; Test = 0.191843\n",
      "Iter 384, Minibatch Loss ---- Train = 0.195878; Test = 0.191452\n",
      "Iter 385, Minibatch Loss ---- Train = 0.206382; Test = 0.192849\n",
      "Iter 386, Minibatch Loss ---- Train = 0.239120; Test = 0.192789\n",
      "Iter 387, Minibatch Loss ---- Train = 0.208305; Test = 0.192519\n",
      "Iter 388, Minibatch Loss ---- Train = 0.212056; Test = 0.190840\n",
      "Iter 389, Minibatch Loss ---- Train = 0.228075; Test = 0.191649\n",
      "Iter 390, Minibatch Loss ---- Train = 0.213032; Test = 0.192574\n",
      "Iter 391, Minibatch Loss ---- Train = 0.210675; Test = 0.193789\n",
      "Iter 392, Minibatch Loss ---- Train = 0.210886; Test = 0.191906\n",
      "Iter 393, Minibatch Loss ---- Train = 0.198033; Test = 0.191658\n",
      "Iter 394, Minibatch Loss ---- Train = 0.251678; Test = 0.194965\n",
      "Iter 395, Minibatch Loss ---- Train = 0.221137; Test = 0.188733\n",
      "Iter 396, Minibatch Loss ---- Train = 0.258278; Test = 0.190642\n",
      "Iter 397, Minibatch Loss ---- Train = 0.213838; Test = 0.195411\n",
      "Iter 398, Minibatch Loss ---- Train = 0.213512; Test = 0.190364\n",
      "Iter 399, Minibatch Loss ---- Train = 0.208917; Test = 0.192084\n",
      "Iter 400, Minibatch Loss ---- Train = 0.217486; Test = 0.194030\n",
      "Iter 401, Minibatch Loss ---- Train = 0.217628; Test = 0.193520\n",
      "Iter 402, Minibatch Loss ---- Train = 0.224883; Test = 0.192307\n",
      "Iter 403, Minibatch Loss ---- Train = 0.185154; Test = 0.194202\n",
      "Iter 404, Minibatch Loss ---- Train = 0.211002; Test = 0.189553\n",
      "Iter 405, Minibatch Loss ---- Train = 0.217853; Test = 0.188332\n",
      "Iter 406, Minibatch Loss ---- Train = 0.221672; Test = 0.192353\n",
      "Iter 407, Minibatch Loss ---- Train = 0.211969; Test = 0.195893\n",
      "Iter 408, Minibatch Loss ---- Train = 0.204490; Test = 0.191936\n",
      "Iter 409, Minibatch Loss ---- Train = 0.192145; Test = 0.194955\n",
      "Iter 410, Minibatch Loss ---- Train = 0.215782; Test = 0.192630\n",
      "Iter 411, Minibatch Loss ---- Train = 0.196033; Test = 0.192763\n",
      "Iter 412, Minibatch Loss ---- Train = 0.232249; Test = 0.191545\n",
      "Iter 413, Minibatch Loss ---- Train = 0.220637; Test = 0.190491\n",
      "Iter 414, Minibatch Loss ---- Train = 0.246734; Test = 0.191704\n",
      "Iter 415, Minibatch Loss ---- Train = 0.235431; Test = 0.187610\n",
      "Iter 416, Minibatch Loss ---- Train = 0.229412; Test = 0.187613\n",
      "Iter 417, Minibatch Loss ---- Train = 0.230297; Test = 0.189123\n",
      "Iter 418, Minibatch Loss ---- Train = 0.231465; Test = 0.195757\n",
      "Iter 419, Minibatch Loss ---- Train = 0.216238; Test = 0.190972\n",
      "Iter 420, Minibatch Loss ---- Train = 0.176249; Test = 0.191205\n",
      "Iter 421, Minibatch Loss ---- Train = 0.211087; Test = 0.192132\n",
      "Iter 422, Minibatch Loss ---- Train = 0.230308; Test = 0.192937\n",
      "Iter 423, Minibatch Loss ---- Train = 0.211009; Test = 0.191670\n",
      "Iter 424, Minibatch Loss ---- Train = 0.206363; Test = 0.191830\n",
      "Iter 425, Minibatch Loss ---- Train = 0.225953; Test = 0.192235\n",
      "Iter 426, Minibatch Loss ---- Train = 0.214155; Test = 0.195591\n",
      "Iter 427, Minibatch Loss ---- Train = 0.202462; Test = 0.189828\n",
      "Iter 428, Minibatch Loss ---- Train = 0.200040; Test = 0.190271\n",
      "Iter 429, Minibatch Loss ---- Train = 0.212979; Test = 0.192390\n",
      "Iter 430, Minibatch Loss ---- Train = 0.236502; Test = 0.190857\n",
      "Iter 431, Minibatch Loss ---- Train = 0.210820; Test = 0.190281\n",
      "Iter 432, Minibatch Loss ---- Train = 0.198172; Test = 0.193431\n",
      "Iter 433, Minibatch Loss ---- Train = 0.199122; Test = 0.190172\n",
      "Iter 434, Minibatch Loss ---- Train = 0.278663; Test = 0.192600\n",
      "Iter 435, Minibatch Loss ---- Train = 0.238314; Test = 0.190549\n",
      "Iter 436, Minibatch Loss ---- Train = 0.203639; Test = 0.192167\n",
      "Iter 437, Minibatch Loss ---- Train = 0.190896; Test = 0.192207\n",
      "Iter 438, Minibatch Loss ---- Train = 0.222595; Test = 0.191875\n",
      "Iter 439, Minibatch Loss ---- Train = 0.226027; Test = 0.192402\n",
      "Iter 440, Minibatch Loss ---- Train = 0.235052; Test = 0.190786\n",
      "Iter 441, Minibatch Loss ---- Train = 0.223213; Test = 0.190290\n",
      "Iter 442, Minibatch Loss ---- Train = 0.223033; Test = 0.188813\n",
      "Iter 443, Minibatch Loss ---- Train = 0.216701; Test = 0.192415\n",
      "Iter 444, Minibatch Loss ---- Train = 0.212482; Test = 0.194537\n",
      "Iter 445, Minibatch Loss ---- Train = 0.208226; Test = 0.191989\n",
      "Iter 446, Minibatch Loss ---- Train = 0.220679; Test = 0.189491\n",
      "Iter 447, Minibatch Loss ---- Train = 0.223547; Test = 0.190827\n",
      "Iter 448, Minibatch Loss ---- Train = 0.225488; Test = 0.194574\n",
      "Iter 449, Minibatch Loss ---- Train = 0.200576; Test = 0.192019\n",
      "Iter 450, Minibatch Loss ---- Train = 0.206359; Test = 0.194131\n",
      "Iter 451, Minibatch Loss ---- Train = 0.241852; Test = 0.192527\n",
      "Iter 452, Minibatch Loss ---- Train = 0.203405; Test = 0.190843\n",
      "Iter 453, Minibatch Loss ---- Train = 0.205554; Test = 0.189948\n",
      "Iter 454, Minibatch Loss ---- Train = 0.191700; Test = 0.191255\n",
      "Iter 455, Minibatch Loss ---- Train = 0.227379; Test = 0.190585\n",
      "Iter 456, Minibatch Loss ---- Train = 0.247200; Test = 0.192163\n",
      "Iter 457, Minibatch Loss ---- Train = 0.236532; Test = 0.190953\n",
      "Iter 458, Minibatch Loss ---- Train = 0.183289; Test = 0.191825\n",
      "Iter 459, Minibatch Loss ---- Train = 0.210905; Test = 0.191943\n",
      "Iter 460, Minibatch Loss ---- Train = 0.234031; Test = 0.187026\n",
      "Iter 461, Minibatch Loss ---- Train = 0.212995; Test = 0.191897\n",
      "Iter 462, Minibatch Loss ---- Train = 0.200601; Test = 0.191402\n",
      "Iter 463, Minibatch Loss ---- Train = 0.237900; Test = 0.190896\n",
      "Iter 464, Minibatch Loss ---- Train = 0.221303; Test = 0.192980\n",
      "Iter 465, Minibatch Loss ---- Train = 0.218541; Test = 0.192224\n",
      "Iter 466, Minibatch Loss ---- Train = 0.218944; Test = 0.191187\n",
      "Iter 467, Minibatch Loss ---- Train = 0.187008; Test = 0.192916\n",
      "Iter 468, Minibatch Loss ---- Train = 0.219940; Test = 0.191268\n",
      "Iter 469, Minibatch Loss ---- Train = 0.204545; Test = 0.190419\n",
      "Iter 470, Minibatch Loss ---- Train = 0.236134; Test = 0.192635\n",
      "Iter 471, Minibatch Loss ---- Train = 0.214643; Test = 0.189822\n",
      "Iter 472, Minibatch Loss ---- Train = 0.211666; Test = 0.190710\n",
      "Iter 473, Minibatch Loss ---- Train = 0.205964; Test = 0.190586\n",
      "Iter 474, Minibatch Loss ---- Train = 0.204521; Test = 0.190867\n",
      "Iter 475, Minibatch Loss ---- Train = 0.202535; Test = 0.191771\n",
      "Iter 476, Minibatch Loss ---- Train = 0.199772; Test = 0.189786\n",
      "Iter 477, Minibatch Loss ---- Train = 0.262094; Test = 0.191262\n",
      "Iter 478, Minibatch Loss ---- Train = 0.190848; Test = 0.189851\n",
      "Iter 479, Minibatch Loss ---- Train = 0.207078; Test = 0.193453\n",
      "Iter 480, Minibatch Loss ---- Train = 0.234081; Test = 0.189711\n",
      "Iter 481, Minibatch Loss ---- Train = 0.207191; Test = 0.189514\n",
      "Iter 482, Minibatch Loss ---- Train = 0.197930; Test = 0.189469\n",
      "Iter 483, Minibatch Loss ---- Train = 0.208502; Test = 0.192742\n",
      "Iter 484, Minibatch Loss ---- Train = 0.196468; Test = 0.191989\n",
      "Iter 485, Minibatch Loss ---- Train = 0.205778; Test = 0.190105\n",
      "Iter 486, Minibatch Loss ---- Train = 0.217686; Test = 0.188854\n",
      "Iter 487, Minibatch Loss ---- Train = 0.213314; Test = 0.192411\n",
      "Iter 488, Minibatch Loss ---- Train = 0.187982; Test = 0.189564\n",
      "Iter 489, Minibatch Loss ---- Train = 0.240987; Test = 0.189421\n",
      "Iter 490, Minibatch Loss ---- Train = 0.197261; Test = 0.191415\n",
      "Iter 491, Minibatch Loss ---- Train = 0.239493; Test = 0.191642\n",
      "Iter 492, Minibatch Loss ---- Train = 0.239225; Test = 0.189622\n",
      "Iter 493, Minibatch Loss ---- Train = 0.227094; Test = 0.194566\n",
      "Iter 494, Minibatch Loss ---- Train = 0.219450; Test = 0.187839\n",
      "Iter 495, Minibatch Loss ---- Train = 0.231584; Test = 0.188309\n",
      "Iter 496, Minibatch Loss ---- Train = 0.227401; Test = 0.191334\n",
      "Iter 497, Minibatch Loss ---- Train = 0.197909; Test = 0.190134\n",
      "Iter 498, Minibatch Loss ---- Train = 0.208311; Test = 0.188798\n",
      "Iter 499, Minibatch Loss ---- Train = 0.190729; Test = 0.192529\n",
      "Iter 500, Minibatch Loss ---- Train = 0.185829; Test = 0.189226\n",
      "Iter 501, Minibatch Loss ---- Train = 0.185102; Test = 0.193540\n",
      "Iter 502, Minibatch Loss ---- Train = 0.218912; Test = 0.188502\n",
      "Iter 503, Minibatch Loss ---- Train = 0.217639; Test = 0.190873\n",
      "Iter 504, Minibatch Loss ---- Train = 0.212174; Test = 0.190706\n",
      "Iter 505, Minibatch Loss ---- Train = 0.233752; Test = 0.192310\n",
      "Iter 506, Minibatch Loss ---- Train = 0.222636; Test = 0.189624\n",
      "Iter 507, Minibatch Loss ---- Train = 0.197201; Test = 0.189505\n",
      "Iter 508, Minibatch Loss ---- Train = 0.206050; Test = 0.190600\n",
      "Iter 509, Minibatch Loss ---- Train = 0.214249; Test = 0.191155\n",
      "Iter 510, Minibatch Loss ---- Train = 0.249228; Test = 0.190594\n",
      "Iter 511, Minibatch Loss ---- Train = 0.208333; Test = 0.189607\n",
      "Iter 512, Minibatch Loss ---- Train = 0.212063; Test = 0.190721\n",
      "Iter 513, Minibatch Loss ---- Train = 0.227410; Test = 0.188815\n",
      "Iter 514, Minibatch Loss ---- Train = 0.240749; Test = 0.191562\n",
      "Iter 515, Minibatch Loss ---- Train = 0.204796; Test = 0.190006\n",
      "Iter 516, Minibatch Loss ---- Train = 0.176984; Test = 0.190860\n",
      "Iter 517, Minibatch Loss ---- Train = 0.243830; Test = 0.186582\n",
      "Iter 518, Minibatch Loss ---- Train = 0.211685; Test = 0.188454\n",
      "Iter 519, Minibatch Loss ---- Train = 0.232118; Test = 0.187199\n",
      "Iter 520, Minibatch Loss ---- Train = 0.201416; Test = 0.195892\n",
      "Iter 521, Minibatch Loss ---- Train = 0.235699; Test = 0.189896\n",
      "Iter 522, Minibatch Loss ---- Train = 0.190221; Test = 0.191700\n",
      "Iter 523, Minibatch Loss ---- Train = 0.192973; Test = 0.187263\n",
      "Iter 524, Minibatch Loss ---- Train = 0.226248; Test = 0.190126\n",
      "Iter 525, Minibatch Loss ---- Train = 0.206079; Test = 0.190218\n",
      "Iter 526, Minibatch Loss ---- Train = 0.197555; Test = 0.190518\n",
      "Iter 527, Minibatch Loss ---- Train = 0.240124; Test = 0.189542\n",
      "Iter 528, Minibatch Loss ---- Train = 0.209412; Test = 0.188211\n",
      "Iter 529, Minibatch Loss ---- Train = 0.219942; Test = 0.189089\n",
      "Iter 530, Minibatch Loss ---- Train = 0.220198; Test = 0.190900\n",
      "Iter 531, Minibatch Loss ---- Train = 0.221459; Test = 0.189250\n",
      "Iter 532, Minibatch Loss ---- Train = 0.234505; Test = 0.190920\n",
      "Iter 533, Minibatch Loss ---- Train = 0.212547; Test = 0.190258\n",
      "Iter 534, Minibatch Loss ---- Train = 0.240463; Test = 0.187345\n",
      "Iter 535, Minibatch Loss ---- Train = 0.216097; Test = 0.189427\n",
      "Iter 536, Minibatch Loss ---- Train = 0.188778; Test = 0.192151\n",
      "Iter 537, Minibatch Loss ---- Train = 0.221419; Test = 0.188124\n",
      "Iter 538, Minibatch Loss ---- Train = 0.209739; Test = 0.189607\n",
      "Iter 539, Minibatch Loss ---- Train = 0.206475; Test = 0.188756\n",
      "Iter 540, Minibatch Loss ---- Train = 0.215721; Test = 0.187740\n",
      "Iter 541, Minibatch Loss ---- Train = 0.219058; Test = 0.191724\n",
      "Iter 542, Minibatch Loss ---- Train = 0.233130; Test = 0.187246\n",
      "Iter 543, Minibatch Loss ---- Train = 0.188521; Test = 0.188535\n",
      "Iter 544, Minibatch Loss ---- Train = 0.241220; Test = 0.191282\n",
      "Iter 545, Minibatch Loss ---- Train = 0.239209; Test = 0.189006\n",
      "Iter 546, Minibatch Loss ---- Train = 0.232649; Test = 0.189851\n",
      "Iter 547, Minibatch Loss ---- Train = 0.200327; Test = 0.190475\n",
      "Iter 548, Minibatch Loss ---- Train = 0.219282; Test = 0.189960\n",
      "Iter 549, Minibatch Loss ---- Train = 0.184126; Test = 0.190182\n",
      "Iter 550, Minibatch Loss ---- Train = 0.207088; Test = 0.186596\n",
      "Iter 551, Minibatch Loss ---- Train = 0.229760; Test = 0.195839\n",
      "Iter 552, Minibatch Loss ---- Train = 0.202361; Test = 0.187897\n",
      "Iter 553, Minibatch Loss ---- Train = 0.180282; Test = 0.186034\n",
      "Iter 554, Minibatch Loss ---- Train = 0.197855; Test = 0.186951\n",
      "Iter 555, Minibatch Loss ---- Train = 0.206449; Test = 0.188432\n",
      "Iter 556, Minibatch Loss ---- Train = 0.253162; Test = 0.191014\n",
      "Iter 557, Minibatch Loss ---- Train = 0.199619; Test = 0.191477\n",
      "Iter 558, Minibatch Loss ---- Train = 0.225657; Test = 0.188457\n",
      "Iter 559, Minibatch Loss ---- Train = 0.217027; Test = 0.189967\n",
      "Iter 560, Minibatch Loss ---- Train = 0.204354; Test = 0.190844\n",
      "Iter 561, Minibatch Loss ---- Train = 0.197037; Test = 0.188062\n",
      "Iter 562, Minibatch Loss ---- Train = 0.241342; Test = 0.190860\n",
      "Iter 563, Minibatch Loss ---- Train = 0.231893; Test = 0.190045\n",
      "Iter 564, Minibatch Loss ---- Train = 0.229940; Test = 0.189642\n",
      "Iter 565, Minibatch Loss ---- Train = 0.205652; Test = 0.187859\n",
      "Iter 566, Minibatch Loss ---- Train = 0.209999; Test = 0.191287\n",
      "Iter 567, Minibatch Loss ---- Train = 0.215726; Test = 0.190278\n",
      "Iter 568, Minibatch Loss ---- Train = 0.202934; Test = 0.187025\n",
      "Iter 569, Minibatch Loss ---- Train = 0.180237; Test = 0.187670\n",
      "Iter 570, Minibatch Loss ---- Train = 0.202192; Test = 0.196238\n",
      "Iter 571, Minibatch Loss ---- Train = 0.210642; Test = 0.187243\n",
      "Iter 572, Minibatch Loss ---- Train = 0.210312; Test = 0.189950\n",
      "Iter 573, Minibatch Loss ---- Train = 0.192538; Test = 0.189546\n",
      "Iter 574, Minibatch Loss ---- Train = 0.220005; Test = 0.189281\n",
      "Iter 575, Minibatch Loss ---- Train = 0.239690; Test = 0.188868\n",
      "Iter 576, Minibatch Loss ---- Train = 0.191485; Test = 0.192239\n",
      "Iter 577, Minibatch Loss ---- Train = 0.230912; Test = 0.189648\n",
      "Iter 578, Minibatch Loss ---- Train = 0.238107; Test = 0.185558\n",
      "Iter 579, Minibatch Loss ---- Train = 0.192308; Test = 0.188876\n",
      "Iter 580, Minibatch Loss ---- Train = 0.200557; Test = 0.191424\n",
      "Iter 581, Minibatch Loss ---- Train = 0.171581; Test = 0.190155\n",
      "Iter 582, Minibatch Loss ---- Train = 0.243700; Test = 0.189616\n",
      "Iter 583, Minibatch Loss ---- Train = 0.213784; Test = 0.188040\n",
      "Iter 584, Minibatch Loss ---- Train = 0.223664; Test = 0.188672\n",
      "Iter 585, Minibatch Loss ---- Train = 0.216787; Test = 0.190640\n",
      "Iter 586, Minibatch Loss ---- Train = 0.190538; Test = 0.190635\n",
      "Iter 587, Minibatch Loss ---- Train = 0.227311; Test = 0.188473\n",
      "Iter 588, Minibatch Loss ---- Train = 0.208035; Test = 0.189432\n",
      "Iter 589, Minibatch Loss ---- Train = 0.214906; Test = 0.188106\n",
      "Iter 590, Minibatch Loss ---- Train = 0.227841; Test = 0.189235\n",
      "Iter 591, Minibatch Loss ---- Train = 0.200363; Test = 0.188193\n",
      "Iter 592, Minibatch Loss ---- Train = 0.193305; Test = 0.189479\n",
      "Iter 593, Minibatch Loss ---- Train = 0.211396; Test = 0.190227\n",
      "Iter 594, Minibatch Loss ---- Train = 0.210952; Test = 0.191577\n",
      "Iter 595, Minibatch Loss ---- Train = 0.213758; Test = 0.187537\n",
      "Iter 596, Minibatch Loss ---- Train = 0.228151; Test = 0.186844\n",
      "Iter 597, Minibatch Loss ---- Train = 0.208062; Test = 0.187190\n",
      "Iter 598, Minibatch Loss ---- Train = 0.193601; Test = 0.189619\n",
      "Iter 599, Minibatch Loss ---- Train = 0.186026; Test = 0.189983\n",
      "Iter 600, Minibatch Loss ---- Train = 0.192367; Test = 0.193010\n",
      "Iter 601, Minibatch Loss ---- Train = 0.223292; Test = 0.186736\n",
      "Iter 602, Minibatch Loss ---- Train = 0.212765; Test = 0.189491\n",
      "Iter 603, Minibatch Loss ---- Train = 0.213842; Test = 0.189236\n",
      "Iter 604, Minibatch Loss ---- Train = 0.207284; Test = 0.190892\n",
      "Iter 605, Minibatch Loss ---- Train = 0.200892; Test = 0.187848\n",
      "Iter 606, Minibatch Loss ---- Train = 0.205195; Test = 0.186053\n",
      "Iter 607, Minibatch Loss ---- Train = 0.177987; Test = 0.187446\n",
      "Iter 608, Minibatch Loss ---- Train = 0.226026; Test = 0.195341\n",
      "Iter 609, Minibatch Loss ---- Train = 0.186898; Test = 0.188119\n",
      "Iter 610, Minibatch Loss ---- Train = 0.227906; Test = 0.186670\n",
      "Iter 611, Minibatch Loss ---- Train = 0.224456; Test = 0.189164\n",
      "Iter 612, Minibatch Loss ---- Train = 0.233150; Test = 0.189054\n",
      "Iter 613, Minibatch Loss ---- Train = 0.192189; Test = 0.187730\n",
      "Iter 614, Minibatch Loss ---- Train = 0.197113; Test = 0.190339\n",
      "Iter 615, Minibatch Loss ---- Train = 0.231121; Test = 0.188713\n",
      "Iter 616, Minibatch Loss ---- Train = 0.189742; Test = 0.189194\n",
      "Iter 617, Minibatch Loss ---- Train = 0.194208; Test = 0.187597\n",
      "Iter 618, Minibatch Loss ---- Train = 0.276609; Test = 0.189351\n",
      "Iter 619, Minibatch Loss ---- Train = 0.206594; Test = 0.188154\n",
      "Iter 620, Minibatch Loss ---- Train = 0.208590; Test = 0.190514\n",
      "Iter 621, Minibatch Loss ---- Train = 0.236180; Test = 0.187083\n",
      "Iter 622, Minibatch Loss ---- Train = 0.223209; Test = 0.188765\n",
      "Iter 623, Minibatch Loss ---- Train = 0.229467; Test = 0.190209\n",
      "Iter 624, Minibatch Loss ---- Train = 0.253229; Test = 0.190370\n",
      "Iter 625, Minibatch Loss ---- Train = 0.202068; Test = 0.188905\n",
      "Iter 626, Minibatch Loss ---- Train = 0.202190; Test = 0.191307\n",
      "Iter 627, Minibatch Loss ---- Train = 0.223952; Test = 0.187238\n",
      "Iter 628, Minibatch Loss ---- Train = 0.206746; Test = 0.190152\n",
      "Iter 629, Minibatch Loss ---- Train = 0.217261; Test = 0.187989\n",
      "Iter 630, Minibatch Loss ---- Train = 0.224039; Test = 0.185295\n",
      "Iter 631, Minibatch Loss ---- Train = 0.210354; Test = 0.186208\n",
      "Iter 632, Minibatch Loss ---- Train = 0.243296; Test = 0.188683\n",
      "Iter 633, Minibatch Loss ---- Train = 0.202312; Test = 0.192534\n",
      "Iter 634, Minibatch Loss ---- Train = 0.233384; Test = 0.188184\n",
      "Iter 635, Minibatch Loss ---- Train = 0.214216; Test = 0.188316\n",
      "Iter 636, Minibatch Loss ---- Train = 0.217816; Test = 0.188289\n",
      "Iter 637, Minibatch Loss ---- Train = 0.222316; Test = 0.187909\n",
      "Iter 638, Minibatch Loss ---- Train = 0.192534; Test = 0.189569\n",
      "Iter 639, Minibatch Loss ---- Train = 0.218461; Test = 0.187329\n",
      "Iter 640, Minibatch Loss ---- Train = 0.207603; Test = 0.187263\n",
      "Iter 641, Minibatch Loss ---- Train = 0.174560; Test = 0.187184\n",
      "Iter 642, Minibatch Loss ---- Train = 0.248890; Test = 0.184572\n",
      "Iter 643, Minibatch Loss ---- Train = 0.210123; Test = 0.188643\n",
      "Iter 644, Minibatch Loss ---- Train = 0.192050; Test = 0.189302\n",
      "Iter 645, Minibatch Loss ---- Train = 0.208088; Test = 0.189860\n",
      "Iter 646, Minibatch Loss ---- Train = 0.201635; Test = 0.186642\n",
      "Iter 647, Minibatch Loss ---- Train = 0.216410; Test = 0.186703\n",
      "Iter 648, Minibatch Loss ---- Train = 0.194399; Test = 0.186338\n",
      "Iter 649, Minibatch Loss ---- Train = 0.226184; Test = 0.190548\n",
      "Iter 650, Minibatch Loss ---- Train = 0.219117; Test = 0.187145\n",
      "Iter 651, Minibatch Loss ---- Train = 0.203576; Test = 0.188460\n",
      "Iter 652, Minibatch Loss ---- Train = 0.200321; Test = 0.186473\n",
      "Iter 653, Minibatch Loss ---- Train = 0.205834; Test = 0.189776\n",
      "Iter 654, Minibatch Loss ---- Train = 0.212695; Test = 0.189148\n",
      "Iter 655, Minibatch Loss ---- Train = 0.234300; Test = 0.187755\n",
      "Iter 656, Minibatch Loss ---- Train = 0.196044; Test = 0.187733\n",
      "Iter 657, Minibatch Loss ---- Train = 0.213073; Test = 0.191670\n",
      "Iter 658, Minibatch Loss ---- Train = 0.199193; Test = 0.186782\n",
      "Iter 659, Minibatch Loss ---- Train = 0.184377; Test = 0.189033\n",
      "Iter 660, Minibatch Loss ---- Train = 0.211265; Test = 0.188313\n",
      "Iter 661, Minibatch Loss ---- Train = 0.201008; Test = 0.184703\n",
      "Iter 662, Minibatch Loss ---- Train = 0.247337; Test = 0.187425\n",
      "Iter 663, Minibatch Loss ---- Train = 0.213082; Test = 0.191449\n",
      "Iter 664, Minibatch Loss ---- Train = 0.214708; Test = 0.188926\n",
      "Iter 665, Minibatch Loss ---- Train = 0.205547; Test = 0.189333\n",
      "Iter 666, Minibatch Loss ---- Train = 0.237908; Test = 0.188140\n",
      "Iter 667, Minibatch Loss ---- Train = 0.207917; Test = 0.188186\n",
      "Iter 668, Minibatch Loss ---- Train = 0.216830; Test = 0.191150\n",
      "Iter 669, Minibatch Loss ---- Train = 0.230864; Test = 0.186901\n",
      "Iter 670, Minibatch Loss ---- Train = 0.184709; Test = 0.188926\n",
      "Iter 671, Minibatch Loss ---- Train = 0.207419; Test = 0.187251\n",
      "Iter 672, Minibatch Loss ---- Train = 0.215002; Test = 0.191724\n",
      "Iter 673, Minibatch Loss ---- Train = 0.251721; Test = 0.188469\n",
      "Iter 674, Minibatch Loss ---- Train = 0.207466; Test = 0.190369\n",
      "Iter 675, Minibatch Loss ---- Train = 0.191861; Test = 0.186737\n",
      "Iter 676, Minibatch Loss ---- Train = 0.229219; Test = 0.191830\n",
      "Iter 677, Minibatch Loss ---- Train = 0.223232; Test = 0.189638\n",
      "Iter 678, Minibatch Loss ---- Train = 0.242805; Test = 0.189891\n",
      "Iter 679, Minibatch Loss ---- Train = 0.228878; Test = 0.190571\n",
      "Iter 680, Minibatch Loss ---- Train = 0.200012; Test = 0.185108\n",
      "Iter 681, Minibatch Loss ---- Train = 0.223434; Test = 0.187837\n",
      "Iter 682, Minibatch Loss ---- Train = 0.190025; Test = 0.190440\n",
      "Iter 683, Minibatch Loss ---- Train = 0.235792; Test = 0.189640\n",
      "Iter 684, Minibatch Loss ---- Train = 0.188461; Test = 0.190132\n",
      "Iter 685, Minibatch Loss ---- Train = 0.168659; Test = 0.186520\n",
      "Iter 686, Minibatch Loss ---- Train = 0.214374; Test = 0.187359\n",
      "Iter 687, Minibatch Loss ---- Train = 0.235091; Test = 0.189128\n",
      "Iter 688, Minibatch Loss ---- Train = 0.214114; Test = 0.187658\n",
      "Iter 689, Minibatch Loss ---- Train = 0.196225; Test = 0.189626\n",
      "Iter 690, Minibatch Loss ---- Train = 0.206758; Test = 0.185060\n",
      "Iter 691, Minibatch Loss ---- Train = 0.229246; Test = 0.188081\n",
      "Iter 692, Minibatch Loss ---- Train = 0.200366; Test = 0.192523\n",
      "Iter 693, Minibatch Loss ---- Train = 0.215372; Test = 0.186861\n",
      "Iter 694, Minibatch Loss ---- Train = 0.194994; Test = 0.191510\n",
      "Iter 695, Minibatch Loss ---- Train = 0.204753; Test = 0.185838\n",
      "Iter 696, Minibatch Loss ---- Train = 0.197254; Test = 0.190085\n",
      "Iter 697, Minibatch Loss ---- Train = 0.199909; Test = 0.188068\n",
      "Iter 698, Minibatch Loss ---- Train = 0.209307; Test = 0.188754\n",
      "Iter 699, Minibatch Loss ---- Train = 0.232548; Test = 0.187844\n",
      "Iter 700, Minibatch Loss ---- Train = 0.218518; Test = 0.187741\n",
      "Iter 701, Minibatch Loss ---- Train = 0.226921; Test = 0.189312\n",
      "Iter 702, Minibatch Loss ---- Train = 0.206906; Test = 0.189416\n",
      "Iter 703, Minibatch Loss ---- Train = 0.235820; Test = 0.187059\n",
      "Iter 704, Minibatch Loss ---- Train = 0.191947; Test = 0.190376\n",
      "Iter 705, Minibatch Loss ---- Train = 0.205029; Test = 0.187649\n",
      "Iter 706, Minibatch Loss ---- Train = 0.209165; Test = 0.192617\n",
      "Iter 707, Minibatch Loss ---- Train = 0.188064; Test = 0.185584\n",
      "Iter 708, Minibatch Loss ---- Train = 0.249967; Test = 0.186406\n",
      "Iter 709, Minibatch Loss ---- Train = 0.212907; Test = 0.188551\n",
      "Iter 710, Minibatch Loss ---- Train = 0.204302; Test = 0.199611\n",
      "Iter 711, Minibatch Loss ---- Train = 0.222150; Test = 0.185890\n",
      "Iter 712, Minibatch Loss ---- Train = 0.210069; Test = 0.185489\n",
      "Iter 713, Minibatch Loss ---- Train = 0.200662; Test = 0.187752\n",
      "Iter 714, Minibatch Loss ---- Train = 0.263937; Test = 0.185856\n",
      "Iter 715, Minibatch Loss ---- Train = 0.201058; Test = 0.192875\n",
      "Iter 716, Minibatch Loss ---- Train = 0.207733; Test = 0.187516\n",
      "Iter 717, Minibatch Loss ---- Train = 0.240439; Test = 0.189367\n",
      "Iter 718, Minibatch Loss ---- Train = 0.190613; Test = 0.186586\n",
      "Iter 719, Minibatch Loss ---- Train = 0.204048; Test = 0.190703\n",
      "Iter 720, Minibatch Loss ---- Train = 0.208240; Test = 0.188618\n",
      "Iter 721, Minibatch Loss ---- Train = 0.183180; Test = 0.190652\n",
      "Iter 722, Minibatch Loss ---- Train = 0.238578; Test = 0.189189\n",
      "Iter 723, Minibatch Loss ---- Train = 0.217338; Test = 0.189828\n",
      "Iter 724, Minibatch Loss ---- Train = 0.207612; Test = 0.190476\n",
      "Iter 725, Minibatch Loss ---- Train = 0.217400; Test = 0.189739\n",
      "Iter 726, Minibatch Loss ---- Train = 0.199944; Test = 0.186740\n",
      "Iter 727, Minibatch Loss ---- Train = 0.179512; Test = 0.188910\n",
      "Iter 728, Minibatch Loss ---- Train = 0.187449; Test = 0.189925\n",
      "Iter 729, Minibatch Loss ---- Train = 0.206109; Test = 0.185636\n",
      "Iter 730, Minibatch Loss ---- Train = 0.179342; Test = 0.187069\n",
      "Iter 731, Minibatch Loss ---- Train = 0.208046; Test = 0.194429\n",
      "Iter 732, Minibatch Loss ---- Train = 0.221048; Test = 0.186488\n",
      "Iter 733, Minibatch Loss ---- Train = 0.226474; Test = 0.188321\n",
      "Iter 734, Minibatch Loss ---- Train = 0.223528; Test = 0.190110\n",
      "Iter 735, Minibatch Loss ---- Train = 0.220206; Test = 0.188463\n",
      "Iter 736, Minibatch Loss ---- Train = 0.221562; Test = 0.189005\n",
      "Iter 737, Minibatch Loss ---- Train = 0.198965; Test = 0.188567\n",
      "Iter 738, Minibatch Loss ---- Train = 0.218277; Test = 0.187995\n",
      "Iter 739, Minibatch Loss ---- Train = 0.200114; Test = 0.192098\n",
      "Iter 740, Minibatch Loss ---- Train = 0.205690; Test = 0.187116\n",
      "Iter 741, Minibatch Loss ---- Train = 0.193679; Test = 0.189868\n",
      "Iter 742, Minibatch Loss ---- Train = 0.198621; Test = 0.188715\n",
      "Iter 743, Minibatch Loss ---- Train = 0.247940; Test = 0.187953\n",
      "Iter 744, Minibatch Loss ---- Train = 0.264406; Test = 0.190687\n",
      "Iter 745, Minibatch Loss ---- Train = 0.220390; Test = 0.193108\n",
      "Iter 746, Minibatch Loss ---- Train = 0.201103; Test = 0.186782\n",
      "Iter 747, Minibatch Loss ---- Train = 0.213044; Test = 0.190079\n",
      "Iter 748, Minibatch Loss ---- Train = 0.171512; Test = 0.188135\n",
      "Iter 749, Minibatch Loss ---- Train = 0.244712; Test = 0.187363\n",
      "Iter 750, Minibatch Loss ---- Train = 0.189163; Test = 0.190428\n",
      "Iter 751, Minibatch Loss ---- Train = 0.250791; Test = 0.186732\n",
      "Iter 752, Minibatch Loss ---- Train = 0.185495; Test = 0.188675\n",
      "Iter 753, Minibatch Loss ---- Train = 0.206527; Test = 0.189249\n",
      "Iter 754, Minibatch Loss ---- Train = 0.218785; Test = 0.188792\n",
      "Iter 755, Minibatch Loss ---- Train = 0.214736; Test = 0.188246\n",
      "Iter 756, Minibatch Loss ---- Train = 0.200868; Test = 0.185796\n",
      "Iter 757, Minibatch Loss ---- Train = 0.196415; Test = 0.191813\n",
      "Iter 758, Minibatch Loss ---- Train = 0.206130; Test = 0.186725\n",
      "Iter 759, Minibatch Loss ---- Train = 0.214321; Test = 0.187020\n",
      "Iter 760, Minibatch Loss ---- Train = 0.206019; Test = 0.189082\n",
      "Iter 761, Minibatch Loss ---- Train = 0.227102; Test = 0.186775\n",
      "Iter 762, Minibatch Loss ---- Train = 0.195213; Test = 0.188732\n",
      "Iter 763, Minibatch Loss ---- Train = 0.231943; Test = 0.188670\n",
      "Iter 764, Minibatch Loss ---- Train = 0.232449; Test = 0.186316\n",
      "Iter 765, Minibatch Loss ---- Train = 0.183181; Test = 0.189110\n",
      "Iter 766, Minibatch Loss ---- Train = 0.215830; Test = 0.188593\n",
      "Iter 767, Minibatch Loss ---- Train = 0.248759; Test = 0.188829\n",
      "Iter 768, Minibatch Loss ---- Train = 0.210280; Test = 0.186885\n",
      "Iter 769, Minibatch Loss ---- Train = 0.213716; Test = 0.188218\n",
      "Iter 770, Minibatch Loss ---- Train = 0.218843; Test = 0.187446\n",
      "Iter 771, Minibatch Loss ---- Train = 0.227185; Test = 0.186122\n",
      "Iter 772, Minibatch Loss ---- Train = 0.170894; Test = 0.185841\n",
      "Iter 773, Minibatch Loss ---- Train = 0.230525; Test = 0.186577\n",
      "Iter 774, Minibatch Loss ---- Train = 0.179495; Test = 0.190949\n",
      "Iter 775, Minibatch Loss ---- Train = 0.205049; Test = 0.187651\n",
      "Iter 776, Minibatch Loss ---- Train = 0.244331; Test = 0.185298\n",
      "Iter 777, Minibatch Loss ---- Train = 0.163536; Test = 0.188987\n",
      "Iter 778, Minibatch Loss ---- Train = 0.227243; Test = 0.184205\n",
      "Iter 779, Minibatch Loss ---- Train = 0.191950; Test = 0.189726\n",
      "Iter 780, Minibatch Loss ---- Train = 0.208838; Test = 0.188950\n",
      "Iter 781, Minibatch Loss ---- Train = 0.207230; Test = 0.186318\n",
      "Iter 782, Minibatch Loss ---- Train = 0.218344; Test = 0.187376\n",
      "Iter 783, Minibatch Loss ---- Train = 0.253722; Test = 0.188127\n",
      "Iter 784, Minibatch Loss ---- Train = 0.199576; Test = 0.186563\n",
      "Iter 785, Minibatch Loss ---- Train = 0.190269; Test = 0.189557\n",
      "Iter 786, Minibatch Loss ---- Train = 0.251616; Test = 0.186192\n",
      "Iter 787, Minibatch Loss ---- Train = 0.211456; Test = 0.186658\n",
      "Iter 788, Minibatch Loss ---- Train = 0.203217; Test = 0.187727\n",
      "Iter 789, Minibatch Loss ---- Train = 0.202851; Test = 0.187806\n",
      "Iter 790, Minibatch Loss ---- Train = 0.211436; Test = 0.188065\n",
      "Iter 791, Minibatch Loss ---- Train = 0.191464; Test = 0.190961\n",
      "Iter 792, Minibatch Loss ---- Train = 0.190431; Test = 0.188513\n",
      "Iter 793, Minibatch Loss ---- Train = 0.213234; Test = 0.185695\n",
      "Iter 794, Minibatch Loss ---- Train = 0.227983; Test = 0.188425\n",
      "Iter 795, Minibatch Loss ---- Train = 0.203839; Test = 0.194069\n",
      "Iter 796, Minibatch Loss ---- Train = 0.206774; Test = 0.186268\n",
      "Iter 797, Minibatch Loss ---- Train = 0.202413; Test = 0.188157\n",
      "Iter 798, Minibatch Loss ---- Train = 0.187752; Test = 0.187118\n",
      "Iter 799, Minibatch Loss ---- Train = 0.216500; Test = 0.189761\n",
      "[0.74253758831915095, 0.73950170898298895, 0.74277358640103996, 0.7441710434884915, 0.74181681496052354, 0.73626359135328234, 0.74331740263285773, 0.74176191297505745, 0.74492446218127417, 0.74082825935210328]\n",
      "total running time cost:863.338108063s\n",
      "Iter 0, Minibatch Loss ---- Train = 5.595959; Test = 5.545074\n",
      "Iter 1, Minibatch Loss ---- Train = 5.180895; Test = 5.055632\n",
      "Iter 2, Minibatch Loss ---- Train = 4.626935; Test = 4.588461\n",
      "Iter 3, Minibatch Loss ---- Train = 4.165640; Test = 4.128243\n",
      "Iter 4, Minibatch Loss ---- Train = 3.532730; Test = 3.685880\n",
      "Iter 5, Minibatch Loss ---- Train = 3.193573; Test = 3.271081\n",
      "Iter 6, Minibatch Loss ---- Train = 2.836119; Test = 2.871462\n",
      "Iter 7, Minibatch Loss ---- Train = 2.410836; Test = 2.455648\n",
      "Iter 8, Minibatch Loss ---- Train = 2.042397; Test = 2.032817\n",
      "Iter 9, Minibatch Loss ---- Train = 1.745822; Test = 1.735387\n",
      "Iter 10, Minibatch Loss ---- Train = 1.497928; Test = 1.476823\n",
      "Iter 11, Minibatch Loss ---- Train = 1.256593; Test = 1.249126\n",
      "Iter 12, Minibatch Loss ---- Train = 1.051087; Test = 1.052366\n",
      "Iter 13, Minibatch Loss ---- Train = 0.946151; Test = 0.885494\n",
      "Iter 14, Minibatch Loss ---- Train = 0.738856; Test = 0.739825\n",
      "Iter 15, Minibatch Loss ---- Train = 0.629086; Test = 0.611972\n",
      "Iter 16, Minibatch Loss ---- Train = 0.503175; Test = 0.504948\n",
      "Iter 17, Minibatch Loss ---- Train = 0.444591; Test = 0.419384\n",
      "Iter 18, Minibatch Loss ---- Train = 0.350734; Test = 0.354205\n",
      "Iter 19, Minibatch Loss ---- Train = 0.348550; Test = 0.323327\n",
      "Iter 20, Minibatch Loss ---- Train = 0.311969; Test = 0.311600\n",
      "Iter 21, Minibatch Loss ---- Train = 0.307023; Test = 0.315784\n",
      "Iter 22, Minibatch Loss ---- Train = 0.265316; Test = 0.289250\n",
      "Iter 23, Minibatch Loss ---- Train = 0.339709; Test = 0.333682\n",
      "Iter 24, Minibatch Loss ---- Train = 0.318875; Test = 0.280274\n",
      "Iter 25, Minibatch Loss ---- Train = 0.295796; Test = 0.299268\n",
      "Iter 26, Minibatch Loss ---- Train = 0.306871; Test = 0.288613\n",
      "Iter 27, Minibatch Loss ---- Train = 0.339535; Test = 0.292577\n",
      "Iter 28, Minibatch Loss ---- Train = 0.246887; Test = 0.255490\n",
      "Iter 29, Minibatch Loss ---- Train = 0.263985; Test = 0.289316\n",
      "Iter 30, Minibatch Loss ---- Train = 0.228491; Test = 0.257516\n",
      "Iter 31, Minibatch Loss ---- Train = 0.297424; Test = 0.293304\n",
      "Iter 32, Minibatch Loss ---- Train = 0.243237; Test = 0.254500\n",
      "Iter 33, Minibatch Loss ---- Train = 0.290077; Test = 0.283136\n",
      "Iter 34, Minibatch Loss ---- Train = 0.262021; Test = 0.256136\n",
      "Iter 35, Minibatch Loss ---- Train = 0.296667; Test = 0.295583\n",
      "Iter 36, Minibatch Loss ---- Train = 0.247060; Test = 0.252612\n",
      "Iter 37, Minibatch Loss ---- Train = 0.308073; Test = 0.277054\n",
      "Iter 38, Minibatch Loss ---- Train = 0.251606; Test = 0.251565\n",
      "Iter 39, Minibatch Loss ---- Train = 0.289530; Test = 0.289034\n",
      "Iter 40, Minibatch Loss ---- Train = 0.215389; Test = 0.248560\n",
      "Iter 41, Minibatch Loss ---- Train = 0.316679; Test = 0.273246\n",
      "Iter 42, Minibatch Loss ---- Train = 0.217242; Test = 0.247243\n",
      "Iter 43, Minibatch Loss ---- Train = 0.317827; Test = 0.280655\n",
      "Iter 44, Minibatch Loss ---- Train = 0.288791; Test = 0.244497\n",
      "Iter 45, Minibatch Loss ---- Train = 0.276654; Test = 0.270051\n",
      "Iter 46, Minibatch Loss ---- Train = 0.238525; Test = 0.244575\n",
      "Iter 47, Minibatch Loss ---- Train = 0.315045; Test = 0.277293\n",
      "Iter 48, Minibatch Loss ---- Train = 0.281676; Test = 0.242546\n",
      "Iter 49, Minibatch Loss ---- Train = 0.263806; Test = 0.269537\n",
      "Iter 50, Minibatch Loss ---- Train = 0.309957; Test = 0.262161\n",
      "Iter 51, Minibatch Loss ---- Train = 0.236835; Test = 0.253844\n",
      "Iter 52, Minibatch Loss ---- Train = 0.259436; Test = 0.244620\n",
      "Iter 53, Minibatch Loss ---- Train = 0.235995; Test = 0.238101\n",
      "Iter 54, Minibatch Loss ---- Train = 0.215219; Test = 0.235051\n",
      "Iter 55, Minibatch Loss ---- Train = 0.221622; Test = 0.234329\n",
      "Iter 56, Minibatch Loss ---- Train = 0.257613; Test = 0.234886\n",
      "Iter 57, Minibatch Loss ---- Train = 0.261135; Test = 0.233668\n",
      "Iter 58, Minibatch Loss ---- Train = 0.238285; Test = 0.234885\n",
      "Iter 59, Minibatch Loss ---- Train = 0.282597; Test = 0.234215\n",
      "Iter 60, Minibatch Loss ---- Train = 0.246762; Test = 0.234602\n",
      "Iter 61, Minibatch Loss ---- Train = 0.281939; Test = 0.230233\n",
      "Iter 62, Minibatch Loss ---- Train = 0.245484; Test = 0.233226\n",
      "Iter 63, Minibatch Loss ---- Train = 0.234916; Test = 0.232002\n",
      "Iter 64, Minibatch Loss ---- Train = 0.232204; Test = 0.230832\n",
      "Iter 65, Minibatch Loss ---- Train = 0.225571; Test = 0.229959\n",
      "Iter 66, Minibatch Loss ---- Train = 0.257100; Test = 0.230514\n",
      "Iter 67, Minibatch Loss ---- Train = 0.259714; Test = 0.226842\n",
      "Iter 68, Minibatch Loss ---- Train = 0.273467; Test = 0.231372\n",
      "Iter 69, Minibatch Loss ---- Train = 0.264980; Test = 0.226573\n",
      "Iter 70, Minibatch Loss ---- Train = 0.224272; Test = 0.226980\n",
      "Iter 71, Minibatch Loss ---- Train = 0.238634; Test = 0.227206\n",
      "Iter 72, Minibatch Loss ---- Train = 0.240488; Test = 0.227287\n",
      "Iter 73, Minibatch Loss ---- Train = 0.235797; Test = 0.225614\n",
      "Iter 74, Minibatch Loss ---- Train = 0.218961; Test = 0.225284\n",
      "Iter 75, Minibatch Loss ---- Train = 0.204398; Test = 0.226019\n",
      "Iter 76, Minibatch Loss ---- Train = 0.258941; Test = 0.225566\n",
      "Iter 77, Minibatch Loss ---- Train = 0.242340; Test = 0.221978\n",
      "Iter 78, Minibatch Loss ---- Train = 0.218552; Test = 0.222854\n",
      "Iter 79, Minibatch Loss ---- Train = 0.214967; Test = 0.227067\n",
      "Iter 80, Minibatch Loss ---- Train = 0.201092; Test = 0.222215\n",
      "Iter 81, Minibatch Loss ---- Train = 0.231702; Test = 0.221770\n",
      "Iter 82, Minibatch Loss ---- Train = 0.227475; Test = 0.222757\n",
      "Iter 83, Minibatch Loss ---- Train = 0.227361; Test = 0.222376\n",
      "Iter 84, Minibatch Loss ---- Train = 0.222925; Test = 0.221606\n",
      "Iter 85, Minibatch Loss ---- Train = 0.237098; Test = 0.221411\n",
      "Iter 86, Minibatch Loss ---- Train = 0.255417; Test = 0.222434\n",
      "Iter 87, Minibatch Loss ---- Train = 0.240010; Test = 0.218825\n",
      "Iter 88, Minibatch Loss ---- Train = 0.216283; Test = 0.220332\n",
      "Iter 89, Minibatch Loss ---- Train = 0.243715; Test = 0.221442\n",
      "Iter 90, Minibatch Loss ---- Train = 0.224838; Test = 0.220098\n",
      "Iter 91, Minibatch Loss ---- Train = 0.214201; Test = 0.218268\n",
      "Iter 92, Minibatch Loss ---- Train = 0.228805; Test = 0.219547\n",
      "Iter 93, Minibatch Loss ---- Train = 0.239888; Test = 0.218885\n",
      "Iter 94, Minibatch Loss ---- Train = 0.208348; Test = 0.217698\n",
      "Iter 95, Minibatch Loss ---- Train = 0.234725; Test = 0.219480\n",
      "Iter 96, Minibatch Loss ---- Train = 0.223260; Test = 0.218440\n",
      "Iter 97, Minibatch Loss ---- Train = 0.189646; Test = 0.217456\n",
      "Iter 98, Minibatch Loss ---- Train = 0.229147; Test = 0.218302\n",
      "Iter 99, Minibatch Loss ---- Train = 0.195463; Test = 0.217338\n",
      "Iter 100, Minibatch Loss ---- Train = 0.238459; Test = 0.217242\n",
      "Iter 101, Minibatch Loss ---- Train = 0.207692; Test = 0.216571\n",
      "Iter 102, Minibatch Loss ---- Train = 0.196090; Test = 0.216569\n",
      "Iter 103, Minibatch Loss ---- Train = 0.204644; Test = 0.217353\n",
      "Iter 104, Minibatch Loss ---- Train = 0.191093; Test = 0.216225\n",
      "Iter 105, Minibatch Loss ---- Train = 0.215489; Test = 0.217334\n",
      "Iter 106, Minibatch Loss ---- Train = 0.208526; Test = 0.216527\n",
      "Iter 107, Minibatch Loss ---- Train = 0.205092; Test = 0.215836\n",
      "Iter 108, Minibatch Loss ---- Train = 0.216177; Test = 0.214956\n",
      "Iter 109, Minibatch Loss ---- Train = 0.248620; Test = 0.215117\n",
      "Iter 110, Minibatch Loss ---- Train = 0.212135; Test = 0.216585\n",
      "Iter 111, Minibatch Loss ---- Train = 0.196836; Test = 0.215330\n",
      "Iter 112, Minibatch Loss ---- Train = 0.215083; Test = 0.214908\n",
      "Iter 113, Minibatch Loss ---- Train = 0.202153; Test = 0.214547\n",
      "Iter 114, Minibatch Loss ---- Train = 0.205241; Test = 0.215375\n",
      "Iter 115, Minibatch Loss ---- Train = 0.208552; Test = 0.214592\n",
      "Iter 116, Minibatch Loss ---- Train = 0.202440; Test = 0.214999\n",
      "Iter 117, Minibatch Loss ---- Train = 0.208029; Test = 0.213886\n",
      "Iter 118, Minibatch Loss ---- Train = 0.231548; Test = 0.214818\n",
      "Iter 119, Minibatch Loss ---- Train = 0.202379; Test = 0.214318\n",
      "Iter 120, Minibatch Loss ---- Train = 0.234161; Test = 0.214284\n",
      "Iter 121, Minibatch Loss ---- Train = 0.222813; Test = 0.212551\n",
      "Iter 122, Minibatch Loss ---- Train = 0.222521; Test = 0.213092\n",
      "Iter 123, Minibatch Loss ---- Train = 0.228580; Test = 0.214043\n",
      "Iter 124, Minibatch Loss ---- Train = 0.207752; Test = 0.213062\n",
      "Iter 125, Minibatch Loss ---- Train = 0.195094; Test = 0.213517\n",
      "Iter 126, Minibatch Loss ---- Train = 0.216200; Test = 0.212705\n",
      "Iter 127, Minibatch Loss ---- Train = 0.214028; Test = 0.212531\n",
      "Iter 128, Minibatch Loss ---- Train = 0.230617; Test = 0.213334\n",
      "Iter 129, Minibatch Loss ---- Train = 0.255784; Test = 0.209963\n",
      "Iter 130, Minibatch Loss ---- Train = 0.195703; Test = 0.210563\n",
      "Iter 131, Minibatch Loss ---- Train = 0.220341; Test = 0.214650\n",
      "Iter 132, Minibatch Loss ---- Train = 0.205348; Test = 0.212140\n",
      "Iter 133, Minibatch Loss ---- Train = 0.217075; Test = 0.210199\n",
      "Iter 134, Minibatch Loss ---- Train = 0.225737; Test = 0.214081\n",
      "Iter 135, Minibatch Loss ---- Train = 0.224711; Test = 0.210741\n",
      "Iter 136, Minibatch Loss ---- Train = 0.228973; Test = 0.211900\n",
      "Iter 137, Minibatch Loss ---- Train = 0.215543; Test = 0.210141\n",
      "Iter 138, Minibatch Loss ---- Train = 0.215728; Test = 0.211854\n",
      "Iter 139, Minibatch Loss ---- Train = 0.185268; Test = 0.211460\n",
      "Iter 140, Minibatch Loss ---- Train = 0.234280; Test = 0.210703\n",
      "Iter 141, Minibatch Loss ---- Train = 0.188358; Test = 0.210522\n",
      "Iter 142, Minibatch Loss ---- Train = 0.240281; Test = 0.211844\n",
      "Iter 143, Minibatch Loss ---- Train = 0.232794; Test = 0.208478\n",
      "Iter 144, Minibatch Loss ---- Train = 0.206016; Test = 0.209841\n",
      "Iter 145, Minibatch Loss ---- Train = 0.197175; Test = 0.211959\n",
      "Iter 146, Minibatch Loss ---- Train = 0.214374; Test = 0.209998\n",
      "Iter 147, Minibatch Loss ---- Train = 0.225655; Test = 0.208058\n",
      "Iter 148, Minibatch Loss ---- Train = 0.208769; Test = 0.208184\n",
      "Iter 149, Minibatch Loss ---- Train = 0.202917; Test = 0.209837\n",
      "Iter 150, Minibatch Loss ---- Train = 0.202506; Test = 0.210599\n",
      "Iter 151, Minibatch Loss ---- Train = 0.182535; Test = 0.209192\n",
      "Iter 152, Minibatch Loss ---- Train = 0.229250; Test = 0.209427\n",
      "Iter 153, Minibatch Loss ---- Train = 0.218678; Test = 0.207444\n",
      "Iter 154, Minibatch Loss ---- Train = 0.227606; Test = 0.210153\n",
      "Iter 155, Minibatch Loss ---- Train = 0.200791; Test = 0.208672\n",
      "Iter 156, Minibatch Loss ---- Train = 0.233881; Test = 0.208925\n",
      "Iter 157, Minibatch Loss ---- Train = 0.222898; Test = 0.207213\n",
      "Iter 158, Minibatch Loss ---- Train = 0.191170; Test = 0.207104\n",
      "Iter 159, Minibatch Loss ---- Train = 0.201291; Test = 0.211216\n",
      "Iter 160, Minibatch Loss ---- Train = 0.210053; Test = 0.207585\n",
      "Iter 161, Minibatch Loss ---- Train = 0.212027; Test = 0.206496\n",
      "Iter 162, Minibatch Loss ---- Train = 0.244808; Test = 0.210487\n",
      "Iter 163, Minibatch Loss ---- Train = 0.222113; Test = 0.206232\n",
      "Iter 164, Minibatch Loss ---- Train = 0.226330; Test = 0.208681\n",
      "Iter 165, Minibatch Loss ---- Train = 0.208625; Test = 0.206959\n",
      "Iter 166, Minibatch Loss ---- Train = 0.228292; Test = 0.207546\n",
      "Iter 167, Minibatch Loss ---- Train = 0.226175; Test = 0.206562\n",
      "Iter 168, Minibatch Loss ---- Train = 0.218444; Test = 0.208435\n",
      "Iter 169, Minibatch Loss ---- Train = 0.253401; Test = 0.205718\n",
      "Iter 170, Minibatch Loss ---- Train = 0.231233; Test = 0.210002\n",
      "Iter 171, Minibatch Loss ---- Train = 0.195234; Test = 0.205441\n",
      "Iter 172, Minibatch Loss ---- Train = 0.193514; Test = 0.204628\n",
      "Iter 173, Minibatch Loss ---- Train = 0.233539; Test = 0.205251\n",
      "Iter 174, Minibatch Loss ---- Train = 0.233306; Test = 0.209371\n",
      "Iter 175, Minibatch Loss ---- Train = 0.226611; Test = 0.204611\n",
      "Iter 176, Minibatch Loss ---- Train = 0.218288; Test = 0.207534\n",
      "Iter 177, Minibatch Loss ---- Train = 0.201798; Test = 0.205184\n",
      "Iter 178, Minibatch Loss ---- Train = 0.219810; Test = 0.207465\n",
      "Iter 179, Minibatch Loss ---- Train = 0.210245; Test = 0.204469\n",
      "Iter 180, Minibatch Loss ---- Train = 0.212536; Test = 0.206562\n",
      "Iter 181, Minibatch Loss ---- Train = 0.200140; Test = 0.205061\n",
      "Iter 182, Minibatch Loss ---- Train = 0.211594; Test = 0.205837\n",
      "Iter 183, Minibatch Loss ---- Train = 0.198563; Test = 0.205252\n",
      "Iter 184, Minibatch Loss ---- Train = 0.212502; Test = 0.205452\n",
      "Iter 185, Minibatch Loss ---- Train = 0.221591; Test = 0.204224\n",
      "Iter 186, Minibatch Loss ---- Train = 0.190040; Test = 0.205038\n",
      "Iter 187, Minibatch Loss ---- Train = 0.199381; Test = 0.205528\n",
      "Iter 188, Minibatch Loss ---- Train = 0.193174; Test = 0.204304\n",
      "Iter 189, Minibatch Loss ---- Train = 0.197625; Test = 0.204271\n",
      "Iter 190, Minibatch Loss ---- Train = 0.223051; Test = 0.205730\n",
      "Iter 191, Minibatch Loss ---- Train = 0.207180; Test = 0.203715\n",
      "Iter 192, Minibatch Loss ---- Train = 0.239721; Test = 0.204489\n",
      "Iter 193, Minibatch Loss ---- Train = 0.195993; Test = 0.204007\n",
      "Iter 194, Minibatch Loss ---- Train = 0.197446; Test = 0.203967\n",
      "Iter 195, Minibatch Loss ---- Train = 0.230397; Test = 0.202694\n",
      "Iter 196, Minibatch Loss ---- Train = 0.200812; Test = 0.204102\n",
      "Iter 197, Minibatch Loss ---- Train = 0.190272; Test = 0.204315\n",
      "Iter 198, Minibatch Loss ---- Train = 0.180232; Test = 0.203799\n",
      "Iter 199, Minibatch Loss ---- Train = 0.195187; Test = 0.203707\n",
      "Iter 200, Minibatch Loss ---- Train = 0.226979; Test = 0.203692\n",
      "Iter 201, Minibatch Loss ---- Train = 0.192304; Test = 0.202797\n",
      "Iter 202, Minibatch Loss ---- Train = 0.223916; Test = 0.203807\n",
      "Iter 203, Minibatch Loss ---- Train = 0.236874; Test = 0.201497\n",
      "Iter 204, Minibatch Loss ---- Train = 0.195707; Test = 0.201936\n",
      "Iter 205, Minibatch Loss ---- Train = 0.228549; Test = 0.205123\n",
      "Iter 206, Minibatch Loss ---- Train = 0.176055; Test = 0.202887\n",
      "Iter 207, Minibatch Loss ---- Train = 0.202757; Test = 0.202056\n",
      "Iter 208, Minibatch Loss ---- Train = 0.220285; Test = 0.203382\n",
      "Iter 209, Minibatch Loss ---- Train = 0.207983; Test = 0.201908\n",
      "Iter 210, Minibatch Loss ---- Train = 0.222628; Test = 0.203249\n",
      "Iter 211, Minibatch Loss ---- Train = 0.212896; Test = 0.200949\n",
      "Iter 212, Minibatch Loss ---- Train = 0.181870; Test = 0.202446\n",
      "Iter 213, Minibatch Loss ---- Train = 0.199572; Test = 0.202437\n",
      "Iter 214, Minibatch Loss ---- Train = 0.218633; Test = 0.202615\n",
      "Iter 215, Minibatch Loss ---- Train = 0.231808; Test = 0.200035\n",
      "Iter 216, Minibatch Loss ---- Train = 0.211588; Test = 0.203888\n",
      "Iter 217, Minibatch Loss ---- Train = 0.207757; Test = 0.200634\n",
      "Iter 218, Minibatch Loss ---- Train = 0.211368; Test = 0.202218\n",
      "Iter 219, Minibatch Loss ---- Train = 0.206840; Test = 0.200339\n",
      "Iter 220, Minibatch Loss ---- Train = 0.201180; Test = 0.201993\n",
      "Iter 221, Minibatch Loss ---- Train = 0.204142; Test = 0.200931\n",
      "Iter 222, Minibatch Loss ---- Train = 0.232816; Test = 0.202102\n",
      "Iter 223, Minibatch Loss ---- Train = 0.214380; Test = 0.199343\n",
      "Iter 224, Minibatch Loss ---- Train = 0.188189; Test = 0.199955\n",
      "Iter 225, Minibatch Loss ---- Train = 0.220213; Test = 0.201412\n",
      "Iter 226, Minibatch Loss ---- Train = 0.219870; Test = 0.201750\n",
      "Iter 227, Minibatch Loss ---- Train = 0.218474; Test = 0.198849\n",
      "Iter 228, Minibatch Loss ---- Train = 0.203751; Test = 0.200487\n",
      "Iter 229, Minibatch Loss ---- Train = 0.221171; Test = 0.200281\n",
      "Iter 230, Minibatch Loss ---- Train = 0.188066; Test = 0.200501\n",
      "Iter 231, Minibatch Loss ---- Train = 0.207503; Test = 0.200607\n",
      "Iter 232, Minibatch Loss ---- Train = 0.194432; Test = 0.200310\n",
      "Iter 233, Minibatch Loss ---- Train = 0.193056; Test = 0.199069\n",
      "Iter 234, Minibatch Loss ---- Train = 0.149898; Test = 0.198085\n",
      "Iter 235, Minibatch Loss ---- Train = 0.218199; Test = 0.198682\n",
      "Iter 236, Minibatch Loss ---- Train = 0.189100; Test = 0.202393\n",
      "Iter 237, Minibatch Loss ---- Train = 0.208168; Test = 0.198262\n",
      "Iter 238, Minibatch Loss ---- Train = 0.169327; Test = 0.197868\n",
      "Iter 239, Minibatch Loss ---- Train = 0.217380; Test = 0.199876\n",
      "Iter 240, Minibatch Loss ---- Train = 0.213501; Test = 0.200012\n",
      "Iter 241, Minibatch Loss ---- Train = 0.199735; Test = 0.198239\n",
      "Iter 242, Minibatch Loss ---- Train = 0.211589; Test = 0.200182\n",
      "Iter 243, Minibatch Loss ---- Train = 0.197097; Test = 0.197527\n",
      "Iter 244, Minibatch Loss ---- Train = 0.192051; Test = 0.198096\n",
      "Iter 245, Minibatch Loss ---- Train = 0.209586; Test = 0.199394\n",
      "Iter 246, Minibatch Loss ---- Train = 0.177987; Test = 0.199194\n",
      "Iter 247, Minibatch Loss ---- Train = 0.220578; Test = 0.198185\n",
      "Iter 248, Minibatch Loss ---- Train = 0.205229; Test = 0.199905\n",
      "Iter 249, Minibatch Loss ---- Train = 0.213011; Test = 0.197390\n",
      "Iter 250, Minibatch Loss ---- Train = 0.217914; Test = 0.199978\n",
      "Iter 251, Minibatch Loss ---- Train = 0.214899; Test = 0.197435\n",
      "Iter 252, Minibatch Loss ---- Train = 0.172901; Test = 0.196930\n",
      "Iter 253, Minibatch Loss ---- Train = 0.202494; Test = 0.197810\n",
      "Iter 254, Minibatch Loss ---- Train = 0.207878; Test = 0.199842\n",
      "Iter 255, Minibatch Loss ---- Train = 0.199519; Test = 0.197116\n",
      "Iter 256, Minibatch Loss ---- Train = 0.161354; Test = 0.196397\n",
      "Iter 257, Minibatch Loss ---- Train = 0.209565; Test = 0.196914\n",
      "Iter 258, Minibatch Loss ---- Train = 0.237824; Test = 0.200368\n",
      "Iter 259, Minibatch Loss ---- Train = 0.188551; Test = 0.196291\n",
      "Iter 260, Minibatch Loss ---- Train = 0.222027; Test = 0.198565\n",
      "Iter 261, Minibatch Loss ---- Train = 0.175756; Test = 0.196639\n",
      "Iter 262, Minibatch Loss ---- Train = 0.200494; Test = 0.196758\n",
      "Iter 263, Minibatch Loss ---- Train = 0.210611; Test = 0.196955\n",
      "Iter 264, Minibatch Loss ---- Train = 0.182857; Test = 0.198114\n",
      "Iter 265, Minibatch Loss ---- Train = 0.210318; Test = 0.196710\n",
      "Iter 266, Minibatch Loss ---- Train = 0.193285; Test = 0.196904\n",
      "Iter 267, Minibatch Loss ---- Train = 0.224759; Test = 0.195701\n",
      "Iter 268, Minibatch Loss ---- Train = 0.177624; Test = 0.197021\n",
      "Iter 269, Minibatch Loss ---- Train = 0.189021; Test = 0.197877\n",
      "Iter 270, Minibatch Loss ---- Train = 0.175640; Test = 0.196208\n",
      "Iter 271, Minibatch Loss ---- Train = 0.170835; Test = 0.198058\n",
      "Iter 272, Minibatch Loss ---- Train = 0.193195; Test = 0.196029\n",
      "Iter 273, Minibatch Loss ---- Train = 0.223414; Test = 0.194202\n",
      "Iter 274, Minibatch Loss ---- Train = 0.212504; Test = 0.197246\n",
      "Iter 275, Minibatch Loss ---- Train = 0.175819; Test = 0.197603\n",
      "Iter 276, Minibatch Loss ---- Train = 0.188387; Test = 0.195644\n",
      "Iter 277, Minibatch Loss ---- Train = 0.168053; Test = 0.196524\n",
      "Iter 278, Minibatch Loss ---- Train = 0.194488; Test = 0.196372\n",
      "Iter 279, Minibatch Loss ---- Train = 0.212141; Test = 0.194510\n",
      "Iter 280, Minibatch Loss ---- Train = 0.193410; Test = 0.196981\n",
      "Iter 281, Minibatch Loss ---- Train = 0.223240; Test = 0.195772\n",
      "Iter 282, Minibatch Loss ---- Train = 0.207129; Test = 0.196656\n",
      "Iter 283, Minibatch Loss ---- Train = 0.195118; Test = 0.195584\n",
      "Iter 284, Minibatch Loss ---- Train = 0.193124; Test = 0.195761\n",
      "Iter 285, Minibatch Loss ---- Train = 0.195518; Test = 0.196140\n",
      "Iter 286, Minibatch Loss ---- Train = 0.191002; Test = 0.195689\n",
      "Iter 287, Minibatch Loss ---- Train = 0.229323; Test = 0.193943\n",
      "Iter 288, Minibatch Loss ---- Train = 0.194522; Test = 0.195985\n",
      "Iter 289, Minibatch Loss ---- Train = 0.213687; Test = 0.195604\n",
      "Iter 290, Minibatch Loss ---- Train = 0.213574; Test = 0.196653\n",
      "Iter 291, Minibatch Loss ---- Train = 0.162563; Test = 0.195078\n",
      "Iter 292, Minibatch Loss ---- Train = 0.203301; Test = 0.195198\n",
      "Iter 293, Minibatch Loss ---- Train = 0.193133; Test = 0.195013\n",
      "Iter 294, Minibatch Loss ---- Train = 0.185285; Test = 0.195949\n",
      "Iter 295, Minibatch Loss ---- Train = 0.191674; Test = 0.195338\n",
      "Iter 296, Minibatch Loss ---- Train = 0.232062; Test = 0.196769\n",
      "Iter 297, Minibatch Loss ---- Train = 0.191765; Test = 0.193773\n",
      "Iter 298, Minibatch Loss ---- Train = 0.213102; Test = 0.195615\n",
      "Iter 299, Minibatch Loss ---- Train = 0.213516; Test = 0.194643\n",
      "Iter 300, Minibatch Loss ---- Train = 0.186104; Test = 0.195437\n",
      "Iter 301, Minibatch Loss ---- Train = 0.189801; Test = 0.195207\n",
      "Iter 302, Minibatch Loss ---- Train = 0.196381; Test = 0.195024\n",
      "Iter 303, Minibatch Loss ---- Train = 0.201665; Test = 0.194116\n",
      "Iter 304, Minibatch Loss ---- Train = 0.202066; Test = 0.195008\n",
      "Iter 305, Minibatch Loss ---- Train = 0.200499; Test = 0.194331\n",
      "Iter 306, Minibatch Loss ---- Train = 0.219489; Test = 0.194973\n",
      "Iter 307, Minibatch Loss ---- Train = 0.207563; Test = 0.193797\n",
      "Iter 308, Minibatch Loss ---- Train = 0.210755; Test = 0.195470\n",
      "Iter 309, Minibatch Loss ---- Train = 0.211833; Test = 0.193127\n",
      "Iter 310, Minibatch Loss ---- Train = 0.160192; Test = 0.192562\n",
      "Iter 311, Minibatch Loss ---- Train = 0.174673; Test = 0.196779\n",
      "Iter 312, Minibatch Loss ---- Train = 0.187692; Test = 0.193998\n",
      "Iter 313, Minibatch Loss ---- Train = 0.210735; Test = 0.193204\n",
      "Iter 314, Minibatch Loss ---- Train = 0.166027; Test = 0.193710\n",
      "Iter 315, Minibatch Loss ---- Train = 0.185836; Test = 0.194482\n",
      "Iter 316, Minibatch Loss ---- Train = 0.227327; Test = 0.194384\n",
      "Iter 317, Minibatch Loss ---- Train = 0.201065; Test = 0.193305\n",
      "Iter 318, Minibatch Loss ---- Train = 0.202543; Test = 0.193956\n",
      "Iter 319, Minibatch Loss ---- Train = 0.184439; Test = 0.193557\n",
      "Iter 320, Minibatch Loss ---- Train = 0.200647; Test = 0.194391\n",
      "Iter 321, Minibatch Loss ---- Train = 0.201645; Test = 0.193043\n",
      "Iter 322, Minibatch Loss ---- Train = 0.184477; Test = 0.193971\n",
      "Iter 323, Minibatch Loss ---- Train = 0.213971; Test = 0.193483\n",
      "Iter 324, Minibatch Loss ---- Train = 0.202445; Test = 0.194717\n",
      "Iter 325, Minibatch Loss ---- Train = 0.197647; Test = 0.192573\n",
      "Iter 326, Minibatch Loss ---- Train = 0.174478; Test = 0.192764\n",
      "Iter 327, Minibatch Loss ---- Train = 0.181293; Test = 0.195619\n",
      "Iter 328, Minibatch Loss ---- Train = 0.215670; Test = 0.193046\n",
      "Iter 329, Minibatch Loss ---- Train = 0.196969; Test = 0.192018\n",
      "Iter 330, Minibatch Loss ---- Train = 0.203903; Test = 0.194565\n",
      "Iter 331, Minibatch Loss ---- Train = 0.179722; Test = 0.193163\n",
      "Iter 332, Minibatch Loss ---- Train = 0.179907; Test = 0.192325\n",
      "Iter 333, Minibatch Loss ---- Train = 0.185935; Test = 0.193452\n",
      "Iter 334, Minibatch Loss ---- Train = 0.196323; Test = 0.194419\n",
      "Iter 335, Minibatch Loss ---- Train = 0.167874; Test = 0.193637\n",
      "Iter 336, Minibatch Loss ---- Train = 0.187474; Test = 0.192245\n",
      "Iter 337, Minibatch Loss ---- Train = 0.207904; Test = 0.192569\n",
      "Iter 338, Minibatch Loss ---- Train = 0.190218; Test = 0.192992\n",
      "Iter 339, Minibatch Loss ---- Train = 0.212030; Test = 0.193112\n",
      "Iter 340, Minibatch Loss ---- Train = 0.194493; Test = 0.193589\n",
      "Iter 341, Minibatch Loss ---- Train = 0.238764; Test = 0.190847\n",
      "Iter 342, Minibatch Loss ---- Train = 0.182319; Test = 0.190706\n",
      "Iter 343, Minibatch Loss ---- Train = 0.193854; Test = 0.190630\n",
      "Iter 344, Minibatch Loss ---- Train = 0.194898; Test = 0.195948\n",
      "Iter 345, Minibatch Loss ---- Train = 0.216663; Test = 0.191467\n",
      "Iter 346, Minibatch Loss ---- Train = 0.215771; Test = 0.192562\n",
      "Iter 347, Minibatch Loss ---- Train = 0.201101; Test = 0.192312\n",
      "Iter 348, Minibatch Loss ---- Train = 0.206023; Test = 0.193573\n",
      "Iter 349, Minibatch Loss ---- Train = 0.184223; Test = 0.191843\n",
      "Iter 350, Minibatch Loss ---- Train = 0.211372; Test = 0.191807\n",
      "Iter 351, Minibatch Loss ---- Train = 0.186152; Test = 0.193209\n",
      "Iter 352, Minibatch Loss ---- Train = 0.202888; Test = 0.191722\n",
      "Iter 353, Minibatch Loss ---- Train = 0.210204; Test = 0.191247\n",
      "Iter 354, Minibatch Loss ---- Train = 0.185478; Test = 0.193012\n",
      "Iter 355, Minibatch Loss ---- Train = 0.190782; Test = 0.193172\n",
      "Iter 356, Minibatch Loss ---- Train = 0.193574; Test = 0.192730\n",
      "Iter 357, Minibatch Loss ---- Train = 0.192423; Test = 0.191652\n",
      "Iter 358, Minibatch Loss ---- Train = 0.226391; Test = 0.193219\n",
      "Iter 359, Minibatch Loss ---- Train = 0.185047; Test = 0.191055\n",
      "Iter 360, Minibatch Loss ---- Train = 0.194113; Test = 0.191117\n",
      "Iter 361, Minibatch Loss ---- Train = 0.225233; Test = 0.190745\n",
      "Iter 362, Minibatch Loss ---- Train = 0.236527; Test = 0.194083\n",
      "Iter 363, Minibatch Loss ---- Train = 0.191288; Test = 0.191329\n",
      "Iter 364, Minibatch Loss ---- Train = 0.171214; Test = 0.191003\n",
      "Iter 365, Minibatch Loss ---- Train = 0.195636; Test = 0.190606\n",
      "Iter 366, Minibatch Loss ---- Train = 0.186284; Test = 0.192131\n",
      "Iter 367, Minibatch Loss ---- Train = 0.200316; Test = 0.192952\n",
      "Iter 368, Minibatch Loss ---- Train = 0.209134; Test = 0.192391\n",
      "Iter 369, Minibatch Loss ---- Train = 0.209037; Test = 0.190363\n",
      "Iter 370, Minibatch Loss ---- Train = 0.195454; Test = 0.191905\n",
      "Iter 371, Minibatch Loss ---- Train = 0.201413; Test = 0.190943\n",
      "Iter 372, Minibatch Loss ---- Train = 0.204246; Test = 0.192183\n",
      "Iter 373, Minibatch Loss ---- Train = 0.206905; Test = 0.189933\n",
      "Iter 374, Minibatch Loss ---- Train = 0.220377; Test = 0.193286\n",
      "Iter 375, Minibatch Loss ---- Train = 0.195363; Test = 0.189951\n",
      "Iter 376, Minibatch Loss ---- Train = 0.199995; Test = 0.191439\n",
      "Iter 377, Minibatch Loss ---- Train = 0.218580; Test = 0.190561\n",
      "Iter 378, Minibatch Loss ---- Train = 0.192157; Test = 0.191389\n",
      "Iter 379, Minibatch Loss ---- Train = 0.181589; Test = 0.190990\n",
      "Iter 380, Minibatch Loss ---- Train = 0.199143; Test = 0.190777\n",
      "Iter 381, Minibatch Loss ---- Train = 0.221791; Test = 0.190126\n",
      "Iter 382, Minibatch Loss ---- Train = 0.197763; Test = 0.192251\n",
      "Iter 383, Minibatch Loss ---- Train = 0.174276; Test = 0.190939\n",
      "Iter 384, Minibatch Loss ---- Train = 0.193779; Test = 0.191042\n",
      "Iter 385, Minibatch Loss ---- Train = 0.190402; Test = 0.189937\n",
      "Iter 386, Minibatch Loss ---- Train = 0.188001; Test = 0.190832\n",
      "Iter 387, Minibatch Loss ---- Train = 0.201656; Test = 0.189935\n",
      "Iter 388, Minibatch Loss ---- Train = 0.216805; Test = 0.193204\n",
      "Iter 389, Minibatch Loss ---- Train = 0.185941; Test = 0.190273\n",
      "Iter 390, Minibatch Loss ---- Train = 0.207087; Test = 0.190341\n",
      "Iter 391, Minibatch Loss ---- Train = 0.187519; Test = 0.190474\n",
      "Iter 392, Minibatch Loss ---- Train = 0.178007; Test = 0.190957\n",
      "Iter 393, Minibatch Loss ---- Train = 0.214996; Test = 0.190125\n",
      "Iter 394, Minibatch Loss ---- Train = 0.214134; Test = 0.191712\n",
      "Iter 395, Minibatch Loss ---- Train = 0.166681; Test = 0.190148\n",
      "Iter 396, Minibatch Loss ---- Train = 0.185682; Test = 0.190374\n",
      "Iter 397, Minibatch Loss ---- Train = 0.201412; Test = 0.189610\n",
      "Iter 398, Minibatch Loss ---- Train = 0.206198; Test = 0.191774\n",
      "Iter 399, Minibatch Loss ---- Train = 0.212739; Test = 0.189551\n",
      "Iter 400, Minibatch Loss ---- Train = 0.219787; Test = 0.192105\n",
      "Iter 401, Minibatch Loss ---- Train = 0.187754; Test = 0.189074\n",
      "Iter 402, Minibatch Loss ---- Train = 0.195748; Test = 0.191022\n",
      "Iter 403, Minibatch Loss ---- Train = 0.198154; Test = 0.190370\n",
      "Iter 404, Minibatch Loss ---- Train = 0.185997; Test = 0.190738\n",
      "Iter 405, Minibatch Loss ---- Train = 0.193420; Test = 0.189180\n",
      "Iter 406, Minibatch Loss ---- Train = 0.196647; Test = 0.189854\n",
      "Iter 407, Minibatch Loss ---- Train = 0.204035; Test = 0.188824\n",
      "Iter 408, Minibatch Loss ---- Train = 0.194770; Test = 0.192316\n",
      "Iter 409, Minibatch Loss ---- Train = 0.197368; Test = 0.189814\n",
      "Iter 410, Minibatch Loss ---- Train = 0.198769; Test = 0.189350\n",
      "Iter 411, Minibatch Loss ---- Train = 0.208995; Test = 0.188654\n",
      "Iter 412, Minibatch Loss ---- Train = 0.195050; Test = 0.191612\n",
      "Iter 413, Minibatch Loss ---- Train = 0.182967; Test = 0.189811\n",
      "Iter 414, Minibatch Loss ---- Train = 0.203333; Test = 0.189910\n",
      "Iter 415, Minibatch Loss ---- Train = 0.181245; Test = 0.189733\n",
      "Iter 416, Minibatch Loss ---- Train = 0.191389; Test = 0.189792\n",
      "Iter 417, Minibatch Loss ---- Train = 0.159888; Test = 0.189827\n",
      "Iter 418, Minibatch Loss ---- Train = 0.163362; Test = 0.188833\n",
      "Iter 419, Minibatch Loss ---- Train = 0.191254; Test = 0.188680\n",
      "Iter 420, Minibatch Loss ---- Train = 0.210046; Test = 0.192425\n",
      "Iter 421, Minibatch Loss ---- Train = 0.199569; Test = 0.189326\n",
      "Iter 422, Minibatch Loss ---- Train = 0.198717; Test = 0.189067\n",
      "Iter 423, Minibatch Loss ---- Train = 0.182220; Test = 0.188983\n",
      "Iter 424, Minibatch Loss ---- Train = 0.165352; Test = 0.189514\n",
      "Iter 425, Minibatch Loss ---- Train = 0.203517; Test = 0.190477\n",
      "Iter 426, Minibatch Loss ---- Train = 0.190700; Test = 0.189468\n",
      "Iter 427, Minibatch Loss ---- Train = 0.215847; Test = 0.187966\n",
      "Iter 428, Minibatch Loss ---- Train = 0.208300; Test = 0.190911\n",
      "Iter 429, Minibatch Loss ---- Train = 0.187919; Test = 0.188814\n",
      "Iter 430, Minibatch Loss ---- Train = 0.178967; Test = 0.189346\n",
      "Iter 431, Minibatch Loss ---- Train = 0.175064; Test = 0.189660\n",
      "Iter 432, Minibatch Loss ---- Train = 0.191071; Test = 0.188898\n",
      "Iter 433, Minibatch Loss ---- Train = 0.174704; Test = 0.187637\n",
      "Iter 434, Minibatch Loss ---- Train = 0.199598; Test = 0.189900\n",
      "Iter 435, Minibatch Loss ---- Train = 0.177953; Test = 0.189082\n",
      "Iter 436, Minibatch Loss ---- Train = 0.230061; Test = 0.189447\n",
      "Iter 437, Minibatch Loss ---- Train = 0.195574; Test = 0.187741\n",
      "Iter 438, Minibatch Loss ---- Train = 0.183591; Test = 0.187011\n",
      "Iter 439, Minibatch Loss ---- Train = 0.219835; Test = 0.187147\n",
      "Iter 440, Minibatch Loss ---- Train = 0.212075; Test = 0.190592\n",
      "Iter 441, Minibatch Loss ---- Train = 0.181146; Test = 0.189014\n",
      "Iter 442, Minibatch Loss ---- Train = 0.187846; Test = 0.189293\n",
      "Iter 443, Minibatch Loss ---- Train = 0.197491; Test = 0.186947\n",
      "Iter 444, Minibatch Loss ---- Train = 0.194070; Test = 0.188382\n",
      "Iter 445, Minibatch Loss ---- Train = 0.174683; Test = 0.189385\n",
      "Iter 446, Minibatch Loss ---- Train = 0.193296; Test = 0.188229\n",
      "Iter 447, Minibatch Loss ---- Train = 0.216542; Test = 0.187815\n",
      "Iter 448, Minibatch Loss ---- Train = 0.199913; Test = 0.188304\n",
      "Iter 449, Minibatch Loss ---- Train = 0.203968; Test = 0.186736\n",
      "Iter 450, Minibatch Loss ---- Train = 0.207008; Test = 0.190575\n",
      "Iter 451, Minibatch Loss ---- Train = 0.177532; Test = 0.187127\n",
      "Iter 452, Minibatch Loss ---- Train = 0.208060; Test = 0.188064\n",
      "Iter 453, Minibatch Loss ---- Train = 0.203428; Test = 0.186567\n",
      "Iter 454, Minibatch Loss ---- Train = 0.194087; Test = 0.189159\n",
      "Iter 455, Minibatch Loss ---- Train = 0.214283; Test = 0.187232\n",
      "Iter 456, Minibatch Loss ---- Train = 0.197478; Test = 0.189238\n",
      "Iter 457, Minibatch Loss ---- Train = 0.192172; Test = 0.187086\n",
      "Iter 458, Minibatch Loss ---- Train = 0.177471; Test = 0.187716\n",
      "Iter 459, Minibatch Loss ---- Train = 0.201345; Test = 0.188633\n",
      "Iter 460, Minibatch Loss ---- Train = 0.216058; Test = 0.188403\n",
      "Iter 461, Minibatch Loss ---- Train = 0.200711; Test = 0.187042\n",
      "Iter 462, Minibatch Loss ---- Train = 0.197613; Test = 0.187825\n",
      "Iter 463, Minibatch Loss ---- Train = 0.199055; Test = 0.188030\n",
      "Iter 464, Minibatch Loss ---- Train = 0.193551; Test = 0.188117\n",
      "Iter 465, Minibatch Loss ---- Train = 0.177471; Test = 0.187545\n",
      "Iter 466, Minibatch Loss ---- Train = 0.178889; Test = 0.186524\n",
      "Iter 467, Minibatch Loss ---- Train = 0.183502; Test = 0.188279\n",
      "Iter 468, Minibatch Loss ---- Train = 0.205525; Test = 0.187770\n",
      "Iter 469, Minibatch Loss ---- Train = 0.210709; Test = 0.186023\n",
      "Iter 470, Minibatch Loss ---- Train = 0.185683; Test = 0.187652\n",
      "Iter 471, Minibatch Loss ---- Train = 0.206472; Test = 0.187424\n",
      "Iter 472, Minibatch Loss ---- Train = 0.184954; Test = 0.188324\n",
      "Iter 473, Minibatch Loss ---- Train = 0.201156; Test = 0.186842\n",
      "Iter 474, Minibatch Loss ---- Train = 0.202616; Test = 0.188221\n",
      "Iter 475, Minibatch Loss ---- Train = 0.153113; Test = 0.186646\n",
      "Iter 476, Minibatch Loss ---- Train = 0.183525; Test = 0.186437\n",
      "Iter 477, Minibatch Loss ---- Train = 0.219064; Test = 0.186779\n",
      "Iter 478, Minibatch Loss ---- Train = 0.169752; Test = 0.188040\n",
      "Iter 479, Minibatch Loss ---- Train = 0.182370; Test = 0.188025\n",
      "Iter 480, Minibatch Loss ---- Train = 0.173593; Test = 0.186513\n",
      "Iter 481, Minibatch Loss ---- Train = 0.203465; Test = 0.186090\n",
      "Iter 482, Minibatch Loss ---- Train = 0.181068; Test = 0.187723\n",
      "Iter 483, Minibatch Loss ---- Train = 0.164317; Test = 0.187152\n",
      "Iter 484, Minibatch Loss ---- Train = 0.193965; Test = 0.186771\n",
      "Iter 485, Minibatch Loss ---- Train = 0.167884; Test = 0.186425\n",
      "Iter 486, Minibatch Loss ---- Train = 0.192088; Test = 0.186834\n",
      "Iter 487, Minibatch Loss ---- Train = 0.197737; Test = 0.186497\n",
      "Iter 488, Minibatch Loss ---- Train = 0.220423; Test = 0.188174\n",
      "Iter 489, Minibatch Loss ---- Train = 0.242702; Test = 0.185188\n",
      "Iter 490, Minibatch Loss ---- Train = 0.192418; Test = 0.185448\n",
      "Iter 491, Minibatch Loss ---- Train = 0.203371; Test = 0.187136\n",
      "Iter 492, Minibatch Loss ---- Train = 0.175915; Test = 0.186484\n",
      "Iter 493, Minibatch Loss ---- Train = 0.225112; Test = 0.184888\n",
      "Iter 494, Minibatch Loss ---- Train = 0.184041; Test = 0.187177\n",
      "Iter 495, Minibatch Loss ---- Train = 0.171448; Test = 0.187076\n",
      "Iter 496, Minibatch Loss ---- Train = 0.192474; Test = 0.187261\n",
      "Iter 497, Minibatch Loss ---- Train = 0.178092; Test = 0.186144\n",
      "Iter 498, Minibatch Loss ---- Train = 0.177017; Test = 0.185622\n",
      "Iter 499, Minibatch Loss ---- Train = 0.189367; Test = 0.186527\n",
      "Iter 500, Minibatch Loss ---- Train = 0.191193; Test = 0.185881\n",
      "Iter 501, Minibatch Loss ---- Train = 0.194951; Test = 0.185628\n",
      "Iter 502, Minibatch Loss ---- Train = 0.192975; Test = 0.186976\n",
      "Iter 503, Minibatch Loss ---- Train = 0.171725; Test = 0.185396\n",
      "Iter 504, Minibatch Loss ---- Train = 0.184652; Test = 0.185572\n",
      "Iter 505, Minibatch Loss ---- Train = 0.193950; Test = 0.186734\n",
      "Iter 506, Minibatch Loss ---- Train = 0.187143; Test = 0.185744\n",
      "Iter 507, Minibatch Loss ---- Train = 0.192984; Test = 0.186070\n",
      "Iter 508, Minibatch Loss ---- Train = 0.209085; Test = 0.186392\n",
      "Iter 509, Minibatch Loss ---- Train = 0.190249; Test = 0.184996\n",
      "Iter 510, Minibatch Loss ---- Train = 0.197910; Test = 0.185264\n",
      "Iter 511, Minibatch Loss ---- Train = 0.184830; Test = 0.184798\n",
      "Iter 512, Minibatch Loss ---- Train = 0.208384; Test = 0.186835\n",
      "Iter 513, Minibatch Loss ---- Train = 0.166785; Test = 0.186338\n",
      "Iter 514, Minibatch Loss ---- Train = 0.181163; Test = 0.184764\n",
      "Iter 515, Minibatch Loss ---- Train = 0.183915; Test = 0.186214\n",
      "Iter 516, Minibatch Loss ---- Train = 0.180832; Test = 0.186021\n",
      "Iter 517, Minibatch Loss ---- Train = 0.202666; Test = 0.184958\n",
      "Iter 518, Minibatch Loss ---- Train = 0.182937; Test = 0.186343\n",
      "Iter 519, Minibatch Loss ---- Train = 0.207676; Test = 0.185179\n",
      "Iter 520, Minibatch Loss ---- Train = 0.215783; Test = 0.185925\n",
      "Iter 521, Minibatch Loss ---- Train = 0.188483; Test = 0.184346\n",
      "Iter 522, Minibatch Loss ---- Train = 0.198033; Test = 0.186273\n",
      "Iter 523, Minibatch Loss ---- Train = 0.194381; Test = 0.184047\n",
      "Iter 524, Minibatch Loss ---- Train = 0.171052; Test = 0.184595\n",
      "Iter 525, Minibatch Loss ---- Train = 0.179738; Test = 0.186470\n",
      "Iter 526, Minibatch Loss ---- Train = 0.199995; Test = 0.185000\n",
      "Iter 527, Minibatch Loss ---- Train = 0.198248; Test = 0.183964\n",
      "Iter 528, Minibatch Loss ---- Train = 0.180687; Test = 0.184773\n",
      "Iter 529, Minibatch Loss ---- Train = 0.201998; Test = 0.185971\n",
      "Iter 530, Minibatch Loss ---- Train = 0.161559; Test = 0.182889\n",
      "Iter 531, Minibatch Loss ---- Train = 0.171741; Test = 0.184462\n",
      "Iter 532, Minibatch Loss ---- Train = 0.188362; Test = 0.186094\n",
      "Iter 533, Minibatch Loss ---- Train = 0.179755; Test = 0.184055\n",
      "Iter 534, Minibatch Loss ---- Train = 0.206519; Test = 0.184500\n",
      "Iter 535, Minibatch Loss ---- Train = 0.182659; Test = 0.185594\n",
      "Iter 536, Minibatch Loss ---- Train = 0.207511; Test = 0.184476\n",
      "Iter 537, Minibatch Loss ---- Train = 0.203366; Test = 0.182875\n",
      "Iter 538, Minibatch Loss ---- Train = 0.189827; Test = 0.184450\n",
      "Iter 539, Minibatch Loss ---- Train = 0.186580; Test = 0.185065\n",
      "Iter 540, Minibatch Loss ---- Train = 0.205000; Test = 0.184581\n",
      "Iter 541, Minibatch Loss ---- Train = 0.191969; Test = 0.184782\n",
      "Iter 542, Minibatch Loss ---- Train = 0.172531; Test = 0.182733\n",
      "Iter 543, Minibatch Loss ---- Train = 0.224152; Test = 0.184014\n",
      "Iter 544, Minibatch Loss ---- Train = 0.190866; Test = 0.183531\n",
      "Iter 545, Minibatch Loss ---- Train = 0.181531; Test = 0.185193\n",
      "Iter 546, Minibatch Loss ---- Train = 0.164279; Test = 0.183980\n",
      "Iter 547, Minibatch Loss ---- Train = 0.215980; Test = 0.181906\n",
      "Iter 548, Minibatch Loss ---- Train = 0.159878; Test = 0.185639\n",
      "Iter 549, Minibatch Loss ---- Train = 0.171800; Test = 0.182597\n",
      "Iter 550, Minibatch Loss ---- Train = 0.184327; Test = 0.184633\n",
      "Iter 551, Minibatch Loss ---- Train = 0.195652; Test = 0.181952\n",
      "Iter 552, Minibatch Loss ---- Train = 0.169191; Test = 0.183506\n",
      "Iter 553, Minibatch Loss ---- Train = 0.201011; Test = 0.181623\n",
      "Iter 554, Minibatch Loss ---- Train = 0.198886; Test = 0.184343\n",
      "Iter 555, Minibatch Loss ---- Train = 0.209667; Test = 0.184181\n",
      "Iter 556, Minibatch Loss ---- Train = 0.176778; Test = 0.182668\n",
      "Iter 557, Minibatch Loss ---- Train = 0.168435; Test = 0.182933\n",
      "Iter 558, Minibatch Loss ---- Train = 0.175608; Test = 0.183556\n",
      "Iter 559, Minibatch Loss ---- Train = 0.188472; Test = 0.182769\n",
      "Iter 560, Minibatch Loss ---- Train = 0.188213; Test = 0.181571\n",
      "Iter 561, Minibatch Loss ---- Train = 0.208876; Test = 0.184409\n",
      "Iter 562, Minibatch Loss ---- Train = 0.209657; Test = 0.181706\n",
      "Iter 563, Minibatch Loss ---- Train = 0.172367; Test = 0.183731\n",
      "Iter 564, Minibatch Loss ---- Train = 0.205030; Test = 0.183870\n",
      "Iter 565, Minibatch Loss ---- Train = 0.191521; Test = 0.183396\n",
      "Iter 566, Minibatch Loss ---- Train = 0.190419; Test = 0.183406\n",
      "Iter 567, Minibatch Loss ---- Train = 0.218466; Test = 0.183067\n",
      "Iter 568, Minibatch Loss ---- Train = 0.196596; Test = 0.182442\n",
      "Iter 569, Minibatch Loss ---- Train = 0.180062; Test = 0.183573\n",
      "Iter 570, Minibatch Loss ---- Train = 0.180932; Test = 0.182183\n",
      "Iter 571, Minibatch Loss ---- Train = 0.173526; Test = 0.184565\n",
      "Iter 572, Minibatch Loss ---- Train = 0.213546; Test = 0.180546\n",
      "Iter 573, Minibatch Loss ---- Train = 0.197556; Test = 0.184406\n",
      "Iter 574, Minibatch Loss ---- Train = 0.197528; Test = 0.180609\n",
      "Iter 575, Minibatch Loss ---- Train = 0.192332; Test = 0.184345\n",
      "Iter 576, Minibatch Loss ---- Train = 0.204736; Test = 0.180985\n",
      "Iter 577, Minibatch Loss ---- Train = 0.182579; Test = 0.183555\n",
      "Iter 578, Minibatch Loss ---- Train = 0.200995; Test = 0.181288\n",
      "Iter 579, Minibatch Loss ---- Train = 0.206475; Test = 0.183738\n",
      "Iter 580, Minibatch Loss ---- Train = 0.224004; Test = 0.180875\n",
      "Iter 581, Minibatch Loss ---- Train = 0.176427; Test = 0.181581\n",
      "Iter 582, Minibatch Loss ---- Train = 0.209424; Test = 0.183483\n",
      "Iter 583, Minibatch Loss ---- Train = 0.160413; Test = 0.182640\n",
      "Iter 584, Minibatch Loss ---- Train = 0.192534; Test = 0.181754\n",
      "Iter 585, Minibatch Loss ---- Train = 0.196799; Test = 0.182034\n",
      "Iter 586, Minibatch Loss ---- Train = 0.157321; Test = 0.180498\n",
      "Iter 587, Minibatch Loss ---- Train = 0.176623; Test = 0.183811\n",
      "Iter 588, Minibatch Loss ---- Train = 0.178637; Test = 0.181476\n",
      "Iter 589, Minibatch Loss ---- Train = 0.187331; Test = 0.180220\n",
      "Iter 590, Minibatch Loss ---- Train = 0.178633; Test = 0.182755\n",
      "Iter 591, Minibatch Loss ---- Train = 0.160384; Test = 0.180384\n",
      "Iter 592, Minibatch Loss ---- Train = 0.194421; Test = 0.183288\n",
      "Iter 593, Minibatch Loss ---- Train = 0.184520; Test = 0.180416\n",
      "Iter 594, Minibatch Loss ---- Train = 0.183169; Test = 0.181240\n",
      "Iter 595, Minibatch Loss ---- Train = 0.212471; Test = 0.179873\n",
      "Iter 596, Minibatch Loss ---- Train = 0.200022; Test = 0.183925\n",
      "Iter 597, Minibatch Loss ---- Train = 0.168663; Test = 0.180332\n",
      "Iter 598, Minibatch Loss ---- Train = 0.182130; Test = 0.180296\n",
      "Iter 599, Minibatch Loss ---- Train = 0.188544; Test = 0.179795\n",
      "Iter 600, Minibatch Loss ---- Train = 0.193509; Test = 0.182649\n",
      "Iter 601, Minibatch Loss ---- Train = 0.210471; Test = 0.180230\n",
      "Iter 602, Minibatch Loss ---- Train = 0.190252; Test = 0.182785\n",
      "Iter 603, Minibatch Loss ---- Train = 0.185529; Test = 0.180110\n",
      "Iter 604, Minibatch Loss ---- Train = 0.189921; Test = 0.183219\n",
      "Iter 605, Minibatch Loss ---- Train = 0.158088; Test = 0.180996\n",
      "Iter 606, Minibatch Loss ---- Train = 0.190571; Test = 0.180325\n",
      "Iter 607, Minibatch Loss ---- Train = 0.201018; Test = 0.180662\n",
      "Iter 608, Minibatch Loss ---- Train = 0.187105; Test = 0.181226\n",
      "Iter 609, Minibatch Loss ---- Train = 0.188410; Test = 0.181503\n",
      "Iter 610, Minibatch Loss ---- Train = 0.192847; Test = 0.182100\n",
      "Iter 611, Minibatch Loss ---- Train = 0.173509; Test = 0.180242\n",
      "Iter 612, Minibatch Loss ---- Train = 0.176594; Test = 0.181023\n",
      "Iter 613, Minibatch Loss ---- Train = 0.168097; Test = 0.181342\n",
      "Iter 614, Minibatch Loss ---- Train = 0.200483; Test = 0.180238\n",
      "Iter 615, Minibatch Loss ---- Train = 0.171768; Test = 0.179998\n",
      "Iter 616, Minibatch Loss ---- Train = 0.231803; Test = 0.181623\n",
      "Iter 617, Minibatch Loss ---- Train = 0.180811; Test = 0.178641\n",
      "Iter 618, Minibatch Loss ---- Train = 0.162302; Test = 0.180480\n",
      "Iter 619, Minibatch Loss ---- Train = 0.172252; Test = 0.179986\n",
      "Iter 620, Minibatch Loss ---- Train = 0.196319; Test = 0.182260\n",
      "Iter 621, Minibatch Loss ---- Train = 0.189060; Test = 0.178777\n",
      "Iter 622, Minibatch Loss ---- Train = 0.196724; Test = 0.182068\n",
      "Iter 623, Minibatch Loss ---- Train = 0.154975; Test = 0.180376\n",
      "Iter 624, Minibatch Loss ---- Train = 0.182496; Test = 0.179732\n",
      "Iter 625, Minibatch Loss ---- Train = 0.208614; Test = 0.178567\n",
      "Iter 626, Minibatch Loss ---- Train = 0.162354; Test = 0.183492\n",
      "Iter 627, Minibatch Loss ---- Train = 0.196620; Test = 0.180379\n",
      "Iter 628, Minibatch Loss ---- Train = 0.183586; Test = 0.179235\n",
      "Iter 629, Minibatch Loss ---- Train = 0.205009; Test = 0.181474\n",
      "Iter 630, Minibatch Loss ---- Train = 0.194264; Test = 0.180583\n",
      "Iter 631, Minibatch Loss ---- Train = 0.179641; Test = 0.181500\n",
      "Iter 632, Minibatch Loss ---- Train = 0.196744; Test = 0.180291\n",
      "Iter 633, Minibatch Loss ---- Train = 0.216496; Test = 0.180660\n",
      "Iter 634, Minibatch Loss ---- Train = 0.160900; Test = 0.180355\n",
      "Iter 635, Minibatch Loss ---- Train = 0.171232; Test = 0.179111\n",
      "Iter 636, Minibatch Loss ---- Train = 0.202951; Test = 0.181321\n",
      "Iter 637, Minibatch Loss ---- Train = 0.187815; Test = 0.179444\n",
      "Iter 638, Minibatch Loss ---- Train = 0.194912; Test = 0.181079\n",
      "Iter 639, Minibatch Loss ---- Train = 0.167572; Test = 0.179515\n",
      "Iter 640, Minibatch Loss ---- Train = 0.186872; Test = 0.182871\n",
      "Iter 641, Minibatch Loss ---- Train = 0.195839; Test = 0.179146\n",
      "Iter 642, Minibatch Loss ---- Train = 0.167134; Test = 0.179601\n",
      "Iter 643, Minibatch Loss ---- Train = 0.223283; Test = 0.179905\n",
      "Iter 644, Minibatch Loss ---- Train = 0.194449; Test = 0.182425\n",
      "Iter 645, Minibatch Loss ---- Train = 0.191926; Test = 0.178127\n",
      "Iter 646, Minibatch Loss ---- Train = 0.165904; Test = 0.182578\n",
      "Iter 647, Minibatch Loss ---- Train = 0.181956; Test = 0.178905\n",
      "Iter 648, Minibatch Loss ---- Train = 0.177237; Test = 0.179152\n",
      "Iter 649, Minibatch Loss ---- Train = 0.199038; Test = 0.179693\n",
      "Iter 650, Minibatch Loss ---- Train = 0.208153; Test = 0.179738\n",
      "Iter 651, Minibatch Loss ---- Train = 0.175757; Test = 0.179045\n",
      "Iter 652, Minibatch Loss ---- Train = 0.182506; Test = 0.178670\n",
      "Iter 653, Minibatch Loss ---- Train = 0.199069; Test = 0.180489\n",
      "Iter 654, Minibatch Loss ---- Train = 0.207504; Test = 0.179317\n",
      "Iter 655, Minibatch Loss ---- Train = 0.178135; Test = 0.178753\n",
      "Iter 656, Minibatch Loss ---- Train = 0.196970; Test = 0.178347\n",
      "Iter 657, Minibatch Loss ---- Train = 0.188502; Test = 0.184366\n",
      "Iter 658, Minibatch Loss ---- Train = 0.178084; Test = 0.177786\n",
      "Iter 659, Minibatch Loss ---- Train = 0.166666; Test = 0.182445\n",
      "Iter 660, Minibatch Loss ---- Train = 0.167946; Test = 0.178552\n",
      "Iter 661, Minibatch Loss ---- Train = 0.187196; Test = 0.181482\n",
      "Iter 662, Minibatch Loss ---- Train = 0.170743; Test = 0.177641\n",
      "Iter 663, Minibatch Loss ---- Train = 0.190187; Test = 0.181713\n",
      "Iter 664, Minibatch Loss ---- Train = 0.184669; Test = 0.178383\n",
      "Iter 665, Minibatch Loss ---- Train = 0.167252; Test = 0.181145\n",
      "Iter 666, Minibatch Loss ---- Train = 0.188045; Test = 0.179048\n",
      "Iter 667, Minibatch Loss ---- Train = 0.202155; Test = 0.179283\n",
      "Iter 668, Minibatch Loss ---- Train = 0.186491; Test = 0.179678\n",
      "Iter 669, Minibatch Loss ---- Train = 0.199410; Test = 0.180775\n",
      "Iter 670, Minibatch Loss ---- Train = 0.208917; Test = 0.178312\n",
      "Iter 671, Minibatch Loss ---- Train = 0.170596; Test = 0.180572\n",
      "Iter 672, Minibatch Loss ---- Train = 0.170896; Test = 0.179022\n",
      "Iter 673, Minibatch Loss ---- Train = 0.190208; Test = 0.180020\n",
      "Iter 674, Minibatch Loss ---- Train = 0.195024; Test = 0.179518\n",
      "Iter 675, Minibatch Loss ---- Train = 0.184281; Test = 0.178269\n",
      "Iter 676, Minibatch Loss ---- Train = 0.188641; Test = 0.179691\n",
      "Iter 677, Minibatch Loss ---- Train = 0.169474; Test = 0.178513\n",
      "Iter 678, Minibatch Loss ---- Train = 0.194885; Test = 0.180628\n",
      "Iter 679, Minibatch Loss ---- Train = 0.184451; Test = 0.176973\n",
      "Iter 680, Minibatch Loss ---- Train = 0.156815; Test = 0.180339\n",
      "Iter 681, Minibatch Loss ---- Train = 0.190583; Test = 0.178133\n",
      "Iter 682, Minibatch Loss ---- Train = 0.191470; Test = 0.180583\n",
      "Iter 683, Minibatch Loss ---- Train = 0.189211; Test = 0.179130\n",
      "Iter 684, Minibatch Loss ---- Train = 0.190356; Test = 0.178433\n",
      "Iter 685, Minibatch Loss ---- Train = 0.221551; Test = 0.179461\n",
      "Iter 686, Minibatch Loss ---- Train = 0.194394; Test = 0.177762\n",
      "Iter 687, Minibatch Loss ---- Train = 0.182049; Test = 0.176666\n",
      "Iter 688, Minibatch Loss ---- Train = 0.170170; Test = 0.182000\n",
      "Iter 689, Minibatch Loss ---- Train = 0.184941; Test = 0.178493\n",
      "Iter 690, Minibatch Loss ---- Train = 0.197304; Test = 0.178267\n",
      "Iter 691, Minibatch Loss ---- Train = 0.200999; Test = 0.179298\n",
      "Iter 692, Minibatch Loss ---- Train = 0.161081; Test = 0.179231\n",
      "Iter 693, Minibatch Loss ---- Train = 0.175072; Test = 0.178139\n",
      "Iter 694, Minibatch Loss ---- Train = 0.173529; Test = 0.178690\n",
      "Iter 695, Minibatch Loss ---- Train = 0.184974; Test = 0.177460\n",
      "Iter 696, Minibatch Loss ---- Train = 0.183108; Test = 0.179676\n",
      "Iter 697, Minibatch Loss ---- Train = 0.213427; Test = 0.178392\n",
      "Iter 698, Minibatch Loss ---- Train = 0.195466; Test = 0.178084\n",
      "Iter 699, Minibatch Loss ---- Train = 0.162597; Test = 0.177736\n",
      "Iter 700, Minibatch Loss ---- Train = 0.178968; Test = 0.178986\n",
      "Iter 701, Minibatch Loss ---- Train = 0.192817; Test = 0.179814\n",
      "Iter 702, Minibatch Loss ---- Train = 0.208322; Test = 0.177177\n",
      "Iter 703, Minibatch Loss ---- Train = 0.197485; Test = 0.178708\n",
      "Iter 704, Minibatch Loss ---- Train = 0.185051; Test = 0.178811\n",
      "Iter 705, Minibatch Loss ---- Train = 0.189927; Test = 0.178320\n",
      "Iter 706, Minibatch Loss ---- Train = 0.180613; Test = 0.177684\n",
      "Iter 707, Minibatch Loss ---- Train = 0.188810; Test = 0.178921\n",
      "Iter 708, Minibatch Loss ---- Train = 0.186374; Test = 0.178739\n",
      "Iter 709, Minibatch Loss ---- Train = 0.201206; Test = 0.178776\n",
      "Iter 710, Minibatch Loss ---- Train = 0.167438; Test = 0.182084\n",
      "Iter 711, Minibatch Loss ---- Train = 0.193580; Test = 0.177450\n",
      "Iter 712, Minibatch Loss ---- Train = 0.200494; Test = 0.178464\n",
      "Iter 713, Minibatch Loss ---- Train = 0.216836; Test = 0.180535\n",
      "Iter 714, Minibatch Loss ---- Train = 0.178623; Test = 0.176423\n",
      "Iter 715, Minibatch Loss ---- Train = 0.180010; Test = 0.181059\n",
      "Iter 716, Minibatch Loss ---- Train = 0.186361; Test = 0.178679\n",
      "Iter 717, Minibatch Loss ---- Train = 0.173677; Test = 0.179578\n",
      "Iter 718, Minibatch Loss ---- Train = 0.189942; Test = 0.176544\n",
      "Iter 719, Minibatch Loss ---- Train = 0.165961; Test = 0.179255\n",
      "Iter 720, Minibatch Loss ---- Train = 0.184133; Test = 0.178645\n",
      "Iter 721, Minibatch Loss ---- Train = 0.174412; Test = 0.179916\n",
      "Iter 722, Minibatch Loss ---- Train = 0.163295; Test = 0.178188\n",
      "Iter 723, Minibatch Loss ---- Train = 0.185729; Test = 0.178814\n",
      "Iter 724, Minibatch Loss ---- Train = 0.184778; Test = 0.176414\n",
      "Iter 725, Minibatch Loss ---- Train = 0.169995; Test = 0.180147\n",
      "Iter 726, Minibatch Loss ---- Train = 0.186571; Test = 0.177637\n",
      "Iter 727, Minibatch Loss ---- Train = 0.192611; Test = 0.181175\n",
      "Iter 728, Minibatch Loss ---- Train = 0.170443; Test = 0.178042\n",
      "Iter 729, Minibatch Loss ---- Train = 0.172430; Test = 0.178838\n",
      "Iter 730, Minibatch Loss ---- Train = 0.186969; Test = 0.177468\n",
      "Iter 731, Minibatch Loss ---- Train = 0.192989; Test = 0.179196\n",
      "Iter 732, Minibatch Loss ---- Train = 0.186793; Test = 0.178220\n",
      "Iter 733, Minibatch Loss ---- Train = 0.198123; Test = 0.180023\n",
      "Iter 734, Minibatch Loss ---- Train = 0.166132; Test = 0.176906\n",
      "Iter 735, Minibatch Loss ---- Train = 0.202551; Test = 0.178642\n",
      "Iter 736, Minibatch Loss ---- Train = 0.180917; Test = 0.177816\n",
      "Iter 737, Minibatch Loss ---- Train = 0.169562; Test = 0.180397\n",
      "Iter 738, Minibatch Loss ---- Train = 0.184697; Test = 0.176873\n",
      "Iter 739, Minibatch Loss ---- Train = 0.170190; Test = 0.177581\n",
      "Iter 740, Minibatch Loss ---- Train = 0.176131; Test = 0.177870\n",
      "Iter 741, Minibatch Loss ---- Train = 0.205563; Test = 0.180758\n",
      "Iter 742, Minibatch Loss ---- Train = 0.194073; Test = 0.176447\n",
      "Iter 743, Minibatch Loss ---- Train = 0.196900; Test = 0.176176\n",
      "Iter 744, Minibatch Loss ---- Train = 0.164202; Test = 0.178490\n",
      "Iter 745, Minibatch Loss ---- Train = 0.176207; Test = 0.178826\n",
      "Iter 746, Minibatch Loss ---- Train = 0.209890; Test = 0.178522\n",
      "Iter 747, Minibatch Loss ---- Train = 0.179180; Test = 0.179000\n",
      "Iter 748, Minibatch Loss ---- Train = 0.179407; Test = 0.176788\n",
      "Iter 749, Minibatch Loss ---- Train = 0.169393; Test = 0.179956\n",
      "Iter 750, Minibatch Loss ---- Train = 0.205685; Test = 0.177740\n",
      "Iter 751, Minibatch Loss ---- Train = 0.186590; Test = 0.177949\n",
      "Iter 752, Minibatch Loss ---- Train = 0.207857; Test = 0.177856\n",
      "Iter 753, Minibatch Loss ---- Train = 0.184479; Test = 0.177201\n",
      "Iter 754, Minibatch Loss ---- Train = 0.157607; Test = 0.176877\n",
      "Iter 755, Minibatch Loss ---- Train = 0.162236; Test = 0.178491\n",
      "Iter 756, Minibatch Loss ---- Train = 0.188119; Test = 0.177943\n",
      "Iter 757, Minibatch Loss ---- Train = 0.163160; Test = 0.177489\n",
      "Iter 758, Minibatch Loss ---- Train = 0.167319; Test = 0.175593\n",
      "Iter 759, Minibatch Loss ---- Train = 0.203286; Test = 0.179417\n",
      "Iter 760, Minibatch Loss ---- Train = 0.189701; Test = 0.178643\n",
      "Iter 761, Minibatch Loss ---- Train = 0.203700; Test = 0.177527\n",
      "Iter 762, Minibatch Loss ---- Train = 0.190603; Test = 0.176761\n",
      "Iter 763, Minibatch Loss ---- Train = 0.174797; Test = 0.179829\n",
      "Iter 764, Minibatch Loss ---- Train = 0.189469; Test = 0.176551\n",
      "Iter 765, Minibatch Loss ---- Train = 0.174840; Test = 0.176974\n",
      "Iter 766, Minibatch Loss ---- Train = 0.204313; Test = 0.177755\n",
      "Iter 767, Minibatch Loss ---- Train = 0.196790; Test = 0.177014\n",
      "Iter 768, Minibatch Loss ---- Train = 0.164123; Test = 0.177130\n",
      "Iter 769, Minibatch Loss ---- Train = 0.180616; Test = 0.179488\n",
      "Iter 770, Minibatch Loss ---- Train = 0.166172; Test = 0.176043\n",
      "Iter 771, Minibatch Loss ---- Train = 0.193561; Test = 0.177084\n",
      "Iter 772, Minibatch Loss ---- Train = 0.151973; Test = 0.175846\n",
      "Iter 773, Minibatch Loss ---- Train = 0.197085; Test = 0.177803\n",
      "Iter 774, Minibatch Loss ---- Train = 0.175767; Test = 0.176173\n",
      "Iter 775, Minibatch Loss ---- Train = 0.182152; Test = 0.179250\n",
      "Iter 776, Minibatch Loss ---- Train = 0.168062; Test = 0.176839\n",
      "Iter 777, Minibatch Loss ---- Train = 0.183451; Test = 0.177824\n",
      "Iter 778, Minibatch Loss ---- Train = 0.165577; Test = 0.176026\n",
      "Iter 779, Minibatch Loss ---- Train = 0.165999; Test = 0.177248\n",
      "Iter 780, Minibatch Loss ---- Train = 0.192114; Test = 0.177862\n",
      "Iter 781, Minibatch Loss ---- Train = 0.178016; Test = 0.177437\n",
      "Iter 782, Minibatch Loss ---- Train = 0.166788; Test = 0.177837\n",
      "Iter 783, Minibatch Loss ---- Train = 0.180725; Test = 0.176904\n",
      "Iter 784, Minibatch Loss ---- Train = 0.165768; Test = 0.176748\n",
      "Iter 785, Minibatch Loss ---- Train = 0.173283; Test = 0.179385\n",
      "Iter 786, Minibatch Loss ---- Train = 0.203369; Test = 0.175499\n",
      "Iter 787, Minibatch Loss ---- Train = 0.184293; Test = 0.175487\n",
      "Iter 788, Minibatch Loss ---- Train = 0.208387; Test = 0.178428\n",
      "Iter 789, Minibatch Loss ---- Train = 0.182415; Test = 0.178072\n",
      "Iter 790, Minibatch Loss ---- Train = 0.182227; Test = 0.176890\n",
      "Iter 791, Minibatch Loss ---- Train = 0.196552; Test = 0.176842\n",
      "Iter 792, Minibatch Loss ---- Train = 0.187175; Test = 0.175653\n",
      "Iter 793, Minibatch Loss ---- Train = 0.165626; Test = 0.178880\n",
      "Iter 794, Minibatch Loss ---- Train = 0.181588; Test = 0.176732\n",
      "Iter 795, Minibatch Loss ---- Train = 0.186872; Test = 0.176953\n",
      "Iter 796, Minibatch Loss ---- Train = 0.177608; Test = 0.176993\n",
      "Iter 797, Minibatch Loss ---- Train = 0.180735; Test = 0.176732\n",
      "Iter 798, Minibatch Loss ---- Train = 0.180423; Test = 0.177379\n",
      "Iter 799, Minibatch Loss ---- Train = 0.186071; Test = 0.177128\n",
      "[0.58174437739957785, 0.57835693077321471, 0.5843270408609339, 0.57714360386269881, 0.58468200808538717, 0.58198039071432872, 0.58409714910749722, 0.58341472935968275, 0.58105048499658107, 0.58129585675467677]\n",
      "total running time cost:1297.16782308s\n",
      "Iter 0, Minibatch Loss ---- Train = 8.845086; Test = 8.828489\n",
      "Iter 1, Minibatch Loss ---- Train = 7.757492; Test = 7.784183\n",
      "Iter 2, Minibatch Loss ---- Train = 5.268173; Test = 5.163170\n",
      "Iter 3, Minibatch Loss ---- Train = 2.335677; Test = 2.247561\n",
      "Iter 4, Minibatch Loss ---- Train = 1.797983; Test = 1.796713\n",
      "Iter 5, Minibatch Loss ---- Train = 1.485847; Test = 1.530408\n",
      "Iter 6, Minibatch Loss ---- Train = 1.359616; Test = 1.310699\n",
      "Iter 7, Minibatch Loss ---- Train = 1.101126; Test = 1.111236\n",
      "Iter 8, Minibatch Loss ---- Train = 0.896114; Test = 0.915271\n",
      "Iter 9, Minibatch Loss ---- Train = 0.696219; Test = 0.727236\n",
      "Iter 10, Minibatch Loss ---- Train = 0.572610; Test = 0.557337\n",
      "Iter 11, Minibatch Loss ---- Train = 0.396928; Test = 0.411939\n",
      "Iter 12, Minibatch Loss ---- Train = 0.287590; Test = 0.294870\n",
      "Iter 13, Minibatch Loss ---- Train = 0.180708; Test = 0.206964\n",
      "Iter 14, Minibatch Loss ---- Train = 0.126021; Test = 0.147468\n",
      "Iter 15, Minibatch Loss ---- Train = 0.121323; Test = 0.116856\n",
      "Iter 16, Minibatch Loss ---- Train = 0.127047; Test = 0.127666\n",
      "Iter 17, Minibatch Loss ---- Train = 0.111830; Test = 0.119470\n",
      "Iter 18, Minibatch Loss ---- Train = 0.139759; Test = 0.143671\n",
      "Iter 19, Minibatch Loss ---- Train = 0.092036; Test = 0.111320\n",
      "Iter 20, Minibatch Loss ---- Train = 0.122833; Test = 0.123402\n",
      "Iter 21, Minibatch Loss ---- Train = 0.118226; Test = 0.122967\n",
      "Iter 22, Minibatch Loss ---- Train = 0.122429; Test = 0.113414\n",
      "Iter 23, Minibatch Loss ---- Train = 0.143595; Test = 0.151052\n",
      "Iter 24, Minibatch Loss ---- Train = 0.104300; Test = 0.111559\n",
      "Iter 25, Minibatch Loss ---- Train = 0.107150; Test = 0.123825\n",
      "Iter 26, Minibatch Loss ---- Train = 0.110162; Test = 0.109717\n",
      "Iter 27, Minibatch Loss ---- Train = 0.141222; Test = 0.135101\n",
      "Iter 28, Minibatch Loss ---- Train = 0.114373; Test = 0.106875\n",
      "Iter 29, Minibatch Loss ---- Train = 0.132522; Test = 0.119649\n",
      "Iter 30, Minibatch Loss ---- Train = 0.102616; Test = 0.111496\n",
      "Iter 31, Minibatch Loss ---- Train = 0.143094; Test = 0.142257\n",
      "Iter 32, Minibatch Loss ---- Train = 0.106620; Test = 0.107546\n",
      "Iter 33, Minibatch Loss ---- Train = 0.127359; Test = 0.120164\n",
      "Iter 34, Minibatch Loss ---- Train = 0.112441; Test = 0.106813\n",
      "Iter 35, Minibatch Loss ---- Train = 0.141014; Test = 0.132011\n",
      "Iter 36, Minibatch Loss ---- Train = 0.091339; Test = 0.104849\n",
      "Iter 37, Minibatch Loss ---- Train = 0.118399; Test = 0.118875\n",
      "Iter 38, Minibatch Loss ---- Train = 0.101870; Test = 0.106137\n",
      "Iter 39, Minibatch Loss ---- Train = 0.118432; Test = 0.133485\n",
      "Iter 40, Minibatch Loss ---- Train = 0.098725; Test = 0.104602\n",
      "Iter 41, Minibatch Loss ---- Train = 0.109257; Test = 0.118154\n",
      "Iter 42, Minibatch Loss ---- Train = 0.104185; Test = 0.104625\n",
      "Iter 43, Minibatch Loss ---- Train = 0.115998; Test = 0.128590\n",
      "Iter 44, Minibatch Loss ---- Train = 0.116443; Test = 0.103342\n",
      "Iter 45, Minibatch Loss ---- Train = 0.101879; Test = 0.118108\n",
      "Iter 46, Minibatch Loss ---- Train = 0.096747; Test = 0.103790\n",
      "Iter 47, Minibatch Loss ---- Train = 0.134158; Test = 0.126642\n",
      "Iter 48, Minibatch Loss ---- Train = 0.108299; Test = 0.102597\n",
      "Iter 49, Minibatch Loss ---- Train = 0.120981; Test = 0.116406\n",
      "Iter 50, Minibatch Loss ---- Train = 0.100401; Test = 0.113618\n",
      "Iter 51, Minibatch Loss ---- Train = 0.097323; Test = 0.109960\n",
      "Iter 52, Minibatch Loss ---- Train = 0.125543; Test = 0.105603\n",
      "Iter 53, Minibatch Loss ---- Train = 0.106712; Test = 0.102441\n",
      "Iter 54, Minibatch Loss ---- Train = 0.077350; Test = 0.101332\n",
      "Iter 55, Minibatch Loss ---- Train = 0.088785; Test = 0.100896\n",
      "Iter 56, Minibatch Loss ---- Train = 0.113264; Test = 0.100363\n",
      "Iter 57, Minibatch Loss ---- Train = 0.095508; Test = 0.099558\n",
      "Iter 58, Minibatch Loss ---- Train = 0.105161; Test = 0.101643\n",
      "Iter 59, Minibatch Loss ---- Train = 0.104509; Test = 0.103105\n",
      "Iter 60, Minibatch Loss ---- Train = 0.101949; Test = 0.100520\n",
      "Iter 61, Minibatch Loss ---- Train = 0.087771; Test = 0.100781\n",
      "Iter 62, Minibatch Loss ---- Train = 0.106252; Test = 0.099211\n",
      "Iter 63, Minibatch Loss ---- Train = 0.080354; Test = 0.099768\n",
      "Iter 64, Minibatch Loss ---- Train = 0.091923; Test = 0.100815\n",
      "Iter 65, Minibatch Loss ---- Train = 0.101453; Test = 0.098653\n",
      "Iter 66, Minibatch Loss ---- Train = 0.089980; Test = 0.099077\n",
      "Iter 67, Minibatch Loss ---- Train = 0.094907; Test = 0.098240\n",
      "Iter 68, Minibatch Loss ---- Train = 0.097130; Test = 0.097901\n",
      "Iter 69, Minibatch Loss ---- Train = 0.097729; Test = 0.098534\n",
      "Iter 70, Minibatch Loss ---- Train = 0.105135; Test = 0.096887\n",
      "Iter 71, Minibatch Loss ---- Train = 0.098382; Test = 0.096569\n",
      "Iter 72, Minibatch Loss ---- Train = 0.084652; Test = 0.098249\n",
      "Iter 73, Minibatch Loss ---- Train = 0.091518; Test = 0.095943\n",
      "Iter 74, Minibatch Loss ---- Train = 0.105919; Test = 0.094529\n",
      "Iter 75, Minibatch Loss ---- Train = 0.096691; Test = 0.096335\n",
      "Iter 76, Minibatch Loss ---- Train = 0.083725; Test = 0.096716\n",
      "Iter 77, Minibatch Loss ---- Train = 0.093324; Test = 0.094466\n",
      "Iter 78, Minibatch Loss ---- Train = 0.099121; Test = 0.094262\n",
      "Iter 79, Minibatch Loss ---- Train = 0.092683; Test = 0.095072\n",
      "Iter 80, Minibatch Loss ---- Train = 0.090839; Test = 0.094663\n",
      "Iter 81, Minibatch Loss ---- Train = 0.099604; Test = 0.093883\n",
      "Iter 82, Minibatch Loss ---- Train = 0.098225; Test = 0.093672\n",
      "Iter 83, Minibatch Loss ---- Train = 0.072372; Test = 0.093489\n",
      "Iter 84, Minibatch Loss ---- Train = 0.093103; Test = 0.093590\n",
      "Iter 85, Minibatch Loss ---- Train = 0.072348; Test = 0.092732\n",
      "Iter 86, Minibatch Loss ---- Train = 0.085655; Test = 0.094300\n",
      "Iter 87, Minibatch Loss ---- Train = 0.110597; Test = 0.092521\n",
      "Iter 88, Minibatch Loss ---- Train = 0.085783; Test = 0.091961\n",
      "Iter 89, Minibatch Loss ---- Train = 0.074097; Test = 0.091550\n",
      "Iter 90, Minibatch Loss ---- Train = 0.084064; Test = 0.093673\n",
      "Iter 91, Minibatch Loss ---- Train = 0.077624; Test = 0.091637\n",
      "Iter 92, Minibatch Loss ---- Train = 0.082341; Test = 0.092111\n",
      "Iter 93, Minibatch Loss ---- Train = 0.092814; Test = 0.091378\n",
      "Iter 94, Minibatch Loss ---- Train = 0.080373; Test = 0.091607\n",
      "Iter 95, Minibatch Loss ---- Train = 0.088110; Test = 0.091141\n",
      "Iter 96, Minibatch Loss ---- Train = 0.084327; Test = 0.091019\n",
      "Iter 97, Minibatch Loss ---- Train = 0.077577; Test = 0.090350\n",
      "Iter 98, Minibatch Loss ---- Train = 0.082877; Test = 0.092282\n",
      "Iter 99, Minibatch Loss ---- Train = 0.080534; Test = 0.090160\n",
      "Iter 100, Minibatch Loss ---- Train = 0.079960; Test = 0.090950\n",
      "Iter 101, Minibatch Loss ---- Train = 0.086924; Test = 0.090435\n",
      "Iter 102, Minibatch Loss ---- Train = 0.083082; Test = 0.090320\n",
      "Iter 103, Minibatch Loss ---- Train = 0.098925; Test = 0.089959\n",
      "Iter 104, Minibatch Loss ---- Train = 0.087882; Test = 0.089435\n",
      "Iter 105, Minibatch Loss ---- Train = 0.074514; Test = 0.089453\n",
      "Iter 106, Minibatch Loss ---- Train = 0.077049; Test = 0.090898\n",
      "Iter 107, Minibatch Loss ---- Train = 0.101177; Test = 0.089260\n",
      "Iter 108, Minibatch Loss ---- Train = 0.070850; Test = 0.089437\n",
      "Iter 109, Minibatch Loss ---- Train = 0.103309; Test = 0.089175\n",
      "Iter 110, Minibatch Loss ---- Train = 0.094473; Test = 0.088249\n",
      "Iter 111, Minibatch Loss ---- Train = 0.084911; Test = 0.089719\n",
      "Iter 112, Minibatch Loss ---- Train = 0.094826; Test = 0.088584\n",
      "Iter 113, Minibatch Loss ---- Train = 0.063266; Test = 0.088240\n",
      "Iter 114, Minibatch Loss ---- Train = 0.080843; Test = 0.089908\n",
      "Iter 115, Minibatch Loss ---- Train = 0.075219; Test = 0.087921\n",
      "Iter 116, Minibatch Loss ---- Train = 0.089024; Test = 0.088548\n",
      "Iter 117, Minibatch Loss ---- Train = 0.088147; Test = 0.087900\n",
      "Iter 118, Minibatch Loss ---- Train = 0.088318; Test = 0.088803\n",
      "Iter 119, Minibatch Loss ---- Train = 0.081691; Test = 0.087789\n",
      "Iter 120, Minibatch Loss ---- Train = 0.087391; Test = 0.087920\n",
      "Iter 121, Minibatch Loss ---- Train = 0.081093; Test = 0.087772\n",
      "Iter 122, Minibatch Loss ---- Train = 0.091219; Test = 0.088293\n",
      "Iter 123, Minibatch Loss ---- Train = 0.097053; Test = 0.088158\n",
      "Iter 124, Minibatch Loss ---- Train = 0.091185; Test = 0.086557\n",
      "Iter 125, Minibatch Loss ---- Train = 0.083159; Test = 0.087621\n",
      "Iter 126, Minibatch Loss ---- Train = 0.081459; Test = 0.088283\n",
      "Iter 127, Minibatch Loss ---- Train = 0.087160; Test = 0.087128\n",
      "Iter 128, Minibatch Loss ---- Train = 0.095535; Test = 0.085641\n",
      "Iter 129, Minibatch Loss ---- Train = 0.104353; Test = 0.088941\n",
      "Iter 130, Minibatch Loss ---- Train = 0.094550; Test = 0.086443\n",
      "Iter 131, Minibatch Loss ---- Train = 0.085181; Test = 0.086944\n",
      "Iter 132, Minibatch Loss ---- Train = 0.077022; Test = 0.087084\n",
      "Iter 133, Minibatch Loss ---- Train = 0.086494; Test = 0.086190\n",
      "Iter 134, Minibatch Loss ---- Train = 0.082963; Test = 0.086810\n",
      "Iter 135, Minibatch Loss ---- Train = 0.090757; Test = 0.086532\n",
      "Iter 136, Minibatch Loss ---- Train = 0.085195; Test = 0.086358\n",
      "Iter 137, Minibatch Loss ---- Train = 0.087558; Test = 0.086365\n",
      "Iter 138, Minibatch Loss ---- Train = 0.090661; Test = 0.086427\n",
      "Iter 139, Minibatch Loss ---- Train = 0.082762; Test = 0.085796\n",
      "Iter 140, Minibatch Loss ---- Train = 0.083219; Test = 0.086467\n",
      "Iter 141, Minibatch Loss ---- Train = 0.092980; Test = 0.086681\n",
      "Iter 142, Minibatch Loss ---- Train = 0.083477; Test = 0.084963\n",
      "Iter 143, Minibatch Loss ---- Train = 0.079078; Test = 0.085174\n",
      "Iter 144, Minibatch Loss ---- Train = 0.094847; Test = 0.086968\n",
      "Iter 145, Minibatch Loss ---- Train = 0.082821; Test = 0.085253\n",
      "Iter 146, Minibatch Loss ---- Train = 0.094809; Test = 0.085227\n",
      "Iter 147, Minibatch Loss ---- Train = 0.085735; Test = 0.085810\n",
      "Iter 148, Minibatch Loss ---- Train = 0.074279; Test = 0.086018\n",
      "Iter 149, Minibatch Loss ---- Train = 0.084745; Test = 0.084885\n",
      "Iter 150, Minibatch Loss ---- Train = 0.060030; Test = 0.086228\n",
      "Iter 151, Minibatch Loss ---- Train = 0.086116; Test = 0.084593\n",
      "Iter 152, Minibatch Loss ---- Train = 0.083120; Test = 0.084690\n",
      "Iter 153, Minibatch Loss ---- Train = 0.085644; Test = 0.085646\n",
      "Iter 154, Minibatch Loss ---- Train = 0.085552; Test = 0.084864\n",
      "Iter 155, Minibatch Loss ---- Train = 0.075479; Test = 0.084687\n",
      "Iter 156, Minibatch Loss ---- Train = 0.073919; Test = 0.085385\n",
      "Iter 157, Minibatch Loss ---- Train = 0.083138; Test = 0.084727\n",
      "Iter 158, Minibatch Loss ---- Train = 0.089707; Test = 0.084254\n",
      "Iter 159, Minibatch Loss ---- Train = 0.071539; Test = 0.084414\n",
      "Iter 160, Minibatch Loss ---- Train = 0.075971; Test = 0.085781\n",
      "Iter 161, Minibatch Loss ---- Train = 0.082258; Test = 0.083715\n",
      "Iter 162, Minibatch Loss ---- Train = 0.076308; Test = 0.085440\n",
      "Iter 163, Minibatch Loss ---- Train = 0.088438; Test = 0.084250\n",
      "Iter 164, Minibatch Loss ---- Train = 0.081063; Test = 0.084354\n",
      "Iter 165, Minibatch Loss ---- Train = 0.071546; Test = 0.082975\n",
      "Iter 166, Minibatch Loss ---- Train = 0.091554; Test = 0.084264\n",
      "Iter 167, Minibatch Loss ---- Train = 0.100455; Test = 0.084983\n",
      "Iter 168, Minibatch Loss ---- Train = 0.090293; Test = 0.083439\n",
      "Iter 169, Minibatch Loss ---- Train = 0.070063; Test = 0.082801\n",
      "Iter 170, Minibatch Loss ---- Train = 0.082004; Test = 0.085700\n",
      "Iter 171, Minibatch Loss ---- Train = 0.068984; Test = 0.082745\n",
      "Iter 172, Minibatch Loss ---- Train = 0.081334; Test = 0.084094\n",
      "Iter 173, Minibatch Loss ---- Train = 0.086019; Test = 0.083635\n",
      "Iter 174, Minibatch Loss ---- Train = 0.099271; Test = 0.083218\n",
      "Iter 175, Minibatch Loss ---- Train = 0.102841; Test = 0.083966\n",
      "Iter 176, Minibatch Loss ---- Train = 0.091277; Test = 0.083124\n",
      "Iter 177, Minibatch Loss ---- Train = 0.078337; Test = 0.083113\n",
      "Iter 178, Minibatch Loss ---- Train = 0.072162; Test = 0.084175\n",
      "Iter 179, Minibatch Loss ---- Train = 0.096196; Test = 0.082954\n",
      "Iter 180, Minibatch Loss ---- Train = 0.076958; Test = 0.082963\n",
      "Iter 181, Minibatch Loss ---- Train = 0.083104; Test = 0.082496\n",
      "Iter 182, Minibatch Loss ---- Train = 0.067375; Test = 0.084237\n",
      "Iter 183, Minibatch Loss ---- Train = 0.084877; Test = 0.082347\n",
      "Iter 184, Minibatch Loss ---- Train = 0.090354; Test = 0.082169\n",
      "Iter 185, Minibatch Loss ---- Train = 0.088261; Test = 0.083604\n",
      "Iter 186, Minibatch Loss ---- Train = 0.083318; Test = 0.083390\n",
      "Iter 187, Minibatch Loss ---- Train = 0.068717; Test = 0.081746\n",
      "Iter 188, Minibatch Loss ---- Train = 0.084809; Test = 0.082736\n",
      "Iter 189, Minibatch Loss ---- Train = 0.086333; Test = 0.083337\n",
      "Iter 190, Minibatch Loss ---- Train = 0.070520; Test = 0.082355\n",
      "Iter 191, Minibatch Loss ---- Train = 0.082040; Test = 0.081804\n",
      "Iter 192, Minibatch Loss ---- Train = 0.082305; Test = 0.082930\n",
      "Iter 193, Minibatch Loss ---- Train = 0.075149; Test = 0.081618\n",
      "Iter 194, Minibatch Loss ---- Train = 0.077006; Test = 0.083355\n",
      "Iter 195, Minibatch Loss ---- Train = 0.068174; Test = 0.081891\n",
      "Iter 196, Minibatch Loss ---- Train = 0.077831; Test = 0.083169\n",
      "Iter 197, Minibatch Loss ---- Train = 0.090672; Test = 0.082098\n",
      "Iter 198, Minibatch Loss ---- Train = 0.091394; Test = 0.081741\n",
      "Iter 199, Minibatch Loss ---- Train = 0.079372; Test = 0.082051\n",
      "Iter 200, Minibatch Loss ---- Train = 0.084523; Test = 0.082581\n",
      "Iter 201, Minibatch Loss ---- Train = 0.072680; Test = 0.081886\n",
      "Iter 202, Minibatch Loss ---- Train = 0.084801; Test = 0.081799\n",
      "Iter 203, Minibatch Loss ---- Train = 0.072952; Test = 0.081938\n",
      "Iter 204, Minibatch Loss ---- Train = 0.078502; Test = 0.082559\n",
      "Iter 205, Minibatch Loss ---- Train = 0.090983; Test = 0.081952\n",
      "Iter 206, Minibatch Loss ---- Train = 0.067153; Test = 0.081852\n",
      "Iter 207, Minibatch Loss ---- Train = 0.070349; Test = 0.081358\n",
      "Iter 208, Minibatch Loss ---- Train = 0.087626; Test = 0.081119\n",
      "Iter 209, Minibatch Loss ---- Train = 0.091645; Test = 0.083639\n",
      "Iter 210, Minibatch Loss ---- Train = 0.083594; Test = 0.081202\n",
      "Iter 211, Minibatch Loss ---- Train = 0.079039; Test = 0.081420\n",
      "Iter 212, Minibatch Loss ---- Train = 0.073747; Test = 0.081985\n",
      "Iter 213, Minibatch Loss ---- Train = 0.093748; Test = 0.081480\n",
      "Iter 214, Minibatch Loss ---- Train = 0.076067; Test = 0.081133\n",
      "Iter 215, Minibatch Loss ---- Train = 0.075477; Test = 0.081463\n",
      "Iter 216, Minibatch Loss ---- Train = 0.066204; Test = 0.082278\n",
      "Iter 217, Minibatch Loss ---- Train = 0.068008; Test = 0.080917\n",
      "Iter 218, Minibatch Loss ---- Train = 0.075526; Test = 0.082008\n",
      "Iter 219, Minibatch Loss ---- Train = 0.090744; Test = 0.081262\n",
      "Iter 220, Minibatch Loss ---- Train = 0.072145; Test = 0.081144\n",
      "Iter 221, Minibatch Loss ---- Train = 0.089912; Test = 0.081210\n",
      "Iter 222, Minibatch Loss ---- Train = 0.080837; Test = 0.082064\n",
      "Iter 223, Minibatch Loss ---- Train = 0.078095; Test = 0.080812\n",
      "Iter 224, Minibatch Loss ---- Train = 0.078290; Test = 0.081948\n",
      "Iter 225, Minibatch Loss ---- Train = 0.082180; Test = 0.081029\n",
      "Iter 226, Minibatch Loss ---- Train = 0.071462; Test = 0.081945\n",
      "Iter 227, Minibatch Loss ---- Train = 0.078889; Test = 0.080777\n",
      "Iter 228, Minibatch Loss ---- Train = 0.089726; Test = 0.080578\n",
      "Iter 229, Minibatch Loss ---- Train = 0.071523; Test = 0.081627\n",
      "Iter 230, Minibatch Loss ---- Train = 0.068370; Test = 0.081975\n",
      "Iter 231, Minibatch Loss ---- Train = 0.073228; Test = 0.080498\n",
      "Iter 232, Minibatch Loss ---- Train = 0.084233; Test = 0.081083\n",
      "Iter 233, Minibatch Loss ---- Train = 0.076205; Test = 0.081456\n",
      "Iter 234, Minibatch Loss ---- Train = 0.064570; Test = 0.081974\n",
      "Iter 235, Minibatch Loss ---- Train = 0.081152; Test = 0.080721\n",
      "Iter 236, Minibatch Loss ---- Train = 0.079235; Test = 0.081157\n",
      "Iter 237, Minibatch Loss ---- Train = 0.077233; Test = 0.080440\n",
      "Iter 238, Minibatch Loss ---- Train = 0.086905; Test = 0.081418\n",
      "Iter 239, Minibatch Loss ---- Train = 0.089486; Test = 0.080885\n",
      "Iter 240, Minibatch Loss ---- Train = 0.078047; Test = 0.081042\n",
      "Iter 241, Minibatch Loss ---- Train = 0.083042; Test = 0.080842\n",
      "Iter 242, Minibatch Loss ---- Train = 0.064945; Test = 0.081471\n",
      "Iter 243, Minibatch Loss ---- Train = 0.086861; Test = 0.080323\n",
      "Iter 244, Minibatch Loss ---- Train = 0.088353; Test = 0.080462\n",
      "Iter 245, Minibatch Loss ---- Train = 0.065342; Test = 0.081006\n",
      "Iter 246, Minibatch Loss ---- Train = 0.069204; Test = 0.081547\n",
      "Iter 247, Minibatch Loss ---- Train = 0.071453; Test = 0.080397\n",
      "Iter 248, Minibatch Loss ---- Train = 0.075074; Test = 0.080999\n",
      "Iter 249, Minibatch Loss ---- Train = 0.079020; Test = 0.080692\n",
      "Iter 250, Minibatch Loss ---- Train = 0.071683; Test = 0.081329\n",
      "Iter 251, Minibatch Loss ---- Train = 0.069685; Test = 0.080695\n",
      "Iter 252, Minibatch Loss ---- Train = 0.080640; Test = 0.080650\n",
      "Iter 253, Minibatch Loss ---- Train = 0.067011; Test = 0.080495\n",
      "Iter 254, Minibatch Loss ---- Train = 0.072595; Test = 0.081754\n",
      "Iter 255, Minibatch Loss ---- Train = 0.084488; Test = 0.080163\n",
      "Iter 256, Minibatch Loss ---- Train = 0.075987; Test = 0.080517\n",
      "Iter 257, Minibatch Loss ---- Train = 0.083168; Test = 0.080833\n",
      "Iter 258, Minibatch Loss ---- Train = 0.081170; Test = 0.081251\n",
      "Iter 259, Minibatch Loss ---- Train = 0.088745; Test = 0.080110\n",
      "Iter 260, Minibatch Loss ---- Train = 0.075559; Test = 0.080278\n",
      "Iter 261, Minibatch Loss ---- Train = 0.078448; Test = 0.080347\n",
      "Iter 262, Minibatch Loss ---- Train = 0.079578; Test = 0.082104\n",
      "Iter 263, Minibatch Loss ---- Train = 0.066763; Test = 0.079921\n",
      "Iter 264, Minibatch Loss ---- Train = 0.080267; Test = 0.081179\n",
      "Iter 265, Minibatch Loss ---- Train = 0.071254; Test = 0.080162\n",
      "Iter 266, Minibatch Loss ---- Train = 0.089758; Test = 0.080771\n",
      "Iter 267, Minibatch Loss ---- Train = 0.090658; Test = 0.080896\n",
      "Iter 268, Minibatch Loss ---- Train = 0.072870; Test = 0.080335\n",
      "Iter 269, Minibatch Loss ---- Train = 0.067285; Test = 0.079601\n",
      "Iter 270, Minibatch Loss ---- Train = 0.069136; Test = 0.082083\n",
      "Iter 271, Minibatch Loss ---- Train = 0.055842; Test = 0.079569\n",
      "Iter 272, Minibatch Loss ---- Train = 0.082089; Test = 0.080548\n",
      "Iter 273, Minibatch Loss ---- Train = 0.091689; Test = 0.081114\n",
      "Iter 274, Minibatch Loss ---- Train = 0.078757; Test = 0.080455\n",
      "Iter 275, Minibatch Loss ---- Train = 0.092294; Test = 0.080902\n",
      "Iter 276, Minibatch Loss ---- Train = 0.080155; Test = 0.079644\n",
      "Iter 277, Minibatch Loss ---- Train = 0.077504; Test = 0.079578\n",
      "Iter 278, Minibatch Loss ---- Train = 0.099678; Test = 0.081590\n",
      "Iter 279, Minibatch Loss ---- Train = 0.077263; Test = 0.080468\n",
      "Iter 280, Minibatch Loss ---- Train = 0.076468; Test = 0.080531\n",
      "Iter 281, Minibatch Loss ---- Train = 0.078927; Test = 0.079851\n",
      "Iter 282, Minibatch Loss ---- Train = 0.072292; Test = 0.081033\n",
      "Iter 283, Minibatch Loss ---- Train = 0.063540; Test = 0.079674\n",
      "Iter 284, Minibatch Loss ---- Train = 0.075349; Test = 0.081111\n",
      "Iter 285, Minibatch Loss ---- Train = 0.082683; Test = 0.080127\n",
      "Iter 286, Minibatch Loss ---- Train = 0.075184; Test = 0.080236\n",
      "Iter 287, Minibatch Loss ---- Train = 0.075075; Test = 0.080359\n",
      "Iter 288, Minibatch Loss ---- Train = 0.077445; Test = 0.080300\n",
      "Iter 289, Minibatch Loss ---- Train = 0.083210; Test = 0.079968\n",
      "Iter 290, Minibatch Loss ---- Train = 0.078743; Test = 0.081077\n",
      "Iter 291, Minibatch Loss ---- Train = 0.078388; Test = 0.080008\n",
      "Iter 292, Minibatch Loss ---- Train = 0.073238; Test = 0.079840\n",
      "Iter 293, Minibatch Loss ---- Train = 0.074155; Test = 0.079524\n",
      "Iter 294, Minibatch Loss ---- Train = 0.077205; Test = 0.081532\n",
      "Iter 295, Minibatch Loss ---- Train = 0.096368; Test = 0.080222\n",
      "Iter 296, Minibatch Loss ---- Train = 0.066549; Test = 0.079804\n",
      "Iter 297, Minibatch Loss ---- Train = 0.080623; Test = 0.079927\n",
      "Iter 298, Minibatch Loss ---- Train = 0.079514; Test = 0.080624\n",
      "Iter 299, Minibatch Loss ---- Train = 0.080012; Test = 0.079791\n",
      "Iter 300, Minibatch Loss ---- Train = 0.073312; Test = 0.080320\n",
      "Iter 301, Minibatch Loss ---- Train = 0.091864; Test = 0.080103\n",
      "Iter 302, Minibatch Loss ---- Train = 0.078691; Test = 0.080522\n",
      "Iter 303, Minibatch Loss ---- Train = 0.072083; Test = 0.079871\n",
      "Iter 304, Minibatch Loss ---- Train = 0.092630; Test = 0.080162\n",
      "Iter 305, Minibatch Loss ---- Train = 0.089531; Test = 0.080360\n",
      "Iter 306, Minibatch Loss ---- Train = 0.064785; Test = 0.080194\n",
      "Iter 307, Minibatch Loss ---- Train = 0.075653; Test = 0.079299\n",
      "Iter 308, Minibatch Loss ---- Train = 0.073775; Test = 0.079913\n",
      "Iter 309, Minibatch Loss ---- Train = 0.074073; Test = 0.079852\n",
      "Iter 310, Minibatch Loss ---- Train = 0.079505; Test = 0.081165\n",
      "Iter 311, Minibatch Loss ---- Train = 0.071062; Test = 0.079687\n",
      "Iter 312, Minibatch Loss ---- Train = 0.084925; Test = 0.079415\n",
      "Iter 313, Minibatch Loss ---- Train = 0.079882; Test = 0.079769\n",
      "Iter 314, Minibatch Loss ---- Train = 0.081953; Test = 0.080435\n",
      "Iter 315, Minibatch Loss ---- Train = 0.065572; Test = 0.079249\n",
      "Iter 316, Minibatch Loss ---- Train = 0.076768; Test = 0.080357\n",
      "Iter 317, Minibatch Loss ---- Train = 0.111125; Test = 0.080218\n",
      "Iter 318, Minibatch Loss ---- Train = 0.078174; Test = 0.080222\n",
      "Iter 319, Minibatch Loss ---- Train = 0.081690; Test = 0.079415\n",
      "Iter 320, Minibatch Loss ---- Train = 0.084369; Test = 0.080210\n",
      "Iter 321, Minibatch Loss ---- Train = 0.088685; Test = 0.079993\n",
      "Iter 322, Minibatch Loss ---- Train = 0.080321; Test = 0.079742\n",
      "Iter 323, Minibatch Loss ---- Train = 0.076673; Test = 0.079594\n",
      "Iter 324, Minibatch Loss ---- Train = 0.080607; Test = 0.079612\n",
      "Iter 325, Minibatch Loss ---- Train = 0.071895; Test = 0.079787\n",
      "Iter 326, Minibatch Loss ---- Train = 0.072349; Test = 0.080487\n",
      "Iter 327, Minibatch Loss ---- Train = 0.076769; Test = 0.079160\n",
      "Iter 328, Minibatch Loss ---- Train = 0.078158; Test = 0.079964\n",
      "Iter 329, Minibatch Loss ---- Train = 0.067578; Test = 0.079231\n",
      "Iter 330, Minibatch Loss ---- Train = 0.081003; Test = 0.080823\n",
      "Iter 331, Minibatch Loss ---- Train = 0.076482; Test = 0.079758\n",
      "Iter 332, Minibatch Loss ---- Train = 0.090765; Test = 0.079209\n",
      "Iter 333, Minibatch Loss ---- Train = 0.078237; Test = 0.079005\n",
      "Iter 334, Minibatch Loss ---- Train = 0.087594; Test = 0.080887\n",
      "Iter 335, Minibatch Loss ---- Train = 0.073917; Test = 0.079289\n",
      "Iter 336, Minibatch Loss ---- Train = 0.088954; Test = 0.079960\n",
      "Iter 337, Minibatch Loss ---- Train = 0.091429; Test = 0.079584\n",
      "Iter 338, Minibatch Loss ---- Train = 0.076806; Test = 0.079421\n",
      "Iter 339, Minibatch Loss ---- Train = 0.080536; Test = 0.079067\n",
      "Iter 340, Minibatch Loss ---- Train = 0.070470; Test = 0.080147\n",
      "Iter 341, Minibatch Loss ---- Train = 0.072407; Test = 0.079219\n",
      "Iter 342, Minibatch Loss ---- Train = 0.074542; Test = 0.080075\n",
      "Iter 343, Minibatch Loss ---- Train = 0.082619; Test = 0.078661\n",
      "Iter 344, Minibatch Loss ---- Train = 0.088074; Test = 0.078802\n",
      "Iter 345, Minibatch Loss ---- Train = 0.074746; Test = 0.079904\n",
      "Iter 346, Minibatch Loss ---- Train = 0.082846; Test = 0.079866\n",
      "Iter 347, Minibatch Loss ---- Train = 0.074162; Test = 0.078842\n",
      "Iter 348, Minibatch Loss ---- Train = 0.071929; Test = 0.080322\n",
      "Iter 349, Minibatch Loss ---- Train = 0.066166; Test = 0.078428\n",
      "Iter 350, Minibatch Loss ---- Train = 0.094989; Test = 0.078721\n",
      "Iter 351, Minibatch Loss ---- Train = 0.079209; Test = 0.079943\n",
      "Iter 352, Minibatch Loss ---- Train = 0.085225; Test = 0.079490\n",
      "Iter 353, Minibatch Loss ---- Train = 0.065123; Test = 0.078747\n",
      "Iter 354, Minibatch Loss ---- Train = 0.083666; Test = 0.078967\n",
      "Iter 355, Minibatch Loss ---- Train = 0.077782; Test = 0.079555\n",
      "Iter 356, Minibatch Loss ---- Train = 0.068742; Test = 0.079828\n",
      "Iter 357, Minibatch Loss ---- Train = 0.083750; Test = 0.078891\n",
      "Iter 358, Minibatch Loss ---- Train = 0.078607; Test = 0.078504\n",
      "Iter 359, Minibatch Loss ---- Train = 0.073813; Test = 0.078689\n",
      "Iter 360, Minibatch Loss ---- Train = 0.073987; Test = 0.080243\n",
      "Iter 361, Minibatch Loss ---- Train = 0.082999; Test = 0.078553\n",
      "Iter 362, Minibatch Loss ---- Train = 0.077911; Test = 0.078880\n",
      "Iter 363, Minibatch Loss ---- Train = 0.068810; Test = 0.079279\n",
      "Iter 364, Minibatch Loss ---- Train = 0.070100; Test = 0.079723\n",
      "Iter 365, Minibatch Loss ---- Train = 0.077402; Test = 0.078677\n",
      "Iter 366, Minibatch Loss ---- Train = 0.076178; Test = 0.078728\n",
      "Iter 367, Minibatch Loss ---- Train = 0.070860; Test = 0.079001\n",
      "Iter 368, Minibatch Loss ---- Train = 0.081883; Test = 0.079236\n",
      "Iter 369, Minibatch Loss ---- Train = 0.070175; Test = 0.078381\n",
      "Iter 370, Minibatch Loss ---- Train = 0.078495; Test = 0.080056\n",
      "Iter 371, Minibatch Loss ---- Train = 0.068136; Test = 0.078279\n",
      "Iter 372, Minibatch Loss ---- Train = 0.078630; Test = 0.078923\n",
      "Iter 373, Minibatch Loss ---- Train = 0.069091; Test = 0.079090\n",
      "Iter 374, Minibatch Loss ---- Train = 0.078420; Test = 0.078977\n",
      "Iter 375, Minibatch Loss ---- Train = 0.069293; Test = 0.079049\n",
      "Iter 376, Minibatch Loss ---- Train = 0.073096; Test = 0.080332\n",
      "Iter 377, Minibatch Loss ---- Train = 0.092797; Test = 0.078531\n",
      "Iter 378, Minibatch Loss ---- Train = 0.077219; Test = 0.078513\n",
      "Iter 379, Minibatch Loss ---- Train = 0.072233; Test = 0.078936\n",
      "Iter 380, Minibatch Loss ---- Train = 0.065030; Test = 0.079610\n",
      "Iter 381, Minibatch Loss ---- Train = 0.082192; Test = 0.078258\n",
      "Iter 382, Minibatch Loss ---- Train = 0.075504; Test = 0.078913\n",
      "Iter 383, Minibatch Loss ---- Train = 0.072688; Test = 0.078509\n",
      "Iter 384, Minibatch Loss ---- Train = 0.090625; Test = 0.079805\n",
      "Iter 385, Minibatch Loss ---- Train = 0.088159; Test = 0.078578\n",
      "Iter 386, Minibatch Loss ---- Train = 0.075523; Test = 0.078893\n",
      "Iter 387, Minibatch Loss ---- Train = 0.073134; Test = 0.078259\n",
      "Iter 388, Minibatch Loss ---- Train = 0.079405; Test = 0.078506\n",
      "Iter 389, Minibatch Loss ---- Train = 0.077461; Test = 0.078893\n",
      "Iter 390, Minibatch Loss ---- Train = 0.071225; Test = 0.079205\n",
      "Iter 391, Minibatch Loss ---- Train = 0.083649; Test = 0.078356\n",
      "Iter 392, Minibatch Loss ---- Train = 0.072919; Test = 0.078713\n",
      "Iter 393, Minibatch Loss ---- Train = 0.080689; Test = 0.078649\n",
      "Iter 394, Minibatch Loss ---- Train = 0.082316; Test = 0.078787\n",
      "Iter 395, Minibatch Loss ---- Train = 0.078883; Test = 0.078675\n",
      "Iter 396, Minibatch Loss ---- Train = 0.085135; Test = 0.078288\n",
      "Iter 397, Minibatch Loss ---- Train = 0.083702; Test = 0.078547\n",
      "Iter 398, Minibatch Loss ---- Train = 0.078051; Test = 0.132965\n",
      "Iter 399, Minibatch Loss ---- Train = 0.081740; Test = 0.078304\n",
      "Iter 400, Minibatch Loss ---- Train = 0.068116; Test = 0.077710\n",
      "Iter 401, Minibatch Loss ---- Train = 0.073445; Test = 0.077909\n",
      "Iter 402, Minibatch Loss ---- Train = 0.084808; Test = 0.077173\n",
      "Iter 403, Minibatch Loss ---- Train = 0.065033; Test = 0.077610\n",
      "Iter 404, Minibatch Loss ---- Train = 0.072217; Test = 0.080588\n",
      "Iter 405, Minibatch Loss ---- Train = 0.076944; Test = 0.077842\n",
      "Iter 406, Minibatch Loss ---- Train = 0.076067; Test = 0.077688\n",
      "Iter 407, Minibatch Loss ---- Train = 0.084207; Test = 0.079389\n",
      "Iter 408, Minibatch Loss ---- Train = 0.083018; Test = 0.079192\n",
      "Iter 409, Minibatch Loss ---- Train = 0.085178; Test = 0.078484\n",
      "Iter 410, Minibatch Loss ---- Train = 0.071409; Test = 0.078993\n",
      "Iter 411, Minibatch Loss ---- Train = 0.079224; Test = 0.078368\n",
      "Iter 412, Minibatch Loss ---- Train = 0.093454; Test = 0.077512\n",
      "Iter 413, Minibatch Loss ---- Train = 0.067940; Test = 0.079003\n",
      "Iter 414, Minibatch Loss ---- Train = 0.160818; Test = 0.198027\n",
      "Iter 415, Minibatch Loss ---- Train = 0.074937; Test = 0.077245\n",
      "Iter 416, Minibatch Loss ---- Train = 0.099239; Test = 0.076990\n",
      "Iter 417, Minibatch Loss ---- Train = 0.073272; Test = 0.077679\n",
      "Iter 418, Minibatch Loss ---- Train = 0.086078; Test = 0.078399\n",
      "Iter 419, Minibatch Loss ---- Train = 0.078641; Test = 0.078678\n",
      "Iter 420, Minibatch Loss ---- Train = 0.079557; Test = 0.078156\n",
      "Iter 421, Minibatch Loss ---- Train = 0.083611; Test = 0.078384\n",
      "Iter 422, Minibatch Loss ---- Train = 0.060518; Test = 0.079254\n",
      "Iter 423, Minibatch Loss ---- Train = 0.080433; Test = 0.078172\n",
      "Iter 424, Minibatch Loss ---- Train = 0.073746; Test = 0.078100\n",
      "Iter 425, Minibatch Loss ---- Train = 0.081049; Test = 0.078951\n",
      "Iter 426, Minibatch Loss ---- Train = 0.081490; Test = 0.078623\n",
      "Iter 427, Minibatch Loss ---- Train = 0.064656; Test = 0.078264\n",
      "Iter 428, Minibatch Loss ---- Train = 0.076249; Test = 0.079138\n",
      "Iter 429, Minibatch Loss ---- Train = 0.083503; Test = 0.077991\n",
      "Iter 430, Minibatch Loss ---- Train = 0.118252; Test = 0.161930\n",
      "Iter 431, Minibatch Loss ---- Train = 0.071814; Test = 0.077043\n",
      "Iter 432, Minibatch Loss ---- Train = 0.066673; Test = 0.077336\n",
      "Iter 433, Minibatch Loss ---- Train = 0.068922; Test = 0.076993\n",
      "Iter 434, Minibatch Loss ---- Train = 0.077744; Test = 0.078260\n",
      "Iter 435, Minibatch Loss ---- Train = 0.077401; Test = 0.077996\n",
      "Iter 436, Minibatch Loss ---- Train = 0.083373; Test = 0.077945\n",
      "Iter 437, Minibatch Loss ---- Train = 0.078838; Test = 0.079106\n",
      "Iter 438, Minibatch Loss ---- Train = 0.075324; Test = 0.078182\n",
      "Iter 439, Minibatch Loss ---- Train = 0.071174; Test = 0.078283\n",
      "Iter 440, Minibatch Loss ---- Train = 0.056563; Test = 0.079660\n",
      "Iter 441, Minibatch Loss ---- Train = 0.068919; Test = 0.077935\n",
      "Iter 442, Minibatch Loss ---- Train = 0.078995; Test = 0.078075\n",
      "Iter 443, Minibatch Loss ---- Train = 0.076942; Test = 0.078802\n",
      "Iter 444, Minibatch Loss ---- Train = 0.057652; Test = 0.079577\n",
      "Iter 445, Minibatch Loss ---- Train = 0.080094; Test = 0.077857\n",
      "Iter 446, Minibatch Loss ---- Train = 0.078908; Test = 0.078402\n",
      "Iter 447, Minibatch Loss ---- Train = 0.075801; Test = 0.078813\n",
      "Iter 448, Minibatch Loss ---- Train = 0.066887; Test = 0.091672\n",
      "Iter 449, Minibatch Loss ---- Train = 0.071553; Test = 0.078544\n",
      "Iter 450, Minibatch Loss ---- Train = 0.089079; Test = 0.077678\n",
      "Iter 451, Minibatch Loss ---- Train = 0.077002; Test = 0.078283\n",
      "Iter 452, Minibatch Loss ---- Train = 0.083174; Test = 0.079271\n",
      "Iter 453, Minibatch Loss ---- Train = 0.071151; Test = 0.078037\n",
      "Iter 454, Minibatch Loss ---- Train = 0.071340; Test = 0.079607\n",
      "Iter 455, Minibatch Loss ---- Train = 0.086215; Test = 0.078048\n",
      "Iter 456, Minibatch Loss ---- Train = 0.068006; Test = 0.079210\n",
      "Iter 457, Minibatch Loss ---- Train = 0.086566; Test = 0.078586\n",
      "Iter 458, Minibatch Loss ---- Train = 0.076708; Test = 0.078572\n",
      "Iter 459, Minibatch Loss ---- Train = 0.074096; Test = 0.078220\n",
      "Iter 460, Minibatch Loss ---- Train = 0.063130; Test = 0.079736\n",
      "Iter 461, Minibatch Loss ---- Train = 0.082701; Test = 0.078282\n",
      "Iter 462, Minibatch Loss ---- Train = 0.096933; Test = 0.182905\n",
      "Iter 463, Minibatch Loss ---- Train = 0.073555; Test = 0.077698\n",
      "Iter 464, Minibatch Loss ---- Train = 0.072537; Test = 0.078546\n",
      "Iter 465, Minibatch Loss ---- Train = 0.067718; Test = 0.077933\n",
      "Iter 466, Minibatch Loss ---- Train = 0.089283; Test = 0.078738\n",
      "Iter 467, Minibatch Loss ---- Train = 0.074545; Test = 0.079256\n",
      "Iter 468, Minibatch Loss ---- Train = 0.069776; Test = 0.079066\n",
      "Iter 469, Minibatch Loss ---- Train = 0.092498; Test = 0.078735\n",
      "Iter 470, Minibatch Loss ---- Train = 0.072649; Test = 0.078381\n",
      "Iter 471, Minibatch Loss ---- Train = 0.084210; Test = 0.078377\n",
      "Iter 472, Minibatch Loss ---- Train = 0.072626; Test = 0.079029\n",
      "Iter 473, Minibatch Loss ---- Train = 0.091137; Test = 0.078685\n",
      "Iter 474, Minibatch Loss ---- Train = 0.091780; Test = 0.160682\n",
      "Iter 475, Minibatch Loss ---- Train = 0.069581; Test = 0.077092\n",
      "Iter 476, Minibatch Loss ---- Train = 0.060987; Test = 0.077580\n",
      "Iter 477, Minibatch Loss ---- Train = 0.080901; Test = 0.077456\n",
      "Iter 478, Minibatch Loss ---- Train = 0.089800; Test = 0.077289\n",
      "Iter 479, Minibatch Loss ---- Train = 0.069846; Test = 0.079580\n",
      "Iter 480, Minibatch Loss ---- Train = 0.059572; Test = 0.078948\n",
      "Iter 481, Minibatch Loss ---- Train = 0.073670; Test = 0.077816\n",
      "Iter 482, Minibatch Loss ---- Train = 0.067921; Test = 0.079207\n",
      "Iter 483, Minibatch Loss ---- Train = 0.082173; Test = 0.078327\n",
      "Iter 484, Minibatch Loss ---- Train = 0.082464; Test = 0.079142\n",
      "Iter 485, Minibatch Loss ---- Train = 0.069146; Test = 0.078769\n",
      "Iter 486, Minibatch Loss ---- Train = 0.072701; Test = 0.078700\n",
      "Iter 487, Minibatch Loss ---- Train = 0.079333; Test = 0.078663\n",
      "Iter 488, Minibatch Loss ---- Train = 0.084469; Test = 0.079037\n",
      "Iter 489, Minibatch Loss ---- Train = 0.074178; Test = 0.078825\n",
      "Iter 490, Minibatch Loss ---- Train = 0.089275; Test = 0.102228\n",
      "Iter 491, Minibatch Loss ---- Train = 0.079547; Test = 0.078106\n",
      "Iter 492, Minibatch Loss ---- Train = 0.083180; Test = 0.078177\n",
      "Iter 493, Minibatch Loss ---- Train = 0.067945; Test = 0.078408\n",
      "Iter 494, Minibatch Loss ---- Train = 0.076148; Test = 0.079004\n",
      "Iter 495, Minibatch Loss ---- Train = 0.088786; Test = 0.079188\n",
      "Iter 496, Minibatch Loss ---- Train = 0.069519; Test = 0.078456\n",
      "Iter 497, Minibatch Loss ---- Train = 0.085316; Test = 0.077769\n",
      "Iter 498, Minibatch Loss ---- Train = 0.076438; Test = 0.079751\n",
      "Iter 499, Minibatch Loss ---- Train = 0.068296; Test = 0.078315\n",
      "Iter 500, Minibatch Loss ---- Train = 0.078865; Test = 0.078688\n",
      "Iter 501, Minibatch Loss ---- Train = 0.072148; Test = 0.078707\n",
      "Iter 502, Minibatch Loss ---- Train = 0.080744; Test = 0.079327\n",
      "Iter 503, Minibatch Loss ---- Train = 0.083898; Test = 0.078817\n",
      "Iter 504, Minibatch Loss ---- Train = 0.100810; Test = 0.142957\n",
      "Iter 505, Minibatch Loss ---- Train = 0.084625; Test = 0.078338\n",
      "Iter 506, Minibatch Loss ---- Train = 0.076316; Test = 0.078109\n",
      "Iter 507, Minibatch Loss ---- Train = 0.074299; Test = 0.079039\n",
      "Iter 508, Minibatch Loss ---- Train = 0.074207; Test = 0.078373\n",
      "Iter 509, Minibatch Loss ---- Train = 0.072906; Test = 0.078850\n",
      "Iter 510, Minibatch Loss ---- Train = 0.081156; Test = 0.078642\n",
      "Iter 511, Minibatch Loss ---- Train = 0.063307; Test = 0.078558\n",
      "Iter 512, Minibatch Loss ---- Train = 0.071956; Test = 0.079236\n",
      "Iter 513, Minibatch Loss ---- Train = 0.071733; Test = 0.078277\n",
      "Iter 514, Minibatch Loss ---- Train = 0.115257; Test = 0.197336\n",
      "Iter 515, Minibatch Loss ---- Train = 0.093312; Test = 0.077169\n",
      "Iter 516, Minibatch Loss ---- Train = 0.059158; Test = 0.077524\n",
      "Iter 517, Minibatch Loss ---- Train = 0.085613; Test = 0.077606\n",
      "Iter 518, Minibatch Loss ---- Train = 0.079438; Test = 0.078382\n",
      "Iter 519, Minibatch Loss ---- Train = 0.077759; Test = 0.078163\n",
      "Iter 520, Minibatch Loss ---- Train = 0.068013; Test = 0.078633\n",
      "Iter 521, Minibatch Loss ---- Train = 0.085847; Test = 0.079042\n",
      "Iter 522, Minibatch Loss ---- Train = 0.069864; Test = 0.078438\n",
      "Iter 523, Minibatch Loss ---- Train = 0.068129; Test = 0.077920\n",
      "Iter 524, Minibatch Loss ---- Train = 0.077359; Test = 0.078159\n",
      "Iter 525, Minibatch Loss ---- Train = 0.074881; Test = 0.079239\n",
      "Iter 526, Minibatch Loss ---- Train = 0.064436; Test = 0.090911\n",
      "Iter 527, Minibatch Loss ---- Train = 0.075852; Test = 0.078019\n",
      "Iter 528, Minibatch Loss ---- Train = 0.078868; Test = 0.077965\n",
      "Iter 529, Minibatch Loss ---- Train = 0.068194; Test = 0.078622\n",
      "Iter 530, Minibatch Loss ---- Train = 0.073733; Test = 0.079172\n",
      "Iter 531, Minibatch Loss ---- Train = 0.055982; Test = 0.078184\n",
      "Iter 532, Minibatch Loss ---- Train = 0.094849; Test = 0.077589\n",
      "Iter 533, Minibatch Loss ---- Train = 0.069304; Test = 0.079347\n",
      "Iter 534, Minibatch Loss ---- Train = 0.076922; Test = 0.090410\n",
      "Iter 535, Minibatch Loss ---- Train = 0.077311; Test = 0.078425\n",
      "Iter 536, Minibatch Loss ---- Train = 0.066844; Test = 0.078122\n",
      "Iter 537, Minibatch Loss ---- Train = 0.075028; Test = 0.078363\n",
      "Iter 538, Minibatch Loss ---- Train = 0.081365; Test = 0.078491\n",
      "Iter 539, Minibatch Loss ---- Train = 0.081879; Test = 0.078330\n",
      "Iter 540, Minibatch Loss ---- Train = 0.079855; Test = 0.079916\n",
      "Iter 541, Minibatch Loss ---- Train = 0.085446; Test = 0.078427\n",
      "Iter 542, Minibatch Loss ---- Train = 0.075498; Test = 0.078334\n",
      "Iter 543, Minibatch Loss ---- Train = 0.081284; Test = 0.078369\n",
      "Iter 544, Minibatch Loss ---- Train = 0.090105; Test = 0.078802\n",
      "Iter 545, Minibatch Loss ---- Train = 0.087555; Test = 0.078778\n",
      "Iter 546, Minibatch Loss ---- Train = 0.084078; Test = 0.078861\n",
      "Iter 547, Minibatch Loss ---- Train = 0.080019; Test = 0.078836\n",
      "Iter 548, Minibatch Loss ---- Train = 0.071614; Test = 0.078873\n",
      "Iter 549, Minibatch Loss ---- Train = 0.080952; Test = 0.078486\n",
      "Iter 550, Minibatch Loss ---- Train = 0.080613; Test = 0.077876\n",
      "Iter 551, Minibatch Loss ---- Train = 0.093270; Test = 0.079573\n",
      "Iter 552, Minibatch Loss ---- Train = 0.079332; Test = 0.078067\n",
      "Iter 553, Minibatch Loss ---- Train = 0.079932; Test = 0.078569\n",
      "Iter 554, Minibatch Loss ---- Train = 0.203229; Test = 0.278065\n",
      "Iter 555, Minibatch Loss ---- Train = 0.072495; Test = 0.077091\n",
      "Iter 556, Minibatch Loss ---- Train = 0.076126; Test = 0.077410\n",
      "Iter 557, Minibatch Loss ---- Train = 0.080370; Test = 0.077833\n",
      "Iter 558, Minibatch Loss ---- Train = 0.075988; Test = 0.078498\n",
      "Iter 559, Minibatch Loss ---- Train = 0.073518; Test = 0.078250\n",
      "Iter 560, Minibatch Loss ---- Train = 0.099961; Test = 0.078169\n",
      "Iter 561, Minibatch Loss ---- Train = 0.081514; Test = 0.079441\n",
      "Iter 562, Minibatch Loss ---- Train = 0.069375; Test = 0.078346\n",
      "Iter 563, Minibatch Loss ---- Train = 0.079837; Test = 0.078491\n",
      "Iter 564, Minibatch Loss ---- Train = 0.073808; Test = 0.077925\n",
      "Iter 565, Minibatch Loss ---- Train = 0.076740; Test = 0.079104\n",
      "Iter 566, Minibatch Loss ---- Train = 0.122206; Test = 0.222262\n",
      "Iter 567, Minibatch Loss ---- Train = 0.095743; Test = 0.077305\n",
      "Iter 568, Minibatch Loss ---- Train = 0.072959; Test = 0.077251\n",
      "Iter 569, Minibatch Loss ---- Train = 0.088598; Test = 0.077416\n",
      "Iter 570, Minibatch Loss ---- Train = 0.078170; Test = 0.078078\n",
      "Iter 571, Minibatch Loss ---- Train = 0.072790; Test = 0.078881\n",
      "Iter 572, Minibatch Loss ---- Train = 0.075559; Test = 0.078728\n",
      "Iter 573, Minibatch Loss ---- Train = 0.068175; Test = 0.078021\n",
      "Iter 574, Minibatch Loss ---- Train = 0.074566; Test = 0.078934\n",
      "Iter 575, Minibatch Loss ---- Train = 0.073468; Test = 0.079012\n",
      "Iter 576, Minibatch Loss ---- Train = 0.069588; Test = 0.078680\n",
      "Iter 577, Minibatch Loss ---- Train = 0.073087; Test = 0.078238\n",
      "Iter 578, Minibatch Loss ---- Train = 0.075551; Test = 0.078314\n",
      "Iter 579, Minibatch Loss ---- Train = 0.079342; Test = 0.078644\n",
      "Iter 580, Minibatch Loss ---- Train = 0.090544; Test = 0.078852\n",
      "Iter 581, Minibatch Loss ---- Train = 0.068598; Test = 0.078372\n",
      "Iter 582, Minibatch Loss ---- Train = 0.119317; Test = 0.190234\n",
      "Iter 583, Minibatch Loss ---- Train = 0.076625; Test = 0.077892\n",
      "Iter 584, Minibatch Loss ---- Train = 0.070861; Test = 0.077790\n",
      "Iter 585, Minibatch Loss ---- Train = 0.085964; Test = 0.078186\n",
      "Iter 586, Minibatch Loss ---- Train = 0.079075; Test = 0.079091\n",
      "Iter 587, Minibatch Loss ---- Train = 0.063223; Test = 0.078155\n",
      "Iter 588, Minibatch Loss ---- Train = 0.083613; Test = 0.078254\n",
      "Iter 589, Minibatch Loss ---- Train = 0.074095; Test = 0.079452\n",
      "Iter 590, Minibatch Loss ---- Train = 0.086081; Test = 0.077938\n",
      "Iter 591, Minibatch Loss ---- Train = 0.083317; Test = 0.078435\n",
      "Iter 592, Minibatch Loss ---- Train = 0.081236; Test = 0.079194\n",
      "Iter 593, Minibatch Loss ---- Train = 0.078501; Test = 0.078828\n",
      "Iter 594, Minibatch Loss ---- Train = 0.112818; Test = 0.154175\n",
      "Iter 595, Minibatch Loss ---- Train = 0.082748; Test = 0.077373\n",
      "Iter 596, Minibatch Loss ---- Train = 0.075013; Test = 0.077219\n",
      "Iter 597, Minibatch Loss ---- Train = 0.065841; Test = 0.077150\n",
      "Iter 598, Minibatch Loss ---- Train = 0.070988; Test = 0.079523\n",
      "Iter 599, Minibatch Loss ---- Train = 0.072060; Test = 0.078256\n",
      "Iter 600, Minibatch Loss ---- Train = 0.080813; Test = 0.078378\n",
      "Iter 601, Minibatch Loss ---- Train = 0.073680; Test = 0.079059\n",
      "Iter 602, Minibatch Loss ---- Train = 0.072017; Test = 0.079018\n",
      "Iter 603, Minibatch Loss ---- Train = 0.066432; Test = 0.078101\n",
      "Iter 604, Minibatch Loss ---- Train = 0.091329; Test = 0.077695\n",
      "Iter 605, Minibatch Loss ---- Train = 0.070890; Test = 0.079364\n",
      "Iter 606, Minibatch Loss ---- Train = 0.080289; Test = 0.078467\n",
      "Iter 607, Minibatch Loss ---- Train = 0.086602; Test = 0.078857\n",
      "Iter 608, Minibatch Loss ---- Train = 0.070649; Test = 0.078993\n",
      "Iter 609, Minibatch Loss ---- Train = 0.058876; Test = 0.078021\n",
      "Iter 610, Minibatch Loss ---- Train = 0.080275; Test = 0.077714\n",
      "Iter 611, Minibatch Loss ---- Train = 0.076300; Test = 0.078933\n",
      "Iter 612, Minibatch Loss ---- Train = 0.086570; Test = 0.080153\n",
      "Iter 613, Minibatch Loss ---- Train = 0.076204; Test = 0.078108\n",
      "Iter 614, Minibatch Loss ---- Train = 0.104798; Test = 0.146165\n",
      "Iter 615, Minibatch Loss ---- Train = 0.077286; Test = 0.077199\n",
      "Iter 616, Minibatch Loss ---- Train = 0.064264; Test = 0.077060\n",
      "Iter 617, Minibatch Loss ---- Train = 0.080619; Test = 0.077906\n",
      "Iter 618, Minibatch Loss ---- Train = 0.071152; Test = 0.078312\n",
      "Iter 619, Minibatch Loss ---- Train = 0.076253; Test = 0.077846\n",
      "Iter 620, Minibatch Loss ---- Train = 0.076060; Test = 0.078826\n",
      "Iter 621, Minibatch Loss ---- Train = 0.069027; Test = 0.078166\n",
      "Iter 622, Minibatch Loss ---- Train = 0.088301; Test = 0.078690\n",
      "Iter 623, Minibatch Loss ---- Train = 0.083884; Test = 0.079205\n",
      "Iter 624, Minibatch Loss ---- Train = 0.076288; Test = 0.078454\n",
      "Iter 625, Minibatch Loss ---- Train = 0.100476; Test = 0.078562\n",
      "Iter 626, Minibatch Loss ---- Train = 0.088691; Test = 0.078701\n",
      "Iter 627, Minibatch Loss ---- Train = 0.073879; Test = 0.078677\n",
      "Iter 628, Minibatch Loss ---- Train = 0.094730; Test = 0.078135\n",
      "Iter 629, Minibatch Loss ---- Train = 0.073530; Test = 0.077987\n",
      "Iter 630, Minibatch Loss ---- Train = 0.069207; Test = 0.081253\n",
      "Iter 631, Minibatch Loss ---- Train = 0.065985; Test = 0.077732\n",
      "Iter 632, Minibatch Loss ---- Train = 0.080600; Test = 0.077811\n",
      "Iter 633, Minibatch Loss ---- Train = 0.103033; Test = 0.078794\n",
      "Iter 634, Minibatch Loss ---- Train = 0.088254; Test = 0.078213\n",
      "Iter 635, Minibatch Loss ---- Train = 0.073031; Test = 0.078671\n",
      "Iter 636, Minibatch Loss ---- Train = 0.141702; Test = 0.204792\n",
      "Iter 637, Minibatch Loss ---- Train = 0.072169; Test = 0.077160\n",
      "Iter 638, Minibatch Loss ---- Train = 0.066595; Test = 0.077515\n",
      "Iter 639, Minibatch Loss ---- Train = 0.075922; Test = 0.077305\n",
      "Iter 640, Minibatch Loss ---- Train = 0.069438; Test = 0.078837\n",
      "Iter 641, Minibatch Loss ---- Train = 0.085811; Test = 0.078078\n",
      "Iter 642, Minibatch Loss ---- Train = 0.077195; Test = 0.077636\n",
      "Iter 643, Minibatch Loss ---- Train = 0.077474; Test = 0.078670\n",
      "Iter 644, Minibatch Loss ---- Train = 0.080103; Test = 0.078240\n",
      "Iter 645, Minibatch Loss ---- Train = 0.066379; Test = 0.078486\n",
      "Iter 646, Minibatch Loss ---- Train = 0.071418; Test = 0.079613\n",
      "Iter 647, Minibatch Loss ---- Train = 0.070645; Test = 0.077383\n",
      "Iter 648, Minibatch Loss ---- Train = 0.074584; Test = 0.078545\n",
      "Iter 649, Minibatch Loss ---- Train = 0.075332; Test = 0.078806\n",
      "Iter 650, Minibatch Loss ---- Train = 0.076004; Test = 0.079900\n",
      "Iter 651, Minibatch Loss ---- Train = 0.066191; Test = 0.078248\n",
      "Iter 652, Minibatch Loss ---- Train = 0.077411; Test = 0.077653\n",
      "Iter 653, Minibatch Loss ---- Train = 0.077328; Test = 0.078901\n",
      "Iter 654, Minibatch Loss ---- Train = 0.070880; Test = 0.079304\n",
      "Iter 655, Minibatch Loss ---- Train = 0.068764; Test = 0.077739\n",
      "Iter 656, Minibatch Loss ---- Train = 0.097936; Test = 0.168043\n",
      "Iter 657, Minibatch Loss ---- Train = 0.072402; Test = 0.077077\n",
      "Iter 658, Minibatch Loss ---- Train = 0.072019; Test = 0.077646\n",
      "Iter 659, Minibatch Loss ---- Train = 0.066975; Test = 0.077405\n",
      "Iter 660, Minibatch Loss ---- Train = 0.081830; Test = 0.079035\n",
      "Iter 661, Minibatch Loss ---- Train = 0.091951; Test = 0.078544\n",
      "Iter 662, Minibatch Loss ---- Train = 0.081270; Test = 0.078093\n",
      "Iter 663, Minibatch Loss ---- Train = 0.073608; Test = 0.078754\n",
      "Iter 664, Minibatch Loss ---- Train = 0.075312; Test = 0.078813\n",
      "Iter 665, Minibatch Loss ---- Train = 0.080646; Test = 0.078742\n",
      "Iter 666, Minibatch Loss ---- Train = 0.079462; Test = 0.078929\n",
      "Iter 667, Minibatch Loss ---- Train = 0.073334; Test = 0.078563\n",
      "Iter 668, Minibatch Loss ---- Train = 0.078596; Test = 0.078613\n",
      "Iter 669, Minibatch Loss ---- Train = 0.083943; Test = 0.078464\n",
      "Iter 670, Minibatch Loss ---- Train = 0.093177; Test = 0.078548\n",
      "Iter 671, Minibatch Loss ---- Train = 0.082180; Test = 0.078530\n",
      "Iter 672, Minibatch Loss ---- Train = 0.080762; Test = 0.099328\n",
      "Iter 673, Minibatch Loss ---- Train = 0.073861; Test = 0.077031\n",
      "Iter 674, Minibatch Loss ---- Train = 0.073683; Test = 0.076831\n",
      "Iter 675, Minibatch Loss ---- Train = 0.077387; Test = 0.076719\n",
      "Iter 676, Minibatch Loss ---- Train = 0.072725; Test = 0.076780\n",
      "Iter 677, Minibatch Loss ---- Train = 0.068143; Test = 0.077078\n",
      "Iter 678, Minibatch Loss ---- Train = 0.090198; Test = 0.080435\n",
      "Iter 679, Minibatch Loss ---- Train = 0.084284; Test = 0.079111\n",
      "Iter 680, Minibatch Loss ---- Train = 0.074944; Test = 0.077883\n",
      "Iter 681, Minibatch Loss ---- Train = 0.086627; Test = 0.078325\n",
      "Iter 682, Minibatch Loss ---- Train = 0.074661; Test = 0.079422\n",
      "Iter 683, Minibatch Loss ---- Train = 0.061937; Test = 0.078055\n",
      "Iter 684, Minibatch Loss ---- Train = 0.084683; Test = 0.079893\n",
      "Iter 685, Minibatch Loss ---- Train = 0.076318; Test = 0.079221\n",
      "Iter 686, Minibatch Loss ---- Train = 0.076345; Test = 0.078271\n",
      "Iter 687, Minibatch Loss ---- Train = 0.077847; Test = 0.077685\n",
      "Iter 688, Minibatch Loss ---- Train = 0.078234; Test = 0.080071\n",
      "Iter 689, Minibatch Loss ---- Train = 0.066854; Test = 0.078392\n",
      "Iter 690, Minibatch Loss ---- Train = 0.077959; Test = 0.080129\n",
      "Iter 691, Minibatch Loss ---- Train = 0.080618; Test = 0.079967\n",
      "Iter 692, Minibatch Loss ---- Train = 0.075687; Test = 0.078155\n",
      "Iter 693, Minibatch Loss ---- Train = 0.078624; Test = 0.078409\n",
      "Iter 694, Minibatch Loss ---- Train = 0.080428; Test = 0.078180\n",
      "Iter 695, Minibatch Loss ---- Train = 0.068330; Test = 0.079017\n",
      "Iter 696, Minibatch Loss ---- Train = 0.085844; Test = 0.081389\n",
      "Iter 697, Minibatch Loss ---- Train = 0.087567; Test = 0.078703\n",
      "Iter 698, Minibatch Loss ---- Train = 0.076751; Test = 0.078344\n",
      "Iter 699, Minibatch Loss ---- Train = 0.085034; Test = 0.078946\n",
      "Iter 700, Minibatch Loss ---- Train = 0.079432; Test = 0.077975\n",
      "Iter 701, Minibatch Loss ---- Train = 0.078201; Test = 0.077923\n",
      "Iter 702, Minibatch Loss ---- Train = 0.068721; Test = 0.079828\n",
      "Iter 703, Minibatch Loss ---- Train = 0.073215; Test = 0.077800\n",
      "Iter 704, Minibatch Loss ---- Train = 0.131922; Test = 0.229225\n",
      "Iter 705, Minibatch Loss ---- Train = 0.066786; Test = 0.077221\n",
      "Iter 706, Minibatch Loss ---- Train = 0.066206; Test = 0.077215\n",
      "Iter 707, Minibatch Loss ---- Train = 0.059619; Test = 0.076954\n",
      "Iter 708, Minibatch Loss ---- Train = 0.073463; Test = 0.077757\n",
      "Iter 709, Minibatch Loss ---- Train = 0.060914; Test = 0.078193\n",
      "Iter 710, Minibatch Loss ---- Train = 0.066347; Test = 0.080515\n",
      "Iter 711, Minibatch Loss ---- Train = 0.066287; Test = 0.077825\n",
      "Iter 712, Minibatch Loss ---- Train = 0.085602; Test = 0.077033\n",
      "Iter 713, Minibatch Loss ---- Train = 0.073127; Test = 0.079266\n",
      "Iter 714, Minibatch Loss ---- Train = 0.097730; Test = 0.078856\n",
      "Iter 715, Minibatch Loss ---- Train = 0.077626; Test = 0.078856\n",
      "Iter 716, Minibatch Loss ---- Train = 0.070696; Test = 0.078433\n",
      "Iter 717, Minibatch Loss ---- Train = 0.078810; Test = 0.078134\n",
      "Iter 718, Minibatch Loss ---- Train = 0.070670; Test = 0.079755\n",
      "Iter 719, Minibatch Loss ---- Train = 0.077568; Test = 0.078148\n",
      "Iter 720, Minibatch Loss ---- Train = 0.064173; Test = 0.078105\n",
      "Iter 721, Minibatch Loss ---- Train = 0.083820; Test = 0.078534\n",
      "Iter 722, Minibatch Loss ---- Train = 0.079904; Test = 0.078574\n",
      "Iter 723, Minibatch Loss ---- Train = 0.089688; Test = 0.078796\n",
      "Iter 724, Minibatch Loss ---- Train = 0.075706; Test = 0.078165\n",
      "Iter 725, Minibatch Loss ---- Train = 0.076412; Test = 0.078171\n",
      "Iter 726, Minibatch Loss ---- Train = 0.074234; Test = 0.079674\n",
      "Iter 727, Minibatch Loss ---- Train = 0.066427; Test = 0.078144\n",
      "Iter 728, Minibatch Loss ---- Train = 0.073223; Test = 0.079104\n",
      "Iter 729, Minibatch Loss ---- Train = 0.087275; Test = 0.078137\n",
      "Iter 730, Minibatch Loss ---- Train = 0.068297; Test = 0.078539\n",
      "Iter 731, Minibatch Loss ---- Train = 0.079648; Test = 0.078105\n",
      "Iter 732, Minibatch Loss ---- Train = 0.087918; Test = 0.078651\n",
      "Iter 733, Minibatch Loss ---- Train = 0.084748; Test = 0.078255\n",
      "Iter 734, Minibatch Loss ---- Train = 0.080762; Test = 0.088654\n",
      "Iter 735, Minibatch Loss ---- Train = 0.071261; Test = 0.078190\n",
      "Iter 736, Minibatch Loss ---- Train = 0.077557; Test = 0.078348\n",
      "Iter 737, Minibatch Loss ---- Train = 0.085132; Test = 0.078749\n",
      "Iter 738, Minibatch Loss ---- Train = 0.066612; Test = 0.078457\n",
      "Iter 739, Minibatch Loss ---- Train = 0.071525; Test = 0.077780\n",
      "Iter 740, Minibatch Loss ---- Train = 0.064952; Test = 0.079032\n",
      "Iter 741, Minibatch Loss ---- Train = 0.075521; Test = 0.093734\n",
      "Iter 742, Minibatch Loss ---- Train = 0.070612; Test = 0.077788\n",
      "Iter 743, Minibatch Loss ---- Train = 0.067817; Test = 0.077185\n",
      "Iter 744, Minibatch Loss ---- Train = 0.077604; Test = 0.077190\n",
      "Iter 745, Minibatch Loss ---- Train = 0.067619; Test = 0.081349\n",
      "Iter 746, Minibatch Loss ---- Train = 0.077552; Test = 0.078394\n",
      "Iter 747, Minibatch Loss ---- Train = 0.077138; Test = 0.078367\n",
      "Iter 748, Minibatch Loss ---- Train = 0.064827; Test = 0.078349\n",
      "Iter 749, Minibatch Loss ---- Train = 0.073313; Test = 0.079592\n",
      "Iter 750, Minibatch Loss ---- Train = 0.101786; Test = 0.078850\n",
      "Iter 751, Minibatch Loss ---- Train = 0.087508; Test = 0.077020\n",
      "Iter 752, Minibatch Loss ---- Train = 0.078466; Test = 0.077563\n",
      "Iter 753, Minibatch Loss ---- Train = 0.083523; Test = 0.080352\n",
      "Iter 754, Minibatch Loss ---- Train = 0.088414; Test = 0.077660\n",
      "Iter 755, Minibatch Loss ---- Train = 0.072964; Test = 0.077444\n",
      "Iter 756, Minibatch Loss ---- Train = 0.075603; Test = 0.077221\n",
      "Iter 757, Minibatch Loss ---- Train = 0.081253; Test = 0.079308\n",
      "Iter 758, Minibatch Loss ---- Train = 0.081675; Test = 0.077980\n",
      "Iter 759, Minibatch Loss ---- Train = 0.078569; Test = 0.078246\n",
      "Iter 760, Minibatch Loss ---- Train = 0.066114; Test = 0.077708\n",
      "Iter 761, Minibatch Loss ---- Train = 0.072610; Test = 0.079486\n",
      "Iter 762, Minibatch Loss ---- Train = 0.075402; Test = 0.077955\n",
      "Iter 763, Minibatch Loss ---- Train = 0.076452; Test = 0.078110\n",
      "Iter 764, Minibatch Loss ---- Train = 0.070391; Test = 0.077707\n",
      "Iter 765, Minibatch Loss ---- Train = 0.074596; Test = 0.079452\n",
      "Iter 766, Minibatch Loss ---- Train = 0.064499; Test = 0.077495\n",
      "Iter 767, Minibatch Loss ---- Train = 0.091792; Test = 0.077081\n",
      "Iter 768, Minibatch Loss ---- Train = 0.078203; Test = 0.078417\n",
      "Iter 769, Minibatch Loss ---- Train = 0.074385; Test = 0.086976\n",
      "Iter 770, Minibatch Loss ---- Train = 0.074358; Test = 0.077358\n",
      "Iter 771, Minibatch Loss ---- Train = 0.067426; Test = 0.078606\n",
      "Iter 772, Minibatch Loss ---- Train = 0.062652; Test = 0.077812\n",
      "Iter 773, Minibatch Loss ---- Train = 0.070393; Test = 0.078228\n",
      "Iter 774, Minibatch Loss ---- Train = 0.067146; Test = 0.077455\n",
      "Iter 775, Minibatch Loss ---- Train = 0.060996; Test = 0.078322\n",
      "Iter 776, Minibatch Loss ---- Train = 0.070326; Test = 0.077956\n",
      "Iter 777, Minibatch Loss ---- Train = 0.084220; Test = 0.078304\n",
      "Iter 778, Minibatch Loss ---- Train = 0.078268; Test = 0.077879\n",
      "Iter 779, Minibatch Loss ---- Train = 0.083806; Test = 0.078147\n",
      "Iter 780, Minibatch Loss ---- Train = 0.070266; Test = 0.078202\n",
      "Iter 781, Minibatch Loss ---- Train = 0.082408; Test = 0.078840\n",
      "Iter 782, Minibatch Loss ---- Train = 0.089973; Test = 0.078389\n",
      "Iter 783, Minibatch Loss ---- Train = 0.087472; Test = 0.076911\n",
      "Iter 784, Minibatch Loss ---- Train = 0.076940; Test = 0.078354\n",
      "Iter 785, Minibatch Loss ---- Train = 0.066828; Test = 0.078580\n",
      "Iter 786, Minibatch Loss ---- Train = 0.073510; Test = 0.077482\n",
      "Iter 787, Minibatch Loss ---- Train = 0.070659; Test = 0.078054\n",
      "Iter 788, Minibatch Loss ---- Train = 0.095421; Test = 0.079095\n",
      "Iter 789, Minibatch Loss ---- Train = 0.077918; Test = 0.077445\n",
      "Iter 790, Minibatch Loss ---- Train = 0.078512; Test = 0.077589\n",
      "Iter 791, Minibatch Loss ---- Train = 0.080898; Test = 0.078584\n",
      "Iter 792, Minibatch Loss ---- Train = 0.072312; Test = 0.077665\n",
      "Iter 793, Minibatch Loss ---- Train = 0.088275; Test = 0.078028\n",
      "Iter 794, Minibatch Loss ---- Train = 0.069123; Test = 0.077751\n",
      "Iter 795, Minibatch Loss ---- Train = 0.065342; Test = 0.079634\n",
      "Iter 796, Minibatch Loss ---- Train = 0.075683; Test = 0.077841\n",
      "Iter 797, Minibatch Loss ---- Train = 0.077730; Test = 0.077981\n",
      "Iter 798, Minibatch Loss ---- Train = 0.061155; Test = 0.077376\n",
      "Iter 799, Minibatch Loss ---- Train = 0.077463; Test = 0.079172\n",
      "[0.5813621640934109, 0.58247062155202833, 0.58121742000834775, 0.58299689977638824, 0.58066839974693552, 0.58026759776295367, 0.58031291103399651, 0.58237265914219916, 0.58157182931152518, 0.58232662537116753]\n",
      "total running time cost:1737.41534209s\n",
      "Iter 0, Minibatch Loss ---- Train = 2.989562; Test = 2.963405\n",
      "Iter 1, Minibatch Loss ---- Train = 2.752424; Test = 2.688175\n",
      "Iter 2, Minibatch Loss ---- Train = 2.442125; Test = 2.442148\n",
      "Iter 3, Minibatch Loss ---- Train = 2.258767; Test = 2.205078\n",
      "Iter 4, Minibatch Loss ---- Train = 2.078022; Test = 1.950218\n",
      "Iter 5, Minibatch Loss ---- Train = 1.755451; Test = 1.740960\n",
      "Iter 6, Minibatch Loss ---- Train = 1.548357; Test = 1.524281\n",
      "Iter 7, Minibatch Loss ---- Train = 1.337360; Test = 1.264091\n",
      "Iter 8, Minibatch Loss ---- Train = 1.091991; Test = 1.013783\n",
      "Iter 9, Minibatch Loss ---- Train = 0.836466; Test = 0.801292\n",
      "Iter 10, Minibatch Loss ---- Train = 0.699865; Test = 0.645004\n",
      "Iter 11, Minibatch Loss ---- Train = 0.534710; Test = 0.529624\n",
      "Iter 12, Minibatch Loss ---- Train = 0.497119; Test = 0.444132\n",
      "Iter 13, Minibatch Loss ---- Train = 0.404464; Test = 0.383596\n",
      "Iter 14, Minibatch Loss ---- Train = 0.403129; Test = 0.365211\n",
      "Iter 15, Minibatch Loss ---- Train = 0.374197; Test = 0.353403\n",
      "Iter 16, Minibatch Loss ---- Train = 0.355217; Test = 0.352386\n",
      "Iter 17, Minibatch Loss ---- Train = 0.374049; Test = 0.340722\n",
      "Iter 18, Minibatch Loss ---- Train = 0.366075; Test = 0.350327\n",
      "Iter 19, Minibatch Loss ---- Train = 0.356255; Test = 0.314709\n",
      "Iter 20, Minibatch Loss ---- Train = 0.312190; Test = 0.333301\n",
      "Iter 21, Minibatch Loss ---- Train = 0.339171; Test = 0.317192\n",
      "Iter 22, Minibatch Loss ---- Train = 0.339423; Test = 0.339020\n",
      "Iter 23, Minibatch Loss ---- Train = 0.308829; Test = 0.306490\n",
      "Iter 24, Minibatch Loss ---- Train = 0.369352; Test = 0.319185\n",
      "Iter 25, Minibatch Loss ---- Train = 0.317832; Test = 0.311287\n",
      "Iter 26, Minibatch Loss ---- Train = 0.346187; Test = 0.326776\n",
      "Iter 27, Minibatch Loss ---- Train = 0.307160; Test = 0.296779\n",
      "Iter 28, Minibatch Loss ---- Train = 0.341487; Test = 0.311839\n",
      "Iter 29, Minibatch Loss ---- Train = 0.280910; Test = 0.294966\n",
      "Iter 30, Minibatch Loss ---- Train = 0.338365; Test = 0.316929\n",
      "Iter 31, Minibatch Loss ---- Train = 0.268625; Test = 0.289691\n",
      "Iter 32, Minibatch Loss ---- Train = 0.351066; Test = 0.306302\n",
      "Iter 33, Minibatch Loss ---- Train = 0.301637; Test = 0.287218\n",
      "Iter 34, Minibatch Loss ---- Train = 0.314825; Test = 0.308460\n",
      "Iter 35, Minibatch Loss ---- Train = 0.273944; Test = 0.282958\n",
      "Iter 36, Minibatch Loss ---- Train = 0.311073; Test = 0.301059\n",
      "Iter 37, Minibatch Loss ---- Train = 0.308491; Test = 0.281554\n",
      "Iter 38, Minibatch Loss ---- Train = 0.325730; Test = 0.302497\n",
      "Iter 39, Minibatch Loss ---- Train = 0.268514; Test = 0.277741\n",
      "Iter 40, Minibatch Loss ---- Train = 0.290976; Test = 0.296749\n",
      "Iter 41, Minibatch Loss ---- Train = 0.244195; Test = 0.275731\n",
      "Iter 42, Minibatch Loss ---- Train = 0.311655; Test = 0.295407\n",
      "Iter 43, Minibatch Loss ---- Train = 0.323866; Test = 0.272928\n",
      "Iter 44, Minibatch Loss ---- Train = 0.259159; Test = 0.291772\n",
      "Iter 45, Minibatch Loss ---- Train = 0.293177; Test = 0.270527\n",
      "Iter 46, Minibatch Loss ---- Train = 0.294571; Test = 0.290680\n",
      "Iter 47, Minibatch Loss ---- Train = 0.347620; Test = 0.268376\n",
      "Iter 48, Minibatch Loss ---- Train = 0.298218; Test = 0.287623\n",
      "Iter 49, Minibatch Loss ---- Train = 0.250332; Test = 0.266593\n",
      "Iter 50, Minibatch Loss ---- Train = 0.307523; Test = 0.264414\n",
      "Iter 51, Minibatch Loss ---- Train = 0.302766; Test = 0.261341\n",
      "Iter 52, Minibatch Loss ---- Train = 0.274025; Test = 0.257907\n",
      "Iter 53, Minibatch Loss ---- Train = 0.234009; Test = 0.254527\n",
      "Iter 54, Minibatch Loss ---- Train = 0.251465; Test = 0.251408\n",
      "Iter 55, Minibatch Loss ---- Train = 0.260794; Test = 0.248856\n",
      "Iter 56, Minibatch Loss ---- Train = 0.254858; Test = 0.246575\n",
      "Iter 57, Minibatch Loss ---- Train = 0.260465; Test = 0.243852\n",
      "Iter 58, Minibatch Loss ---- Train = 0.237456; Test = 0.241210\n",
      "Iter 59, Minibatch Loss ---- Train = 0.276291; Test = 0.241327\n",
      "Iter 60, Minibatch Loss ---- Train = 0.242670; Test = 0.236773\n",
      "Iter 61, Minibatch Loss ---- Train = 0.232220; Test = 0.234468\n",
      "Iter 62, Minibatch Loss ---- Train = 0.238510; Test = 0.231799\n",
      "Iter 63, Minibatch Loss ---- Train = 0.192307; Test = 0.228683\n",
      "Iter 64, Minibatch Loss ---- Train = 0.230378; Test = 0.225050\n",
      "Iter 65, Minibatch Loss ---- Train = 0.232087; Test = 0.226182\n",
      "Iter 66, Minibatch Loss ---- Train = 0.232796; Test = 0.221186\n",
      "Iter 67, Minibatch Loss ---- Train = 0.195067; Test = 0.218832\n",
      "Iter 68, Minibatch Loss ---- Train = 0.201706; Test = 0.217958\n",
      "Iter 69, Minibatch Loss ---- Train = 0.202121; Test = 0.216591\n",
      "Iter 70, Minibatch Loss ---- Train = 0.198722; Test = 0.214916\n",
      "Iter 71, Minibatch Loss ---- Train = 0.230496; Test = 0.213023\n",
      "Iter 72, Minibatch Loss ---- Train = 0.217199; Test = 0.210574\n",
      "Iter 73, Minibatch Loss ---- Train = 0.206694; Test = 0.211319\n",
      "Iter 74, Minibatch Loss ---- Train = 0.230113; Test = 0.207636\n",
      "Iter 75, Minibatch Loss ---- Train = 0.172143; Test = 0.206702\n",
      "Iter 76, Minibatch Loss ---- Train = 0.240180; Test = 0.204765\n",
      "Iter 77, Minibatch Loss ---- Train = 0.228117; Test = 0.206488\n",
      "Iter 78, Minibatch Loss ---- Train = 0.229388; Test = 0.202316\n",
      "Iter 79, Minibatch Loss ---- Train = 0.213159; Test = 0.202880\n",
      "Iter 80, Minibatch Loss ---- Train = 0.265367; Test = 0.198807\n",
      "Iter 81, Minibatch Loss ---- Train = 0.204605; Test = 0.199968\n",
      "Iter 82, Minibatch Loss ---- Train = 0.223062; Test = 0.200154\n",
      "Iter 83, Minibatch Loss ---- Train = 0.245685; Test = 0.196147\n",
      "Iter 84, Minibatch Loss ---- Train = 0.195172; Test = 0.197157\n",
      "Iter 85, Minibatch Loss ---- Train = 0.174379; Test = 0.198605\n",
      "Iter 86, Minibatch Loss ---- Train = 0.190806; Test = 0.195629\n",
      "Iter 87, Minibatch Loss ---- Train = 0.220154; Test = 0.193907\n",
      "Iter 88, Minibatch Loss ---- Train = 0.159281; Test = 0.192773\n",
      "Iter 89, Minibatch Loss ---- Train = 0.226723; Test = 0.196784\n",
      "Iter 90, Minibatch Loss ---- Train = 0.200786; Test = 0.193528\n",
      "Iter 91, Minibatch Loss ---- Train = 0.200546; Test = 0.193768\n",
      "Iter 92, Minibatch Loss ---- Train = 0.253180; Test = 0.190454\n",
      "Iter 93, Minibatch Loss ---- Train = 0.189484; Test = 0.191379\n",
      "Iter 94, Minibatch Loss ---- Train = 0.198495; Test = 0.192961\n",
      "Iter 95, Minibatch Loss ---- Train = 0.222796; Test = 0.192390\n",
      "Iter 96, Minibatch Loss ---- Train = 0.196168; Test = 0.189878\n",
      "Iter 97, Minibatch Loss ---- Train = 0.201893; Test = 0.190570\n",
      "Iter 98, Minibatch Loss ---- Train = 0.183442; Test = 0.190159\n",
      "Iter 99, Minibatch Loss ---- Train = 0.183904; Test = 0.190583\n",
      "Iter 100, Minibatch Loss ---- Train = 0.173697; Test = 0.189503\n",
      "Iter 101, Minibatch Loss ---- Train = 0.207447; Test = 0.190073\n",
      "Iter 102, Minibatch Loss ---- Train = 0.185062; Test = 0.188375\n",
      "Iter 103, Minibatch Loss ---- Train = 0.162911; Test = 0.187213\n",
      "Iter 104, Minibatch Loss ---- Train = 0.189317; Test = 0.187556\n",
      "Iter 105, Minibatch Loss ---- Train = 0.210099; Test = 0.191552\n",
      "Iter 106, Minibatch Loss ---- Train = 0.183991; Test = 0.187208\n",
      "Iter 107, Minibatch Loss ---- Train = 0.197037; Test = 0.186928\n",
      "Iter 108, Minibatch Loss ---- Train = 0.218701; Test = 0.187297\n",
      "Iter 109, Minibatch Loss ---- Train = 0.190766; Test = 0.188411\n",
      "Iter 110, Minibatch Loss ---- Train = 0.207086; Test = 0.186408\n",
      "Iter 111, Minibatch Loss ---- Train = 0.191651; Test = 0.188068\n",
      "Iter 112, Minibatch Loss ---- Train = 0.182977; Test = 0.187258\n",
      "Iter 113, Minibatch Loss ---- Train = 0.191276; Test = 0.186586\n",
      "Iter 114, Minibatch Loss ---- Train = 0.195932; Test = 0.185906\n",
      "Iter 115, Minibatch Loss ---- Train = 0.189967; Test = 0.188552\n",
      "Iter 116, Minibatch Loss ---- Train = 0.212671; Test = 0.185168\n",
      "Iter 117, Minibatch Loss ---- Train = 0.163880; Test = 0.185817\n",
      "Iter 118, Minibatch Loss ---- Train = 0.217551; Test = 0.184743\n",
      "Iter 119, Minibatch Loss ---- Train = 0.208318; Test = 0.187138\n",
      "Iter 120, Minibatch Loss ---- Train = 0.192901; Test = 0.186478\n",
      "Iter 121, Minibatch Loss ---- Train = 0.218208; Test = 0.186421\n",
      "Iter 122, Minibatch Loss ---- Train = 0.185026; Test = 0.185252\n",
      "Iter 123, Minibatch Loss ---- Train = 0.169387; Test = 0.185303\n",
      "Iter 124, Minibatch Loss ---- Train = 0.191668; Test = 0.184556\n",
      "Iter 125, Minibatch Loss ---- Train = 0.157453; Test = 0.186760\n",
      "Iter 126, Minibatch Loss ---- Train = 0.164576; Test = 0.186144\n",
      "Iter 127, Minibatch Loss ---- Train = 0.170774; Test = 0.184896\n",
      "Iter 128, Minibatch Loss ---- Train = 0.201421; Test = 0.183394\n",
      "Iter 129, Minibatch Loss ---- Train = 0.211203; Test = 0.188730\n",
      "Iter 130, Minibatch Loss ---- Train = 0.186571; Test = 0.184355\n",
      "Iter 131, Minibatch Loss ---- Train = 0.192431; Test = 0.184530\n",
      "Iter 132, Minibatch Loss ---- Train = 0.192434; Test = 0.185497\n",
      "Iter 133, Minibatch Loss ---- Train = 0.211140; Test = 0.185757\n",
      "Iter 134, Minibatch Loss ---- Train = 0.211834; Test = 0.183565\n",
      "Iter 135, Minibatch Loss ---- Train = 0.212600; Test = 0.187489\n",
      "Iter 136, Minibatch Loss ---- Train = 0.183487; Test = 0.184059\n",
      "Iter 137, Minibatch Loss ---- Train = 0.195150; Test = 0.185107\n",
      "Iter 138, Minibatch Loss ---- Train = 0.179479; Test = 0.184853\n",
      "Iter 139, Minibatch Loss ---- Train = 0.157285; Test = 0.184821\n",
      "Iter 140, Minibatch Loss ---- Train = 0.178552; Test = 0.185369\n",
      "Iter 141, Minibatch Loss ---- Train = 0.207049; Test = 0.184994\n",
      "Iter 142, Minibatch Loss ---- Train = 0.154646; Test = 0.183897\n",
      "Iter 143, Minibatch Loss ---- Train = 0.163276; Test = 0.184518\n",
      "Iter 144, Minibatch Loss ---- Train = 0.168288; Test = 0.185560\n",
      "Iter 145, Minibatch Loss ---- Train = 0.187926; Test = 0.184556\n",
      "Iter 146, Minibatch Loss ---- Train = 0.173617; Test = 0.184703\n",
      "Iter 147, Minibatch Loss ---- Train = 0.160684; Test = 0.184108\n",
      "Iter 148, Minibatch Loss ---- Train = 0.207545; Test = 0.184163\n",
      "Iter 149, Minibatch Loss ---- Train = 0.206065; Test = 0.186220\n",
      "Iter 150, Minibatch Loss ---- Train = 0.174407; Test = 0.183648\n",
      "Iter 151, Minibatch Loss ---- Train = 0.169519; Test = 0.184635\n",
      "Iter 152, Minibatch Loss ---- Train = 0.199079; Test = 0.184282\n",
      "Iter 153, Minibatch Loss ---- Train = 0.189286; Test = 0.185931\n",
      "Iter 154, Minibatch Loss ---- Train = 0.189921; Test = 0.183682\n",
      "Iter 155, Minibatch Loss ---- Train = 0.156069; Test = 0.183781\n",
      "Iter 156, Minibatch Loss ---- Train = 0.182990; Test = 0.184732\n",
      "Iter 157, Minibatch Loss ---- Train = 0.174544; Test = 0.184757\n",
      "Iter 158, Minibatch Loss ---- Train = 0.175933; Test = 0.187442\n",
      "Iter 159, Minibatch Loss ---- Train = 0.193544; Test = 0.183182\n",
      "Iter 160, Minibatch Loss ---- Train = 0.186711; Test = 0.182914\n",
      "Iter 161, Minibatch Loss ---- Train = 0.206121; Test = 0.186197\n",
      "Iter 162, Minibatch Loss ---- Train = 0.196589; Test = 0.183344\n",
      "Iter 163, Minibatch Loss ---- Train = 0.187543; Test = 0.185330\n",
      "Iter 164, Minibatch Loss ---- Train = 0.151044; Test = 0.184345\n",
      "Iter 165, Minibatch Loss ---- Train = 0.189110; Test = 0.183998\n",
      "Iter 166, Minibatch Loss ---- Train = 0.191355; Test = 0.183249\n",
      "Iter 167, Minibatch Loss ---- Train = 0.186435; Test = 0.185074\n",
      "Iter 168, Minibatch Loss ---- Train = 0.186951; Test = 0.183992\n",
      "Iter 169, Minibatch Loss ---- Train = 0.182852; Test = 0.184377\n",
      "Iter 170, Minibatch Loss ---- Train = 0.196966; Test = 0.183843\n",
      "Iter 171, Minibatch Loss ---- Train = 0.210714; Test = 0.184966\n",
      "Iter 172, Minibatch Loss ---- Train = 0.181364; Test = 0.183020\n",
      "Iter 173, Minibatch Loss ---- Train = 0.170487; Test = 0.182581\n",
      "Iter 174, Minibatch Loss ---- Train = 0.216688; Test = 0.190048\n",
      "Iter 175, Minibatch Loss ---- Train = 0.177008; Test = 0.183977\n",
      "Iter 176, Minibatch Loss ---- Train = 0.180092; Test = 0.183837\n",
      "Iter 177, Minibatch Loss ---- Train = 0.178752; Test = 0.184782\n",
      "Iter 178, Minibatch Loss ---- Train = 0.190786; Test = 0.182800\n",
      "Iter 179, Minibatch Loss ---- Train = 0.179887; Test = 0.183804\n",
      "Iter 180, Minibatch Loss ---- Train = 0.202651; Test = 0.183557\n",
      "Iter 181, Minibatch Loss ---- Train = 0.173706; Test = 0.184389\n",
      "Iter 182, Minibatch Loss ---- Train = 0.152356; Test = 0.184181\n",
      "Iter 183, Minibatch Loss ---- Train = 0.192118; Test = 0.183591\n",
      "Iter 184, Minibatch Loss ---- Train = 0.166896; Test = 0.183338\n",
      "Iter 185, Minibatch Loss ---- Train = 0.196847; Test = 0.184120\n",
      "Iter 186, Minibatch Loss ---- Train = 0.189787; Test = 0.184200\n",
      "Iter 187, Minibatch Loss ---- Train = 0.188250; Test = 0.184099\n",
      "Iter 188, Minibatch Loss ---- Train = 0.181623; Test = 0.183075\n",
      "Iter 189, Minibatch Loss ---- Train = 0.176347; Test = 0.184721\n",
      "Iter 190, Minibatch Loss ---- Train = 0.197526; Test = 0.182729\n",
      "Iter 191, Minibatch Loss ---- Train = 0.194086; Test = 0.184756\n",
      "Iter 192, Minibatch Loss ---- Train = 0.175380; Test = 0.183145\n",
      "Iter 193, Minibatch Loss ---- Train = 0.175677; Test = 0.183685\n",
      "Iter 194, Minibatch Loss ---- Train = 0.190700; Test = 0.182833\n",
      "Iter 195, Minibatch Loss ---- Train = 0.153228; Test = 0.182944\n",
      "Iter 196, Minibatch Loss ---- Train = 0.173150; Test = 0.185866\n",
      "Iter 197, Minibatch Loss ---- Train = 0.177590; Test = 0.182998\n",
      "Iter 198, Minibatch Loss ---- Train = 0.201125; Test = 0.185078\n",
      "Iter 199, Minibatch Loss ---- Train = 0.170494; Test = 0.183511\n",
      "Iter 200, Minibatch Loss ---- Train = 0.202854; Test = 0.183246\n",
      "Iter 201, Minibatch Loss ---- Train = 0.191511; Test = 0.184024\n",
      "Iter 202, Minibatch Loss ---- Train = 0.178069; Test = 0.183417\n",
      "Iter 203, Minibatch Loss ---- Train = 0.191730; Test = 0.183124\n",
      "Iter 204, Minibatch Loss ---- Train = 0.194773; Test = 0.182505\n",
      "Iter 205, Minibatch Loss ---- Train = 0.181636; Test = 0.184188\n",
      "Iter 206, Minibatch Loss ---- Train = 0.214527; Test = 0.195418\n",
      "Iter 207, Minibatch Loss ---- Train = 0.198300; Test = 0.183125\n",
      "Iter 208, Minibatch Loss ---- Train = 0.150667; Test = 0.182544\n",
      "Iter 209, Minibatch Loss ---- Train = 0.194115; Test = 0.183081\n",
      "Iter 210, Minibatch Loss ---- Train = 0.173005; Test = 0.183002\n",
      "Iter 211, Minibatch Loss ---- Train = 0.175891; Test = 0.184107\n",
      "Iter 212, Minibatch Loss ---- Train = 0.224337; Test = 0.182179\n",
      "Iter 213, Minibatch Loss ---- Train = 0.192352; Test = 0.189217\n",
      "Iter 214, Minibatch Loss ---- Train = 0.188718; Test = 0.181877\n",
      "Iter 215, Minibatch Loss ---- Train = 0.188222; Test = 0.183816\n",
      "Iter 216, Minibatch Loss ---- Train = 0.166452; Test = 0.183671\n",
      "Iter 217, Minibatch Loss ---- Train = 0.171601; Test = 0.182771\n",
      "Iter 218, Minibatch Loss ---- Train = 0.195402; Test = 0.181843\n",
      "Iter 219, Minibatch Loss ---- Train = 0.177466; Test = 0.183199\n",
      "Iter 220, Minibatch Loss ---- Train = 0.163260; Test = 0.184911\n",
      "Iter 221, Minibatch Loss ---- Train = 0.184681; Test = 0.182796\n",
      "Iter 222, Minibatch Loss ---- Train = 0.185839; Test = 0.183714\n",
      "Iter 223, Minibatch Loss ---- Train = 0.204381; Test = 0.183466\n",
      "Iter 224, Minibatch Loss ---- Train = 0.199035; Test = 0.182585\n",
      "Iter 225, Minibatch Loss ---- Train = 0.179469; Test = 0.182855\n",
      "Iter 226, Minibatch Loss ---- Train = 0.193070; Test = 0.184253\n",
      "Iter 227, Minibatch Loss ---- Train = 0.179272; Test = 0.182699\n",
      "Iter 228, Minibatch Loss ---- Train = 0.171214; Test = 0.182237\n",
      "Iter 229, Minibatch Loss ---- Train = 0.174402; Test = 0.183227\n",
      "Iter 230, Minibatch Loss ---- Train = 0.162565; Test = 0.183313\n",
      "Iter 231, Minibatch Loss ---- Train = 0.181431; Test = 0.182772\n",
      "Iter 232, Minibatch Loss ---- Train = 0.152032; Test = 0.184513\n",
      "Iter 233, Minibatch Loss ---- Train = 0.179074; Test = 0.186952\n",
      "Iter 234, Minibatch Loss ---- Train = 0.174103; Test = 0.180764\n",
      "Iter 235, Minibatch Loss ---- Train = 0.174595; Test = 0.181418\n",
      "Iter 236, Minibatch Loss ---- Train = 0.173057; Test = 0.185823\n",
      "Iter 237, Minibatch Loss ---- Train = 0.211312; Test = 0.181562\n",
      "Iter 238, Minibatch Loss ---- Train = 0.184099; Test = 0.181059\n",
      "Iter 239, Minibatch Loss ---- Train = 0.170041; Test = 0.182097\n",
      "Iter 240, Minibatch Loss ---- Train = 0.186598; Test = 0.184000\n",
      "Iter 241, Minibatch Loss ---- Train = 0.180983; Test = 0.182134\n",
      "Iter 242, Minibatch Loss ---- Train = 0.180887; Test = 0.182617\n",
      "Iter 243, Minibatch Loss ---- Train = 0.156062; Test = 0.181850\n",
      "Iter 244, Minibatch Loss ---- Train = 0.165005; Test = 0.182606\n",
      "Iter 245, Minibatch Loss ---- Train = 0.161213; Test = 0.182754\n",
      "Iter 246, Minibatch Loss ---- Train = 0.189457; Test = 0.183259\n",
      "Iter 247, Minibatch Loss ---- Train = 0.176143; Test = 0.182512\n",
      "Iter 248, Minibatch Loss ---- Train = 0.185516; Test = 0.181730\n",
      "Iter 249, Minibatch Loss ---- Train = 0.188454; Test = 0.184462\n",
      "Iter 250, Minibatch Loss ---- Train = 0.196379; Test = 0.182201\n",
      "Iter 251, Minibatch Loss ---- Train = 0.188326; Test = 0.182343\n",
      "Iter 252, Minibatch Loss ---- Train = 0.194692; Test = 0.182043\n",
      "Iter 253, Minibatch Loss ---- Train = 0.169924; Test = 0.182398\n",
      "Iter 254, Minibatch Loss ---- Train = 0.175018; Test = 0.183230\n",
      "Iter 255, Minibatch Loss ---- Train = 0.175437; Test = 0.184148\n",
      "Iter 256, Minibatch Loss ---- Train = 0.165080; Test = 0.181608\n",
      "Iter 257, Minibatch Loss ---- Train = 0.175123; Test = 0.182251\n",
      "Iter 258, Minibatch Loss ---- Train = 0.173814; Test = 0.182419\n",
      "Iter 259, Minibatch Loss ---- Train = 0.215168; Test = 0.187162\n",
      "Iter 260, Minibatch Loss ---- Train = 0.190422; Test = 0.180661\n",
      "Iter 261, Minibatch Loss ---- Train = 0.197596; Test = 0.183489\n",
      "Iter 262, Minibatch Loss ---- Train = 0.194294; Test = 0.182546\n",
      "Iter 263, Minibatch Loss ---- Train = 0.169200; Test = 0.181955\n",
      "Iter 264, Minibatch Loss ---- Train = 0.179120; Test = 0.181636\n",
      "Iter 265, Minibatch Loss ---- Train = 0.198507; Test = 0.183518\n",
      "Iter 266, Minibatch Loss ---- Train = 0.180985; Test = 0.181820\n",
      "Iter 267, Minibatch Loss ---- Train = 0.231783; Test = 0.183294\n",
      "Iter 268, Minibatch Loss ---- Train = 0.206552; Test = 0.182487\n",
      "Iter 269, Minibatch Loss ---- Train = 0.170719; Test = 0.182258\n",
      "Iter 270, Minibatch Loss ---- Train = 0.196359; Test = 0.182203\n",
      "Iter 271, Minibatch Loss ---- Train = 0.194858; Test = 0.183138\n",
      "Iter 272, Minibatch Loss ---- Train = 0.214667; Test = 0.180616\n",
      "Iter 273, Minibatch Loss ---- Train = 0.164904; Test = 0.181487\n",
      "Iter 274, Minibatch Loss ---- Train = 0.189433; Test = 0.181114\n",
      "Iter 275, Minibatch Loss ---- Train = 0.151849; Test = 0.180506\n",
      "Iter 276, Minibatch Loss ---- Train = 0.156168; Test = 0.185216\n",
      "Iter 277, Minibatch Loss ---- Train = 0.179651; Test = 0.181606\n",
      "Iter 278, Minibatch Loss ---- Train = 0.178934; Test = 0.180652\n",
      "Iter 279, Minibatch Loss ---- Train = 0.190373; Test = 0.183839\n",
      "Iter 280, Minibatch Loss ---- Train = 0.163532; Test = 0.181638\n",
      "Iter 281, Minibatch Loss ---- Train = 0.190359; Test = 0.183296\n",
      "Iter 282, Minibatch Loss ---- Train = 0.193899; Test = 0.181319\n",
      "Iter 283, Minibatch Loss ---- Train = 0.179455; Test = 0.184128\n",
      "Iter 284, Minibatch Loss ---- Train = 0.198356; Test = 0.181204\n",
      "Iter 285, Minibatch Loss ---- Train = 0.183255; Test = 0.183243\n",
      "Iter 286, Minibatch Loss ---- Train = 0.202439; Test = 0.180931\n",
      "Iter 287, Minibatch Loss ---- Train = 0.193424; Test = 0.183255\n",
      "Iter 288, Minibatch Loss ---- Train = 0.206492; Test = 0.181817\n",
      "Iter 289, Minibatch Loss ---- Train = 0.182287; Test = 0.183432\n",
      "Iter 290, Minibatch Loss ---- Train = 0.185923; Test = 0.181480\n",
      "Iter 291, Minibatch Loss ---- Train = 0.208852; Test = 0.183405\n",
      "Iter 292, Minibatch Loss ---- Train = 0.165270; Test = 0.180869\n",
      "Iter 293, Minibatch Loss ---- Train = 0.185608; Test = 0.182264\n",
      "Iter 294, Minibatch Loss ---- Train = 0.185448; Test = 0.181350\n",
      "Iter 295, Minibatch Loss ---- Train = 0.218678; Test = 0.182209\n",
      "Iter 296, Minibatch Loss ---- Train = 0.168246; Test = 0.185661\n",
      "Iter 297, Minibatch Loss ---- Train = 0.166638; Test = 0.181001\n",
      "Iter 298, Minibatch Loss ---- Train = 0.167077; Test = 0.180906\n",
      "Iter 299, Minibatch Loss ---- Train = 0.183110; Test = 0.181206\n",
      "Iter 300, Minibatch Loss ---- Train = 0.183396; Test = 0.181519\n",
      "Iter 301, Minibatch Loss ---- Train = 0.201450; Test = 0.182924\n",
      "Iter 302, Minibatch Loss ---- Train = 0.191459; Test = 0.180618\n",
      "Iter 303, Minibatch Loss ---- Train = 0.150239; Test = 0.180446\n",
      "Iter 304, Minibatch Loss ---- Train = 0.196743; Test = 0.180027\n",
      "Iter 305, Minibatch Loss ---- Train = 0.215048; Test = 0.179592\n",
      "Iter 306, Minibatch Loss ---- Train = 0.194136; Test = 0.185781\n",
      "Iter 307, Minibatch Loss ---- Train = 0.178408; Test = 0.180745\n",
      "Iter 308, Minibatch Loss ---- Train = 0.189422; Test = 0.181881\n",
      "Iter 309, Minibatch Loss ---- Train = 0.189190; Test = 0.181232\n",
      "Iter 310, Minibatch Loss ---- Train = 0.172230; Test = 0.182771\n",
      "Iter 311, Minibatch Loss ---- Train = 0.193445; Test = 0.181230\n",
      "Iter 312, Minibatch Loss ---- Train = 0.200037; Test = 0.181754\n",
      "Iter 313, Minibatch Loss ---- Train = 0.194198; Test = 0.180664\n",
      "Iter 314, Minibatch Loss ---- Train = 0.174559; Test = 0.182631\n",
      "Iter 315, Minibatch Loss ---- Train = 0.197524; Test = 0.180633\n",
      "Iter 316, Minibatch Loss ---- Train = 0.193827; Test = 0.181219\n",
      "Iter 317, Minibatch Loss ---- Train = 0.206543; Test = 0.181640\n",
      "Iter 318, Minibatch Loss ---- Train = 0.211602; Test = 0.183218\n",
      "Iter 319, Minibatch Loss ---- Train = 0.181812; Test = 0.180461\n",
      "Iter 320, Minibatch Loss ---- Train = 0.150156; Test = 0.180071\n",
      "Iter 321, Minibatch Loss ---- Train = 0.185463; Test = 0.183447\n",
      "Iter 322, Minibatch Loss ---- Train = 0.172134; Test = 0.181765\n",
      "Iter 323, Minibatch Loss ---- Train = 0.186046; Test = 0.180363\n",
      "Iter 324, Minibatch Loss ---- Train = 0.172341; Test = 0.181967\n",
      "Iter 325, Minibatch Loss ---- Train = 0.175006; Test = 0.181836\n",
      "Iter 326, Minibatch Loss ---- Train = 0.197022; Test = 0.181142\n",
      "Iter 327, Minibatch Loss ---- Train = 0.183510; Test = 0.180260\n",
      "Iter 328, Minibatch Loss ---- Train = 0.229543; Test = 0.182629\n",
      "Iter 329, Minibatch Loss ---- Train = 0.195814; Test = 0.181074\n",
      "Iter 330, Minibatch Loss ---- Train = 0.212383; Test = 0.182709\n",
      "Iter 331, Minibatch Loss ---- Train = 0.198425; Test = 0.180217\n",
      "Iter 332, Minibatch Loss ---- Train = 0.204484; Test = 0.183190\n",
      "Iter 333, Minibatch Loss ---- Train = 0.184469; Test = 0.180033\n",
      "Iter 334, Minibatch Loss ---- Train = 0.179563; Test = 0.180370\n",
      "Iter 335, Minibatch Loss ---- Train = 0.177992; Test = 0.180054\n",
      "Iter 336, Minibatch Loss ---- Train = 0.186360; Test = 0.182514\n",
      "Iter 337, Minibatch Loss ---- Train = 0.169595; Test = 0.180599\n",
      "Iter 338, Minibatch Loss ---- Train = 0.172907; Test = 0.180151\n",
      "Iter 339, Minibatch Loss ---- Train = 0.173605; Test = 0.179433\n",
      "Iter 340, Minibatch Loss ---- Train = 0.153670; Test = 0.178787\n",
      "Iter 341, Minibatch Loss ---- Train = 0.194324; Test = 0.181423\n",
      "Iter 342, Minibatch Loss ---- Train = 0.168074; Test = 0.180769\n",
      "Iter 343, Minibatch Loss ---- Train = 0.171007; Test = 0.180481\n",
      "Iter 344, Minibatch Loss ---- Train = 0.163865; Test = 0.181582\n",
      "Iter 345, Minibatch Loss ---- Train = 0.178671; Test = 0.180790\n",
      "Iter 346, Minibatch Loss ---- Train = 0.204960; Test = 0.179238\n",
      "Iter 347, Minibatch Loss ---- Train = 0.205933; Test = 0.182696\n",
      "Iter 348, Minibatch Loss ---- Train = 0.175117; Test = 0.179514\n",
      "Iter 349, Minibatch Loss ---- Train = 0.170121; Test = 0.179540\n",
      "Iter 350, Minibatch Loss ---- Train = 0.176249; Test = 0.179209\n",
      "Iter 351, Minibatch Loss ---- Train = 0.164395; Test = 0.180826\n",
      "Iter 352, Minibatch Loss ---- Train = 0.206440; Test = 0.181264\n",
      "Iter 353, Minibatch Loss ---- Train = 0.189808; Test = 0.180985\n",
      "Iter 354, Minibatch Loss ---- Train = 0.181660; Test = 0.179491\n",
      "Iter 355, Minibatch Loss ---- Train = 0.174768; Test = 0.179677\n",
      "Iter 356, Minibatch Loss ---- Train = 0.170322; Test = 0.181587\n",
      "Iter 357, Minibatch Loss ---- Train = 0.197292; Test = 0.179740\n",
      "Iter 358, Minibatch Loss ---- Train = 0.163783; Test = 0.179866\n",
      "Iter 359, Minibatch Loss ---- Train = 0.176092; Test = 0.180025\n",
      "Iter 360, Minibatch Loss ---- Train = 0.181493; Test = 0.179224\n",
      "Iter 361, Minibatch Loss ---- Train = 0.159347; Test = 0.180122\n",
      "Iter 362, Minibatch Loss ---- Train = 0.191429; Test = 0.179241\n",
      "Iter 363, Minibatch Loss ---- Train = 0.194367; Test = 0.181255\n",
      "Iter 364, Minibatch Loss ---- Train = 0.169200; Test = 0.179078\n",
      "Iter 365, Minibatch Loss ---- Train = 0.180590; Test = 0.179562\n",
      "Iter 366, Minibatch Loss ---- Train = 0.145924; Test = 0.179269\n",
      "Iter 367, Minibatch Loss ---- Train = 0.172861; Test = 0.179091\n",
      "Iter 368, Minibatch Loss ---- Train = 0.164181; Test = 0.179854\n",
      "Iter 369, Minibatch Loss ---- Train = 0.171554; Test = 0.179421\n",
      "Iter 370, Minibatch Loss ---- Train = 0.185823; Test = 0.178548\n",
      "Iter 371, Minibatch Loss ---- Train = 0.191766; Test = 0.180168\n",
      "Iter 372, Minibatch Loss ---- Train = 0.170760; Test = 0.179535\n",
      "Iter 373, Minibatch Loss ---- Train = 0.184097; Test = 0.178681\n",
      "Iter 374, Minibatch Loss ---- Train = 0.167787; Test = 0.178422\n",
      "Iter 375, Minibatch Loss ---- Train = 0.183637; Test = 0.180431\n",
      "Iter 376, Minibatch Loss ---- Train = 0.183722; Test = 0.178309\n",
      "Iter 377, Minibatch Loss ---- Train = 0.161838; Test = 0.177459\n",
      "Iter 378, Minibatch Loss ---- Train = 0.179654; Test = 0.180009\n",
      "Iter 379, Minibatch Loss ---- Train = 0.168158; Test = 0.179181\n",
      "Iter 380, Minibatch Loss ---- Train = 0.166120; Test = 0.178375\n",
      "Iter 381, Minibatch Loss ---- Train = 0.202856; Test = 0.178752\n",
      "Iter 382, Minibatch Loss ---- Train = 0.207898; Test = 0.178288\n",
      "Iter 383, Minibatch Loss ---- Train = 0.178437; Test = 0.180222\n",
      "Iter 384, Minibatch Loss ---- Train = 0.149585; Test = 0.178075\n",
      "Iter 385, Minibatch Loss ---- Train = 0.171686; Test = 0.177931\n",
      "Iter 386, Minibatch Loss ---- Train = 0.173391; Test = 0.177636\n",
      "Iter 387, Minibatch Loss ---- Train = 0.168214; Test = 0.179436\n",
      "Iter 388, Minibatch Loss ---- Train = 0.196180; Test = 0.178469\n",
      "Iter 389, Minibatch Loss ---- Train = 0.170575; Test = 0.177475\n",
      "Iter 390, Minibatch Loss ---- Train = 0.168558; Test = 0.181934\n",
      "Iter 391, Minibatch Loss ---- Train = 0.167531; Test = 0.177694\n",
      "Iter 392, Minibatch Loss ---- Train = 0.189365; Test = 0.176066\n",
      "Iter 393, Minibatch Loss ---- Train = 0.161812; Test = 0.177498\n",
      "Iter 394, Minibatch Loss ---- Train = 0.180674; Test = 0.180072\n",
      "Iter 395, Minibatch Loss ---- Train = 0.195807; Test = 0.178453\n",
      "Iter 396, Minibatch Loss ---- Train = 0.202158; Test = 0.175941\n",
      "Iter 397, Minibatch Loss ---- Train = 0.191121; Test = 0.179667\n",
      "Iter 398, Minibatch Loss ---- Train = 0.175588; Test = 0.177346\n",
      "Iter 399, Minibatch Loss ---- Train = 0.186830; Test = 0.178446\n",
      "Iter 400, Minibatch Loss ---- Train = 0.212447; Test = 0.175615\n",
      "Iter 401, Minibatch Loss ---- Train = 0.186766; Test = 0.178146\n",
      "Iter 402, Minibatch Loss ---- Train = 0.194634; Test = 0.179476\n",
      "Iter 403, Minibatch Loss ---- Train = 0.180754; Test = 0.176664\n",
      "Iter 404, Minibatch Loss ---- Train = 0.170241; Test = 0.176380\n",
      "Iter 405, Minibatch Loss ---- Train = 0.146628; Test = 0.176172\n",
      "Iter 406, Minibatch Loss ---- Train = 0.182656; Test = 0.175409\n",
      "Iter 407, Minibatch Loss ---- Train = 0.189307; Test = 0.181613\n",
      "Iter 408, Minibatch Loss ---- Train = 0.174225; Test = 0.176569\n",
      "Iter 409, Minibatch Loss ---- Train = 0.173661; Test = 0.176149\n",
      "Iter 410, Minibatch Loss ---- Train = 0.199440; Test = 0.175931\n",
      "Iter 411, Minibatch Loss ---- Train = 0.179507; Test = 0.176687\n",
      "Iter 412, Minibatch Loss ---- Train = 0.158200; Test = 0.177829\n",
      "Iter 413, Minibatch Loss ---- Train = 0.193653; Test = 0.177409\n",
      "Iter 414, Minibatch Loss ---- Train = 0.190783; Test = 0.176155\n",
      "Iter 415, Minibatch Loss ---- Train = 0.185840; Test = 0.176391\n",
      "Iter 416, Minibatch Loss ---- Train = 0.188698; Test = 0.181101\n",
      "Iter 417, Minibatch Loss ---- Train = 0.185266; Test = 0.176297\n",
      "Iter 418, Minibatch Loss ---- Train = 0.176070; Test = 0.175431\n",
      "Iter 419, Minibatch Loss ---- Train = 0.183047; Test = 0.178189\n",
      "Iter 420, Minibatch Loss ---- Train = 0.189864; Test = 0.175473\n",
      "Iter 421, Minibatch Loss ---- Train = 0.197512; Test = 0.177428\n",
      "Iter 422, Minibatch Loss ---- Train = 0.168815; Test = 0.174791\n",
      "Iter 423, Minibatch Loss ---- Train = 0.162059; Test = 0.176675\n",
      "Iter 424, Minibatch Loss ---- Train = 0.168179; Test = 0.176682\n",
      "Iter 425, Minibatch Loss ---- Train = 0.213426; Test = 0.177719\n",
      "Iter 426, Minibatch Loss ---- Train = 0.181328; Test = 0.174523\n",
      "Iter 427, Minibatch Loss ---- Train = 0.188021; Test = 0.175638\n",
      "Iter 428, Minibatch Loss ---- Train = 0.198217; Test = 0.175153\n",
      "Iter 429, Minibatch Loss ---- Train = 0.155680; Test = 0.177058\n",
      "Iter 430, Minibatch Loss ---- Train = 0.202102; Test = 0.177786\n",
      "Iter 431, Minibatch Loss ---- Train = 0.180697; Test = 0.177305\n",
      "Iter 432, Minibatch Loss ---- Train = 0.176668; Test = 0.174435\n",
      "Iter 433, Minibatch Loss ---- Train = 0.142992; Test = 0.174618\n",
      "Iter 434, Minibatch Loss ---- Train = 0.151205; Test = 0.174687\n",
      "Iter 435, Minibatch Loss ---- Train = 0.173144; Test = 0.179191\n",
      "Iter 436, Minibatch Loss ---- Train = 0.177082; Test = 0.175767\n",
      "Iter 437, Minibatch Loss ---- Train = 0.155104; Test = 0.175869\n",
      "Iter 438, Minibatch Loss ---- Train = 0.173840; Test = 0.175733\n",
      "Iter 439, Minibatch Loss ---- Train = 0.171511; Test = 0.177081\n",
      "Iter 440, Minibatch Loss ---- Train = 0.186367; Test = 0.176066\n",
      "Iter 441, Minibatch Loss ---- Train = 0.182034; Test = 0.174574\n",
      "Iter 442, Minibatch Loss ---- Train = 0.185623; Test = 0.176339\n",
      "Iter 443, Minibatch Loss ---- Train = 0.194343; Test = 0.174732\n",
      "Iter 444, Minibatch Loss ---- Train = 0.189843; Test = 0.177500\n",
      "Iter 445, Minibatch Loss ---- Train = 0.177674; Test = 0.175092\n",
      "Iter 446, Minibatch Loss ---- Train = 0.186424; Test = 0.176498\n",
      "Iter 447, Minibatch Loss ---- Train = 0.171246; Test = 0.175147\n",
      "Iter 448, Minibatch Loss ---- Train = 0.171347; Test = 0.174932\n",
      "Iter 449, Minibatch Loss ---- Train = 0.191396; Test = 0.175221\n",
      "Iter 450, Minibatch Loss ---- Train = 0.191621; Test = 0.177317\n",
      "Iter 451, Minibatch Loss ---- Train = 0.175856; Test = 0.174516\n",
      "Iter 452, Minibatch Loss ---- Train = 0.185967; Test = 0.176164\n",
      "Iter 453, Minibatch Loss ---- Train = 0.177847; Test = 0.174618\n",
      "Iter 454, Minibatch Loss ---- Train = 0.167797; Test = 0.179528\n",
      "Iter 455, Minibatch Loss ---- Train = 0.162061; Test = 0.174486\n",
      "Iter 456, Minibatch Loss ---- Train = 0.198356; Test = 0.176595\n",
      "Iter 457, Minibatch Loss ---- Train = 0.162697; Test = 0.174490\n",
      "Iter 458, Minibatch Loss ---- Train = 0.177701; Test = 0.176063\n",
      "Iter 459, Minibatch Loss ---- Train = 0.183928; Test = 0.174191\n",
      "Iter 460, Minibatch Loss ---- Train = 0.190173; Test = 0.178123\n",
      "Iter 461, Minibatch Loss ---- Train = 0.190562; Test = 0.174970\n",
      "Iter 462, Minibatch Loss ---- Train = 0.200616; Test = 0.175695\n",
      "Iter 463, Minibatch Loss ---- Train = 0.174119; Test = 0.175539\n",
      "Iter 464, Minibatch Loss ---- Train = 0.157689; Test = 0.174440\n",
      "Iter 465, Minibatch Loss ---- Train = 0.165712; Test = 0.175415\n",
      "Iter 466, Minibatch Loss ---- Train = 0.175542; Test = 0.177139\n",
      "Iter 467, Minibatch Loss ---- Train = 0.157200; Test = 0.174445\n",
      "Iter 468, Minibatch Loss ---- Train = 0.163697; Test = 0.176772\n",
      "Iter 469, Minibatch Loss ---- Train = 0.193755; Test = 0.173428\n",
      "Iter 470, Minibatch Loss ---- Train = 0.186803; Test = 0.176273\n",
      "Iter 471, Minibatch Loss ---- Train = 0.188684; Test = 0.180421\n",
      "Iter 472, Minibatch Loss ---- Train = 0.189213; Test = 0.175813\n",
      "Iter 473, Minibatch Loss ---- Train = 0.193802; Test = 0.174019\n",
      "Iter 474, Minibatch Loss ---- Train = 0.172604; Test = 0.175152\n",
      "Iter 475, Minibatch Loss ---- Train = 0.198876; Test = 0.175089\n",
      "Iter 476, Minibatch Loss ---- Train = 0.173620; Test = 0.176197\n",
      "Iter 477, Minibatch Loss ---- Train = 0.155426; Test = 0.175497\n",
      "Iter 478, Minibatch Loss ---- Train = 0.177656; Test = 0.175057\n",
      "Iter 479, Minibatch Loss ---- Train = 0.170511; Test = 0.174467\n",
      "Iter 480, Minibatch Loss ---- Train = 0.185065; Test = 0.175589\n",
      "Iter 481, Minibatch Loss ---- Train = 0.155069; Test = 0.174904\n",
      "Iter 482, Minibatch Loss ---- Train = 0.186644; Test = 0.175427\n",
      "Iter 483, Minibatch Loss ---- Train = 0.186644; Test = 0.173929\n",
      "Iter 484, Minibatch Loss ---- Train = 0.152421; Test = 0.173447\n",
      "Iter 485, Minibatch Loss ---- Train = 0.172104; Test = 0.176385\n",
      "Iter 486, Minibatch Loss ---- Train = 0.186731; Test = 0.175736\n",
      "Iter 487, Minibatch Loss ---- Train = 0.167268; Test = 0.175192\n",
      "Iter 488, Minibatch Loss ---- Train = 0.183134; Test = 0.175911\n",
      "Iter 489, Minibatch Loss ---- Train = 0.184189; Test = 0.175556\n",
      "Iter 490, Minibatch Loss ---- Train = 0.188077; Test = 0.176913\n",
      "Iter 491, Minibatch Loss ---- Train = 0.197365; Test = 0.173454\n",
      "Iter 492, Minibatch Loss ---- Train = 0.151962; Test = 0.173816\n",
      "Iter 493, Minibatch Loss ---- Train = 0.192520; Test = 0.174208\n",
      "Iter 494, Minibatch Loss ---- Train = 0.210716; Test = 0.177474\n",
      "Iter 495, Minibatch Loss ---- Train = 0.187150; Test = 0.173500\n",
      "Iter 496, Minibatch Loss ---- Train = 0.164447; Test = 0.175721\n",
      "Iter 497, Minibatch Loss ---- Train = 0.182585; Test = 0.174340\n",
      "Iter 498, Minibatch Loss ---- Train = 0.172091; Test = 0.176299\n",
      "Iter 499, Minibatch Loss ---- Train = 0.198965; Test = 0.175063\n",
      "Iter 500, Minibatch Loss ---- Train = 0.131745; Test = 0.173438\n",
      "Iter 501, Minibatch Loss ---- Train = 0.186818; Test = 0.176979\n",
      "Iter 502, Minibatch Loss ---- Train = 0.168988; Test = 0.175768\n",
      "Iter 503, Minibatch Loss ---- Train = 0.167043; Test = 0.173717\n",
      "Iter 504, Minibatch Loss ---- Train = 0.169403; Test = 0.175017\n",
      "Iter 505, Minibatch Loss ---- Train = 0.206854; Test = 0.174838\n",
      "Iter 506, Minibatch Loss ---- Train = 0.181836; Test = 0.173433\n",
      "Iter 507, Minibatch Loss ---- Train = 0.156081; Test = 0.173905\n",
      "Iter 508, Minibatch Loss ---- Train = 0.151710; Test = 0.175272\n",
      "Iter 509, Minibatch Loss ---- Train = 0.184716; Test = 0.176042\n",
      "Iter 510, Minibatch Loss ---- Train = 0.164613; Test = 0.173418\n",
      "Iter 511, Minibatch Loss ---- Train = 0.186817; Test = 0.175650\n",
      "Iter 512, Minibatch Loss ---- Train = 0.190892; Test = 0.174560\n",
      "Iter 513, Minibatch Loss ---- Train = 0.166153; Test = 0.174254\n",
      "Iter 514, Minibatch Loss ---- Train = 0.155067; Test = 0.174601\n",
      "Iter 515, Minibatch Loss ---- Train = 0.179174; Test = 0.173870\n",
      "Iter 516, Minibatch Loss ---- Train = 0.139081; Test = 0.174322\n",
      "Iter 517, Minibatch Loss ---- Train = 0.171349; Test = 0.175537\n",
      "Iter 518, Minibatch Loss ---- Train = 0.180597; Test = 0.174755\n",
      "Iter 519, Minibatch Loss ---- Train = 0.199860; Test = 0.175935\n",
      "Iter 520, Minibatch Loss ---- Train = 0.200271; Test = 0.173431\n",
      "Iter 521, Minibatch Loss ---- Train = 0.173540; Test = 0.174287\n",
      "Iter 522, Minibatch Loss ---- Train = 0.164952; Test = 0.175132\n",
      "Iter 523, Minibatch Loss ---- Train = 0.171983; Test = 0.175881\n",
      "Iter 524, Minibatch Loss ---- Train = 0.170119; Test = 0.173983\n",
      "Iter 525, Minibatch Loss ---- Train = 0.183492; Test = 0.175460\n",
      "Iter 526, Minibatch Loss ---- Train = 0.181453; Test = 0.173869\n",
      "Iter 527, Minibatch Loss ---- Train = 0.176278; Test = 0.176356\n",
      "Iter 528, Minibatch Loss ---- Train = 0.156086; Test = 0.173798\n",
      "Iter 529, Minibatch Loss ---- Train = 0.169938; Test = 0.174302\n",
      "Iter 530, Minibatch Loss ---- Train = 0.172619; Test = 0.174367\n",
      "Iter 531, Minibatch Loss ---- Train = 0.178873; Test = 0.176601\n",
      "Iter 532, Minibatch Loss ---- Train = 0.162860; Test = 0.173524\n",
      "Iter 533, Minibatch Loss ---- Train = 0.191439; Test = 0.175997\n",
      "Iter 534, Minibatch Loss ---- Train = 0.175026; Test = 0.172817\n",
      "Iter 535, Minibatch Loss ---- Train = 0.194133; Test = 0.176499\n",
      "Iter 536, Minibatch Loss ---- Train = 0.223624; Test = 0.173025\n",
      "Iter 537, Minibatch Loss ---- Train = 0.159044; Test = 0.173927\n",
      "Iter 538, Minibatch Loss ---- Train = 0.204517; Test = 0.174027\n",
      "Iter 539, Minibatch Loss ---- Train = 0.175615; Test = 0.175551\n",
      "Iter 540, Minibatch Loss ---- Train = 0.153995; Test = 0.174137\n",
      "Iter 541, Minibatch Loss ---- Train = 0.152824; Test = 0.173495\n",
      "Iter 542, Minibatch Loss ---- Train = 0.178550; Test = 0.174209\n",
      "Iter 543, Minibatch Loss ---- Train = 0.160135; Test = 0.175450\n",
      "Iter 544, Minibatch Loss ---- Train = 0.169566; Test = 0.173922\n",
      "Iter 545, Minibatch Loss ---- Train = 0.149858; Test = 0.173775\n",
      "Iter 546, Minibatch Loss ---- Train = 0.135682; Test = 0.175465\n",
      "Iter 547, Minibatch Loss ---- Train = 0.190688; Test = 0.173780\n",
      "Iter 548, Minibatch Loss ---- Train = 0.171222; Test = 0.173237\n",
      "Iter 549, Minibatch Loss ---- Train = 0.169733; Test = 0.173021\n",
      "Iter 550, Minibatch Loss ---- Train = 0.167180; Test = 0.179839\n",
      "Iter 551, Minibatch Loss ---- Train = 0.167353; Test = 0.173466\n",
      "Iter 552, Minibatch Loss ---- Train = 0.171746; Test = 0.174264\n",
      "Iter 553, Minibatch Loss ---- Train = 0.155857; Test = 0.174133\n",
      "Iter 554, Minibatch Loss ---- Train = 0.173434; Test = 0.173878\n",
      "Iter 555, Minibatch Loss ---- Train = 0.205781; Test = 0.174515\n",
      "Iter 556, Minibatch Loss ---- Train = 0.219243; Test = 0.173006\n",
      "Iter 557, Minibatch Loss ---- Train = 0.190731; Test = 0.174297\n",
      "Iter 558, Minibatch Loss ---- Train = 0.193010; Test = 0.175202\n",
      "Iter 559, Minibatch Loss ---- Train = 0.169004; Test = 0.174116\n",
      "Iter 560, Minibatch Loss ---- Train = 0.181607; Test = 0.174474\n",
      "Iter 561, Minibatch Loss ---- Train = 0.167308; Test = 0.174231\n",
      "Iter 562, Minibatch Loss ---- Train = 0.195067; Test = 0.173333\n",
      "Iter 563, Minibatch Loss ---- Train = 0.161000; Test = 0.173252\n",
      "Iter 564, Minibatch Loss ---- Train = 0.181278; Test = 0.175160\n",
      "Iter 565, Minibatch Loss ---- Train = 0.175439; Test = 0.176590\n",
      "Iter 566, Minibatch Loss ---- Train = 0.163203; Test = 0.172768\n",
      "Iter 567, Minibatch Loss ---- Train = 0.168354; Test = 0.173306\n",
      "Iter 568, Minibatch Loss ---- Train = 0.169731; Test = 0.175539\n",
      "Iter 569, Minibatch Loss ---- Train = 0.168813; Test = 0.174775\n",
      "Iter 570, Minibatch Loss ---- Train = 0.198679; Test = 0.173288\n",
      "Iter 571, Minibatch Loss ---- Train = 0.167705; Test = 0.175726\n",
      "Iter 572, Minibatch Loss ---- Train = 0.196709; Test = 0.175425\n",
      "Iter 573, Minibatch Loss ---- Train = 0.181034; Test = 0.176718\n",
      "Iter 574, Minibatch Loss ---- Train = 0.170522; Test = 0.172941\n",
      "Iter 575, Minibatch Loss ---- Train = 0.146121; Test = 0.173757\n",
      "Iter 576, Minibatch Loss ---- Train = 0.191594; Test = 0.173179\n",
      "Iter 577, Minibatch Loss ---- Train = 0.163576; Test = 0.176932\n",
      "Iter 578, Minibatch Loss ---- Train = 0.167532; Test = 0.173613\n",
      "Iter 579, Minibatch Loss ---- Train = 0.148179; Test = 0.173373\n",
      "Iter 580, Minibatch Loss ---- Train = 0.153469; Test = 0.175715\n",
      "Iter 581, Minibatch Loss ---- Train = 0.180353; Test = 0.173968\n",
      "Iter 582, Minibatch Loss ---- Train = 0.162296; Test = 0.173178\n",
      "Iter 583, Minibatch Loss ---- Train = 0.185492; Test = 0.174753\n",
      "Iter 584, Minibatch Loss ---- Train = 0.174830; Test = 0.172796\n",
      "Iter 585, Minibatch Loss ---- Train = 0.199265; Test = 0.174312\n",
      "Iter 586, Minibatch Loss ---- Train = 0.147716; Test = 0.174682\n",
      "Iter 587, Minibatch Loss ---- Train = 0.170085; Test = 0.174159\n",
      "Iter 588, Minibatch Loss ---- Train = 0.167125; Test = 0.173600\n",
      "Iter 589, Minibatch Loss ---- Train = 0.186212; Test = 0.175566\n",
      "Iter 590, Minibatch Loss ---- Train = 0.195521; Test = 0.174952\n",
      "Iter 591, Minibatch Loss ---- Train = 0.196847; Test = 0.174821\n",
      "Iter 592, Minibatch Loss ---- Train = 0.181749; Test = 0.174004\n",
      "Iter 593, Minibatch Loss ---- Train = 0.182799; Test = 0.174108\n",
      "Iter 594, Minibatch Loss ---- Train = 0.191865; Test = 0.173276\n",
      "Iter 595, Minibatch Loss ---- Train = 0.180530; Test = 0.173114\n",
      "Iter 596, Minibatch Loss ---- Train = 0.168833; Test = 0.175088\n",
      "Iter 597, Minibatch Loss ---- Train = 0.190100; Test = 0.178641\n",
      "Iter 598, Minibatch Loss ---- Train = 0.182190; Test = 0.172934\n",
      "Iter 599, Minibatch Loss ---- Train = 0.185289; Test = 0.173199\n",
      "Iter 600, Minibatch Loss ---- Train = 0.174028; Test = 0.174246\n",
      "Iter 601, Minibatch Loss ---- Train = 0.198574; Test = 0.175978\n",
      "Iter 602, Minibatch Loss ---- Train = 0.162713; Test = 0.174420\n",
      "Iter 603, Minibatch Loss ---- Train = 0.160332; Test = 0.173859\n",
      "Iter 604, Minibatch Loss ---- Train = 0.160630; Test = 0.173540\n",
      "Iter 605, Minibatch Loss ---- Train = 0.187062; Test = 0.174535\n",
      "Iter 606, Minibatch Loss ---- Train = 0.184282; Test = 0.173385\n",
      "Iter 607, Minibatch Loss ---- Train = 0.196782; Test = 0.175864\n",
      "Iter 608, Minibatch Loss ---- Train = 0.153447; Test = 0.173656\n",
      "Iter 609, Minibatch Loss ---- Train = 0.162488; Test = 0.173306\n",
      "Iter 610, Minibatch Loss ---- Train = 0.176875; Test = 0.173007\n",
      "Iter 611, Minibatch Loss ---- Train = 0.194991; Test = 0.175052\n",
      "Iter 612, Minibatch Loss ---- Train = 0.169476; Test = 0.176415\n",
      "Iter 613, Minibatch Loss ---- Train = 0.160263; Test = 0.173764\n",
      "Iter 614, Minibatch Loss ---- Train = 0.180093; Test = 0.172565\n",
      "Iter 615, Minibatch Loss ---- Train = 0.180829; Test = 0.173833\n",
      "Iter 616, Minibatch Loss ---- Train = 0.204377; Test = 0.173667\n",
      "Iter 617, Minibatch Loss ---- Train = 0.198785; Test = 0.177917\n",
      "Iter 618, Minibatch Loss ---- Train = 0.174039; Test = 0.173121\n",
      "Iter 619, Minibatch Loss ---- Train = 0.202338; Test = 0.175900\n",
      "Iter 620, Minibatch Loss ---- Train = 0.155822; Test = 0.172991\n",
      "Iter 621, Minibatch Loss ---- Train = 0.212711; Test = 0.175455\n",
      "Iter 622, Minibatch Loss ---- Train = 0.179694; Test = 0.173164\n",
      "Iter 623, Minibatch Loss ---- Train = 0.160633; Test = 0.172368\n",
      "Iter 624, Minibatch Loss ---- Train = 0.185653; Test = 0.173231\n",
      "Iter 625, Minibatch Loss ---- Train = 0.170005; Test = 0.175540\n",
      "Iter 626, Minibatch Loss ---- Train = 0.169298; Test = 0.173150\n",
      "Iter 627, Minibatch Loss ---- Train = 0.149796; Test = 0.173399\n",
      "Iter 628, Minibatch Loss ---- Train = 0.163956; Test = 0.173524\n",
      "Iter 629, Minibatch Loss ---- Train = 0.182788; Test = 0.174868\n",
      "Iter 630, Minibatch Loss ---- Train = 0.186265; Test = 0.173679\n",
      "Iter 631, Minibatch Loss ---- Train = 0.174345; Test = 0.174125\n",
      "Iter 632, Minibatch Loss ---- Train = 0.167643; Test = 0.173639\n",
      "Iter 633, Minibatch Loss ---- Train = 0.158662; Test = 0.174153\n",
      "Iter 634, Minibatch Loss ---- Train = 0.172577; Test = 0.174004\n",
      "Iter 635, Minibatch Loss ---- Train = 0.164021; Test = 0.173480\n",
      "Iter 636, Minibatch Loss ---- Train = 0.189938; Test = 0.172510\n",
      "Iter 637, Minibatch Loss ---- Train = 0.167845; Test = 0.176094\n",
      "Iter 638, Minibatch Loss ---- Train = 0.161855; Test = 0.175348\n",
      "Iter 639, Minibatch Loss ---- Train = 0.174079; Test = 0.173186\n",
      "Iter 640, Minibatch Loss ---- Train = 0.192862; Test = 0.172575\n",
      "Iter 641, Minibatch Loss ---- Train = 0.150542; Test = 0.175523\n",
      "Iter 642, Minibatch Loss ---- Train = 0.155926; Test = 0.172969\n",
      "Iter 643, Minibatch Loss ---- Train = 0.138410; Test = 0.172635\n",
      "Iter 644, Minibatch Loss ---- Train = 0.167214; Test = 0.174457\n",
      "Iter 645, Minibatch Loss ---- Train = 0.175250; Test = 0.173442\n",
      "Iter 646, Minibatch Loss ---- Train = 0.159967; Test = 0.173608\n",
      "Iter 647, Minibatch Loss ---- Train = 0.173210; Test = 0.174641\n",
      "Iter 648, Minibatch Loss ---- Train = 0.179976; Test = 0.173091\n",
      "Iter 649, Minibatch Loss ---- Train = 0.159717; Test = 0.172793\n",
      "Iter 650, Minibatch Loss ---- Train = 0.168888; Test = 0.172316\n",
      "Iter 651, Minibatch Loss ---- Train = 0.184847; Test = 0.178219\n",
      "Iter 652, Minibatch Loss ---- Train = 0.188145; Test = 0.172894\n",
      "Iter 653, Minibatch Loss ---- Train = 0.163471; Test = 0.173889\n",
      "Iter 654, Minibatch Loss ---- Train = 0.155200; Test = 0.173576\n",
      "Iter 655, Minibatch Loss ---- Train = 0.172769; Test = 0.173035\n",
      "Iter 656, Minibatch Loss ---- Train = 0.163268; Test = 0.173174\n",
      "Iter 657, Minibatch Loss ---- Train = 0.148659; Test = 0.174536\n",
      "Iter 658, Minibatch Loss ---- Train = 0.203505; Test = 0.172872\n",
      "Iter 659, Minibatch Loss ---- Train = 0.159672; Test = 0.174037\n",
      "Iter 660, Minibatch Loss ---- Train = 0.202953; Test = 0.173842\n",
      "Iter 661, Minibatch Loss ---- Train = 0.180301; Test = 0.173269\n",
      "Iter 662, Minibatch Loss ---- Train = 0.168984; Test = 0.173435\n",
      "Iter 663, Minibatch Loss ---- Train = 0.184372; Test = 0.174587\n",
      "Iter 664, Minibatch Loss ---- Train = 0.170934; Test = 0.172744\n",
      "Iter 665, Minibatch Loss ---- Train = 0.175796; Test = 0.175245\n",
      "Iter 666, Minibatch Loss ---- Train = 0.180082; Test = 0.173793\n",
      "Iter 667, Minibatch Loss ---- Train = 0.175898; Test = 0.174507\n",
      "Iter 668, Minibatch Loss ---- Train = 0.195466; Test = 0.172696\n",
      "Iter 669, Minibatch Loss ---- Train = 0.155623; Test = 0.174519\n",
      "Iter 670, Minibatch Loss ---- Train = 0.205160; Test = 0.172904\n",
      "Iter 671, Minibatch Loss ---- Train = 0.174260; Test = 0.175007\n",
      "Iter 672, Minibatch Loss ---- Train = 0.157854; Test = 0.173404\n",
      "Iter 673, Minibatch Loss ---- Train = 0.201174; Test = 0.174447\n",
      "Iter 674, Minibatch Loss ---- Train = 0.170521; Test = 0.172897\n",
      "Iter 675, Minibatch Loss ---- Train = 0.176775; Test = 0.174984\n",
      "Iter 676, Minibatch Loss ---- Train = 0.185037; Test = 0.173594\n",
      "Iter 677, Minibatch Loss ---- Train = 0.190028; Test = 0.176460\n",
      "Iter 678, Minibatch Loss ---- Train = 0.181078; Test = 0.173102\n",
      "Iter 679, Minibatch Loss ---- Train = 0.179765; Test = 0.173282\n",
      "Iter 680, Minibatch Loss ---- Train = 0.153282; Test = 0.174719\n",
      "Iter 681, Minibatch Loss ---- Train = 0.177008; Test = 0.173934\n",
      "Iter 682, Minibatch Loss ---- Train = 0.189925; Test = 0.172947\n",
      "Iter 683, Minibatch Loss ---- Train = 0.190377; Test = 0.174503\n",
      "Iter 684, Minibatch Loss ---- Train = 0.182368; Test = 0.173386\n",
      "Iter 685, Minibatch Loss ---- Train = 0.175556; Test = 0.174409\n",
      "Iter 686, Minibatch Loss ---- Train = 0.165039; Test = 0.172492\n",
      "Iter 687, Minibatch Loss ---- Train = 0.162173; Test = 0.173294\n",
      "Iter 688, Minibatch Loss ---- Train = 0.173207; Test = 0.174208\n",
      "Iter 689, Minibatch Loss ---- Train = 0.161539; Test = 0.171995\n",
      "Iter 690, Minibatch Loss ---- Train = 0.132140; Test = 0.172584\n",
      "Iter 691, Minibatch Loss ---- Train = 0.199143; Test = 0.176609\n",
      "Iter 692, Minibatch Loss ---- Train = 0.172230; Test = 0.173221\n",
      "Iter 693, Minibatch Loss ---- Train = 0.171245; Test = 0.175276\n",
      "Iter 694, Minibatch Loss ---- Train = 0.177125; Test = 0.172656\n",
      "Iter 695, Minibatch Loss ---- Train = 0.200127; Test = 0.176119\n",
      "Iter 696, Minibatch Loss ---- Train = 0.182741; Test = 0.172162\n",
      "Iter 697, Minibatch Loss ---- Train = 0.180065; Test = 0.174060\n",
      "Iter 698, Minibatch Loss ---- Train = 0.175531; Test = 0.173508\n",
      "Iter 699, Minibatch Loss ---- Train = 0.161018; Test = 0.173270\n",
      "Iter 700, Minibatch Loss ---- Train = 0.193104; Test = 0.172520\n",
      "Iter 701, Minibatch Loss ---- Train = 0.175038; Test = 0.173239\n",
      "Iter 702, Minibatch Loss ---- Train = 0.186088; Test = 0.175136\n",
      "Iter 703, Minibatch Loss ---- Train = 0.172650; Test = 0.174430\n",
      "Iter 704, Minibatch Loss ---- Train = 0.168306; Test = 0.172484\n",
      "Iter 705, Minibatch Loss ---- Train = 0.157913; Test = 0.173394\n",
      "Iter 706, Minibatch Loss ---- Train = 0.172403; Test = 0.173974\n",
      "Iter 707, Minibatch Loss ---- Train = 0.170039; Test = 0.174920\n",
      "Iter 708, Minibatch Loss ---- Train = 0.155313; Test = 0.172563\n",
      "Iter 709, Minibatch Loss ---- Train = 0.164658; Test = 0.173337\n",
      "Iter 710, Minibatch Loss ---- Train = 0.167356; Test = 0.174664\n",
      "Iter 711, Minibatch Loss ---- Train = 0.158857; Test = 0.173945\n",
      "Iter 712, Minibatch Loss ---- Train = 0.196137; Test = 0.173604\n",
      "Iter 713, Minibatch Loss ---- Train = 0.162888; Test = 0.173593\n",
      "Iter 714, Minibatch Loss ---- Train = 0.170677; Test = 0.174107\n",
      "Iter 715, Minibatch Loss ---- Train = 0.178024; Test = 0.175506\n",
      "Iter 716, Minibatch Loss ---- Train = 0.182153; Test = 0.172869\n",
      "Iter 717, Minibatch Loss ---- Train = 0.168918; Test = 0.173145\n",
      "Iter 718, Minibatch Loss ---- Train = 0.165153; Test = 0.172300\n",
      "Iter 719, Minibatch Loss ---- Train = 0.182283; Test = 0.173845\n",
      "Iter 720, Minibatch Loss ---- Train = 0.194881; Test = 0.173286\n",
      "Iter 721, Minibatch Loss ---- Train = 0.182672; Test = 0.175424\n",
      "Iter 722, Minibatch Loss ---- Train = 0.148765; Test = 0.173531\n",
      "Iter 723, Minibatch Loss ---- Train = 0.161420; Test = 0.173447\n",
      "Iter 724, Minibatch Loss ---- Train = 0.182064; Test = 0.172757\n",
      "Iter 725, Minibatch Loss ---- Train = 0.199899; Test = 0.174325\n",
      "Iter 726, Minibatch Loss ---- Train = 0.195491; Test = 0.174859\n",
      "Iter 727, Minibatch Loss ---- Train = 0.202434; Test = 0.175884\n",
      "Iter 728, Minibatch Loss ---- Train = 0.165344; Test = 0.172640\n",
      "Iter 729, Minibatch Loss ---- Train = 0.166503; Test = 0.172403\n",
      "Iter 730, Minibatch Loss ---- Train = 0.167599; Test = 0.172714\n",
      "Iter 731, Minibatch Loss ---- Train = 0.193916; Test = 0.177123\n",
      "Iter 732, Minibatch Loss ---- Train = 0.161344; Test = 0.173216\n",
      "Iter 733, Minibatch Loss ---- Train = 0.199844; Test = 0.174911\n",
      "Iter 734, Minibatch Loss ---- Train = 0.159319; Test = 0.172916\n",
      "Iter 735, Minibatch Loss ---- Train = 0.190795; Test = 0.176696\n",
      "Iter 736, Minibatch Loss ---- Train = 0.189577; Test = 0.172820\n",
      "Iter 737, Minibatch Loss ---- Train = 0.167048; Test = 0.174459\n",
      "Iter 738, Minibatch Loss ---- Train = 0.155592; Test = 0.173400\n",
      "Iter 739, Minibatch Loss ---- Train = 0.174992; Test = 0.175625\n",
      "Iter 740, Minibatch Loss ---- Train = 0.164713; Test = 0.172659\n",
      "Iter 741, Minibatch Loss ---- Train = 0.184631; Test = 0.175668\n",
      "Iter 742, Minibatch Loss ---- Train = 0.174260; Test = 0.173143\n",
      "Iter 743, Minibatch Loss ---- Train = 0.165274; Test = 0.172551\n",
      "Iter 744, Minibatch Loss ---- Train = 0.193265; Test = 0.172584\n",
      "Iter 745, Minibatch Loss ---- Train = 0.173793; Test = 0.175092\n",
      "Iter 746, Minibatch Loss ---- Train = 0.198317; Test = 0.172748\n",
      "Iter 747, Minibatch Loss ---- Train = 0.178009; Test = 0.172942\n",
      "Iter 748, Minibatch Loss ---- Train = 0.153273; Test = 0.173367\n",
      "Iter 749, Minibatch Loss ---- Train = 0.160498; Test = 0.173635\n",
      "Iter 750, Minibatch Loss ---- Train = 0.174176; Test = 0.172712\n",
      "Iter 751, Minibatch Loss ---- Train = 0.174461; Test = 0.174261\n",
      "Iter 752, Minibatch Loss ---- Train = 0.163476; Test = 0.172903\n",
      "Iter 753, Minibatch Loss ---- Train = 0.165826; Test = 0.173874\n",
      "Iter 754, Minibatch Loss ---- Train = 0.166906; Test = 0.173161\n",
      "Iter 755, Minibatch Loss ---- Train = 0.169197; Test = 0.173501\n",
      "Iter 756, Minibatch Loss ---- Train = 0.178370; Test = 0.172466\n",
      "Iter 757, Minibatch Loss ---- Train = 0.171680; Test = 0.174769\n",
      "Iter 758, Minibatch Loss ---- Train = 0.196547; Test = 0.173135\n",
      "Iter 759, Minibatch Loss ---- Train = 0.192012; Test = 0.174445\n",
      "Iter 760, Minibatch Loss ---- Train = 0.174028; Test = 0.172700\n",
      "Iter 761, Minibatch Loss ---- Train = 0.186289; Test = 0.173715\n",
      "Iter 762, Minibatch Loss ---- Train = 0.156692; Test = 0.172998\n",
      "Iter 763, Minibatch Loss ---- Train = 0.174775; Test = 0.173564\n",
      "Iter 764, Minibatch Loss ---- Train = 0.152763; Test = 0.175176\n",
      "Iter 765, Minibatch Loss ---- Train = 0.156084; Test = 0.173899\n",
      "Iter 766, Minibatch Loss ---- Train = 0.195188; Test = 0.173175\n",
      "Iter 767, Minibatch Loss ---- Train = 0.162344; Test = 0.172491\n",
      "Iter 768, Minibatch Loss ---- Train = 0.194003; Test = 0.174761\n",
      "Iter 769, Minibatch Loss ---- Train = 0.190706; Test = 0.176176\n",
      "Iter 770, Minibatch Loss ---- Train = 0.176774; Test = 0.174710\n",
      "Iter 771, Minibatch Loss ---- Train = 0.156156; Test = 0.172754\n",
      "Iter 772, Minibatch Loss ---- Train = 0.179230; Test = 0.173671\n",
      "Iter 773, Minibatch Loss ---- Train = 0.171320; Test = 0.174196\n",
      "Iter 774, Minibatch Loss ---- Train = 0.181906; Test = 0.177335\n",
      "Iter 775, Minibatch Loss ---- Train = 0.159533; Test = 0.172745\n",
      "Iter 776, Minibatch Loss ---- Train = 0.168562; Test = 0.174188\n",
      "Iter 777, Minibatch Loss ---- Train = 0.160068; Test = 0.173306\n",
      "Iter 778, Minibatch Loss ---- Train = 0.196573; Test = 0.175662\n",
      "Iter 779, Minibatch Loss ---- Train = 0.202298; Test = 0.173286\n",
      "Iter 780, Minibatch Loss ---- Train = 0.175880; Test = 0.174390\n",
      "Iter 781, Minibatch Loss ---- Train = 0.168535; Test = 0.173146\n",
      "Iter 782, Minibatch Loss ---- Train = 0.183829; Test = 0.174759\n",
      "Iter 783, Minibatch Loss ---- Train = 0.152939; Test = 0.174011\n",
      "Iter 784, Minibatch Loss ---- Train = 0.198397; Test = 0.174660\n",
      "Iter 785, Minibatch Loss ---- Train = 0.178234; Test = 0.172532\n",
      "Iter 786, Minibatch Loss ---- Train = 0.185242; Test = 0.174655\n",
      "Iter 787, Minibatch Loss ---- Train = 0.180229; Test = 0.173272\n",
      "Iter 788, Minibatch Loss ---- Train = 0.185176; Test = 0.172972\n",
      "Iter 789, Minibatch Loss ---- Train = 0.185565; Test = 0.173304\n",
      "Iter 790, Minibatch Loss ---- Train = 0.179572; Test = 0.174891\n",
      "Iter 791, Minibatch Loss ---- Train = 0.195091; Test = 0.172299\n",
      "Iter 792, Minibatch Loss ---- Train = 0.186733; Test = 0.175364\n",
      "Iter 793, Minibatch Loss ---- Train = 0.146836; Test = 0.173054\n",
      "Iter 794, Minibatch Loss ---- Train = 0.160572; Test = 0.173468\n",
      "Iter 795, Minibatch Loss ---- Train = 0.161213; Test = 0.173080\n",
      "Iter 796, Minibatch Loss ---- Train = 0.169806; Test = 0.173608\n",
      "Iter 797, Minibatch Loss ---- Train = 0.171502; Test = 0.173115\n",
      "Iter 798, Minibatch Loss ---- Train = 0.182725; Test = 0.173640\n",
      "Iter 799, Minibatch Loss ---- Train = 0.177478; Test = 0.172858\n",
      "[0.60350414950413112, 0.60615653346290244, 0.60231563129889831, 0.60586463742286589, 0.60424063011830909, 0.60648692446942498, 0.60464397233502787, 0.60751944048792483, 0.60443654091153731, 0.60660348996615587]\n",
      "total running time cost:2180.4600029s\n",
      "Iter 0, Minibatch Loss ---- Train = 15.403926; Test = 16.007334\n",
      "Iter 1, Minibatch Loss ---- Train = 15.542191; Test = 15.498752\n",
      "Iter 2, Minibatch Loss ---- Train = 14.451434; Test = 15.084775\n",
      "Iter 3, Minibatch Loss ---- Train = 14.851022; Test = 14.683482\n",
      "Iter 4, Minibatch Loss ---- Train = 13.808092; Test = 14.262192\n",
      "Iter 5, Minibatch Loss ---- Train = 13.925129; Test = 13.973647\n",
      "Iter 6, Minibatch Loss ---- Train = 14.279840; Test = 13.761974\n",
      "Iter 7, Minibatch Loss ---- Train = 13.685238; Test = 13.588133\n",
      "Iter 8, Minibatch Loss ---- Train = 14.835083; Test = 13.394728\n",
      "Iter 9, Minibatch Loss ---- Train = 13.457209; Test = 13.273378\n",
      "Iter 10, Minibatch Loss ---- Train = 12.586945; Test = 13.038628\n",
      "Iter 11, Minibatch Loss ---- Train = 13.938283; Test = 12.932946\n",
      "Iter 12, Minibatch Loss ---- Train = 13.422011; Test = 12.572891\n",
      "Iter 13, Minibatch Loss ---- Train = 11.797805; Test = 12.595799\n",
      "Iter 14, Minibatch Loss ---- Train = 12.915203; Test = 12.102129\n",
      "Iter 15, Minibatch Loss ---- Train = 12.381727; Test = 12.221414\n",
      "Iter 16, Minibatch Loss ---- Train = 11.824717; Test = 11.791856\n",
      "Iter 17, Minibatch Loss ---- Train = 11.573893; Test = 11.942533\n",
      "Iter 18, Minibatch Loss ---- Train = 11.488911; Test = 11.474487\n",
      "Iter 19, Minibatch Loss ---- Train = 11.846219; Test = 11.543462\n",
      "Iter 20, Minibatch Loss ---- Train = 11.188924; Test = 11.389210\n",
      "Iter 21, Minibatch Loss ---- Train = 10.167248; Test = 10.997319\n",
      "Iter 22, Minibatch Loss ---- Train = 10.760798; Test = 11.217874\n",
      "Iter 23, Minibatch Loss ---- Train = 10.461129; Test = 10.812823\n",
      "Iter 24, Minibatch Loss ---- Train = 11.294596; Test = 10.950274\n",
      "Iter 25, Minibatch Loss ---- Train = 10.657077; Test = 10.603246\n",
      "Iter 26, Minibatch Loss ---- Train = 9.770073; Test = 10.906580\n",
      "Iter 27, Minibatch Loss ---- Train = 10.207492; Test = 10.519558\n",
      "Iter 28, Minibatch Loss ---- Train = 10.405703; Test = 10.741060\n",
      "Iter 29, Minibatch Loss ---- Train = 9.912127; Test = 10.373528\n",
      "Iter 30, Minibatch Loss ---- Train = 10.101424; Test = 10.559810\n",
      "Iter 31, Minibatch Loss ---- Train = 9.334028; Test = 10.215246\n",
      "Iter 32, Minibatch Loss ---- Train = 10.526673; Test = 10.477690\n",
      "Iter 33, Minibatch Loss ---- Train = 9.995163; Test = 10.109212\n",
      "Iter 34, Minibatch Loss ---- Train = 9.646222; Test = 10.317160\n",
      "Iter 35, Minibatch Loss ---- Train = 9.433238; Test = 9.973645\n",
      "Iter 36, Minibatch Loss ---- Train = 10.742809; Test = 10.212930\n",
      "Iter 37, Minibatch Loss ---- Train = 9.330300; Test = 9.828454\n",
      "Iter 38, Minibatch Loss ---- Train = 10.568675; Test = 10.099804\n",
      "Iter 39, Minibatch Loss ---- Train = 9.630226; Test = 9.719196\n",
      "Iter 40, Minibatch Loss ---- Train = 9.628687; Test = 9.964818\n",
      "Iter 41, Minibatch Loss ---- Train = 9.077632; Test = 9.614304\n",
      "Iter 42, Minibatch Loss ---- Train = 9.784085; Test = 9.880251\n",
      "Iter 43, Minibatch Loss ---- Train = 9.841794; Test = 9.452075\n",
      "Iter 44, Minibatch Loss ---- Train = 9.330046; Test = 9.720082\n",
      "Iter 45, Minibatch Loss ---- Train = 9.377045; Test = 9.390562\n",
      "Iter 46, Minibatch Loss ---- Train = 9.340249; Test = 9.745782\n",
      "Iter 47, Minibatch Loss ---- Train = 9.448086; Test = 9.308664\n",
      "Iter 48, Minibatch Loss ---- Train = 10.051799; Test = 9.569722\n",
      "Iter 49, Minibatch Loss ---- Train = 8.921861; Test = 9.212451\n",
      "Iter 50, Minibatch Loss ---- Train = 8.996398; Test = 8.960591\n",
      "Iter 51, Minibatch Loss ---- Train = 8.827706; Test = 8.810533\n",
      "Iter 52, Minibatch Loss ---- Train = 9.112189; Test = 8.692585\n",
      "Iter 53, Minibatch Loss ---- Train = 8.589758; Test = 8.552794\n",
      "Iter 54, Minibatch Loss ---- Train = 8.072487; Test = 8.411747\n",
      "Iter 55, Minibatch Loss ---- Train = 7.944232; Test = 8.263347\n",
      "Iter 56, Minibatch Loss ---- Train = 7.347927; Test = 8.141241\n",
      "Iter 57, Minibatch Loss ---- Train = 7.621964; Test = 8.017070\n",
      "Iter 58, Minibatch Loss ---- Train = 7.709583; Test = 7.932407\n",
      "Iter 59, Minibatch Loss ---- Train = 7.861609; Test = 7.799497\n",
      "Iter 60, Minibatch Loss ---- Train = 7.901226; Test = 7.750925\n",
      "Iter 61, Minibatch Loss ---- Train = 7.854622; Test = 7.598177\n",
      "Iter 62, Minibatch Loss ---- Train = 7.400401; Test = 7.539626\n",
      "Iter 63, Minibatch Loss ---- Train = 7.509883; Test = 7.433174\n",
      "Iter 64, Minibatch Loss ---- Train = 7.734074; Test = 7.385824\n",
      "Iter 65, Minibatch Loss ---- Train = 7.771582; Test = 7.247306\n",
      "Iter 66, Minibatch Loss ---- Train = 6.912546; Test = 7.215431\n",
      "Iter 67, Minibatch Loss ---- Train = 7.175132; Test = 7.095858\n",
      "Iter 68, Minibatch Loss ---- Train = 6.903174; Test = 7.021626\n",
      "Iter 69, Minibatch Loss ---- Train = 6.953992; Test = 6.949764\n",
      "Iter 70, Minibatch Loss ---- Train = 6.530845; Test = 6.922413\n",
      "Iter 71, Minibatch Loss ---- Train = 7.131050; Test = 6.775967\n",
      "Iter 72, Minibatch Loss ---- Train = 6.390405; Test = 6.748197\n",
      "Iter 73, Minibatch Loss ---- Train = 6.799656; Test = 6.653886\n",
      "Iter 74, Minibatch Loss ---- Train = 6.734874; Test = 6.624369\n",
      "Iter 75, Minibatch Loss ---- Train = 6.480603; Test = 6.481249\n",
      "Iter 76, Minibatch Loss ---- Train = 6.533704; Test = 6.510661\n",
      "Iter 77, Minibatch Loss ---- Train = 6.234731; Test = 6.352612\n",
      "Iter 78, Minibatch Loss ---- Train = 6.693766; Test = 6.389994\n",
      "Iter 79, Minibatch Loss ---- Train = 6.382717; Test = 6.217528\n",
      "Iter 80, Minibatch Loss ---- Train = 6.075530; Test = 6.199201\n",
      "Iter 81, Minibatch Loss ---- Train = 6.311119; Test = 6.105066\n",
      "Iter 82, Minibatch Loss ---- Train = 5.995761; Test = 6.091831\n",
      "Iter 83, Minibatch Loss ---- Train = 6.067492; Test = 6.002716\n",
      "Iter 84, Minibatch Loss ---- Train = 5.948581; Test = 5.994068\n",
      "Iter 85, Minibatch Loss ---- Train = 5.652894; Test = 5.940926\n",
      "Iter 86, Minibatch Loss ---- Train = 6.385453; Test = 5.762706\n",
      "Iter 87, Minibatch Loss ---- Train = 6.008671; Test = 5.810566\n",
      "Iter 88, Minibatch Loss ---- Train = 5.963293; Test = 5.740098\n",
      "Iter 89, Minibatch Loss ---- Train = 5.729747; Test = 5.594206\n",
      "Iter 90, Minibatch Loss ---- Train = 5.512258; Test = 5.597252\n",
      "Iter 91, Minibatch Loss ---- Train = 6.165123; Test = 5.523415\n",
      "Iter 92, Minibatch Loss ---- Train = 5.893877; Test = 5.500913\n",
      "Iter 93, Minibatch Loss ---- Train = 5.507587; Test = 5.416133\n",
      "Iter 94, Minibatch Loss ---- Train = 5.576205; Test = 5.264021\n",
      "Iter 95, Minibatch Loss ---- Train = 5.067327; Test = 5.283034\n",
      "Iter 96, Minibatch Loss ---- Train = 5.084094; Test = 5.197216\n",
      "Iter 97, Minibatch Loss ---- Train = 5.566381; Test = 5.306053\n",
      "Iter 98, Minibatch Loss ---- Train = 5.435993; Test = 5.023515\n",
      "Iter 99, Minibatch Loss ---- Train = 4.625997; Test = 5.063308\n",
      "Iter 100, Minibatch Loss ---- Train = 4.827466; Test = 4.955341\n",
      "Iter 101, Minibatch Loss ---- Train = 4.471559; Test = 4.955398\n",
      "Iter 102, Minibatch Loss ---- Train = 5.024492; Test = 4.774943\n",
      "Iter 103, Minibatch Loss ---- Train = 4.972353; Test = 4.927820\n",
      "Iter 104, Minibatch Loss ---- Train = 4.617656; Test = 4.745293\n",
      "Iter 105, Minibatch Loss ---- Train = 4.840456; Test = 4.777884\n",
      "Iter 106, Minibatch Loss ---- Train = 4.745006; Test = 4.553125\n",
      "Iter 107, Minibatch Loss ---- Train = 4.625263; Test = 4.576204\n",
      "Iter 108, Minibatch Loss ---- Train = 4.542612; Test = 4.430383\n",
      "Iter 109, Minibatch Loss ---- Train = 4.351813; Test = 4.462726\n",
      "Iter 110, Minibatch Loss ---- Train = 5.142180; Test = 4.366657\n",
      "Iter 111, Minibatch Loss ---- Train = 4.415763; Test = 4.321226\n",
      "Iter 112, Minibatch Loss ---- Train = 4.466030; Test = 4.418440\n",
      "Iter 113, Minibatch Loss ---- Train = 4.126021; Test = 4.289672\n",
      "Iter 114, Minibatch Loss ---- Train = 4.608675; Test = 4.272016\n",
      "Iter 115, Minibatch Loss ---- Train = 4.090181; Test = 4.148305\n",
      "Iter 116, Minibatch Loss ---- Train = 4.380723; Test = 4.208873\n",
      "Iter 117, Minibatch Loss ---- Train = 4.249321; Test = 4.030093\n",
      "Iter 118, Minibatch Loss ---- Train = 4.222479; Test = 4.168062\n",
      "Iter 119, Minibatch Loss ---- Train = 4.186102; Test = 3.949401\n",
      "Iter 120, Minibatch Loss ---- Train = 4.314867; Test = 3.924483\n",
      "Iter 121, Minibatch Loss ---- Train = 4.262258; Test = 3.910213\n",
      "Iter 122, Minibatch Loss ---- Train = 3.831431; Test = 3.910460\n",
      "Iter 123, Minibatch Loss ---- Train = 3.819623; Test = 3.801758\n",
      "Iter 124, Minibatch Loss ---- Train = 3.818997; Test = 3.789582\n",
      "Iter 125, Minibatch Loss ---- Train = 4.048408; Test = 3.745175\n",
      "Iter 126, Minibatch Loss ---- Train = 3.642451; Test = 3.731441\n",
      "Iter 127, Minibatch Loss ---- Train = 3.923504; Test = 3.633230\n",
      "Iter 128, Minibatch Loss ---- Train = 3.458359; Test = 3.660200\n",
      "Iter 129, Minibatch Loss ---- Train = 3.689250; Test = 3.583679\n",
      "Iter 130, Minibatch Loss ---- Train = 3.402404; Test = 3.561707\n",
      "Iter 131, Minibatch Loss ---- Train = 3.387110; Test = 3.502301\n",
      "Iter 132, Minibatch Loss ---- Train = 3.378459; Test = 3.429791\n",
      "Iter 133, Minibatch Loss ---- Train = 3.280108; Test = 3.335204\n",
      "Iter 134, Minibatch Loss ---- Train = 4.020775; Test = 3.787803\n",
      "Iter 135, Minibatch Loss ---- Train = 3.306536; Test = 3.284780\n",
      "Iter 136, Minibatch Loss ---- Train = 3.460816; Test = 3.300449\n",
      "Iter 137, Minibatch Loss ---- Train = 3.332063; Test = 3.176557\n",
      "Iter 138, Minibatch Loss ---- Train = 3.192130; Test = 3.274673\n",
      "Iter 139, Minibatch Loss ---- Train = 3.084909; Test = 3.191362\n",
      "Iter 140, Minibatch Loss ---- Train = 3.329100; Test = 3.261953\n",
      "Iter 141, Minibatch Loss ---- Train = 3.122228; Test = 3.120843\n",
      "Iter 142, Minibatch Loss ---- Train = 3.131330; Test = 3.103548\n",
      "Iter 143, Minibatch Loss ---- Train = 2.910149; Test = 2.945613\n",
      "Iter 144, Minibatch Loss ---- Train = 3.236857; Test = 3.240687\n",
      "Iter 145, Minibatch Loss ---- Train = 3.129722; Test = 2.949947\n",
      "Iter 146, Minibatch Loss ---- Train = 3.233690; Test = 2.916701\n",
      "Iter 147, Minibatch Loss ---- Train = 3.125706; Test = 2.877092\n",
      "Iter 148, Minibatch Loss ---- Train = 2.892206; Test = 2.919670\n",
      "Iter 149, Minibatch Loss ---- Train = 3.098985; Test = 3.054754\n",
      "Iter 150, Minibatch Loss ---- Train = 2.808082; Test = 2.727121\n",
      "Iter 151, Minibatch Loss ---- Train = 2.936197; Test = 2.698107\n",
      "Iter 152, Minibatch Loss ---- Train = 2.752919; Test = 2.755765\n",
      "Iter 153, Minibatch Loss ---- Train = 2.535082; Test = 2.672889\n",
      "Iter 154, Minibatch Loss ---- Train = 3.072760; Test = 2.919523\n",
      "Iter 155, Minibatch Loss ---- Train = 2.799960; Test = 2.630119\n",
      "Iter 156, Minibatch Loss ---- Train = 2.596809; Test = 2.581902\n",
      "Iter 157, Minibatch Loss ---- Train = 3.239533; Test = 3.242843\n",
      "Iter 158, Minibatch Loss ---- Train = 2.580092; Test = 2.568124\n",
      "Iter 159, Minibatch Loss ---- Train = 2.417487; Test = 2.434965\n",
      "Iter 160, Minibatch Loss ---- Train = 2.667238; Test = 2.447451\n",
      "Iter 161, Minibatch Loss ---- Train = 2.805554; Test = 2.556722\n",
      "Iter 162, Minibatch Loss ---- Train = 2.600897; Test = 2.774868\n",
      "Iter 163, Minibatch Loss ---- Train = 2.628381; Test = 2.540294\n",
      "Iter 164, Minibatch Loss ---- Train = 2.154214; Test = 2.292822\n",
      "Iter 165, Minibatch Loss ---- Train = 2.925925; Test = 2.496463\n",
      "Iter 166, Minibatch Loss ---- Train = 2.576524; Test = 2.326993\n",
      "Iter 167, Minibatch Loss ---- Train = 2.154415; Test = 2.263439\n",
      "Iter 168, Minibatch Loss ---- Train = 2.603429; Test = 2.427635\n",
      "Iter 169, Minibatch Loss ---- Train = 2.480809; Test = 2.344718\n",
      "Iter 170, Minibatch Loss ---- Train = 2.311048; Test = 2.232287\n",
      "Iter 171, Minibatch Loss ---- Train = 2.320444; Test = 2.237686\n",
      "Iter 172, Minibatch Loss ---- Train = 2.311891; Test = 2.243188\n",
      "Iter 173, Minibatch Loss ---- Train = 2.322441; Test = 2.163857\n",
      "Iter 174, Minibatch Loss ---- Train = 2.354754; Test = 2.170439\n",
      "Iter 175, Minibatch Loss ---- Train = 2.188316; Test = 2.172718\n",
      "Iter 176, Minibatch Loss ---- Train = 2.493332; Test = 2.120567\n",
      "Iter 177, Minibatch Loss ---- Train = 2.568562; Test = 2.260349\n",
      "Iter 178, Minibatch Loss ---- Train = 2.085171; Test = 1.995455\n",
      "Iter 179, Minibatch Loss ---- Train = 1.887483; Test = 2.066677\n",
      "Iter 180, Minibatch Loss ---- Train = 2.396778; Test = 2.405421\n",
      "Iter 181, Minibatch Loss ---- Train = 3.465651; Test = 3.437248\n",
      "Iter 182, Minibatch Loss ---- Train = 2.453620; Test = 2.293029\n",
      "Iter 183, Minibatch Loss ---- Train = 2.309255; Test = 2.252641\n",
      "Iter 184, Minibatch Loss ---- Train = 2.213959; Test = 2.068305\n",
      "Iter 185, Minibatch Loss ---- Train = 2.415287; Test = 2.249164\n",
      "Iter 186, Minibatch Loss ---- Train = 2.202836; Test = 1.945024\n",
      "Iter 187, Minibatch Loss ---- Train = 2.033530; Test = 1.975551\n",
      "Iter 188, Minibatch Loss ---- Train = 2.250015; Test = 1.979265\n",
      "Iter 189, Minibatch Loss ---- Train = 1.998646; Test = 1.914986\n",
      "Iter 190, Minibatch Loss ---- Train = 1.817166; Test = 1.853025\n",
      "Iter 191, Minibatch Loss ---- Train = 1.883490; Test = 1.824452\n",
      "Iter 192, Minibatch Loss ---- Train = 1.812063; Test = 1.790101\n",
      "Iter 193, Minibatch Loss ---- Train = 1.946099; Test = 1.851891\n",
      "Iter 194, Minibatch Loss ---- Train = 1.920063; Test = 1.801210\n",
      "Iter 195, Minibatch Loss ---- Train = 1.723968; Test = 1.778674\n",
      "Iter 196, Minibatch Loss ---- Train = 1.892846; Test = 1.804429\n",
      "Iter 197, Minibatch Loss ---- Train = 1.836216; Test = 1.747552\n",
      "Iter 198, Minibatch Loss ---- Train = 1.779952; Test = 1.613392\n",
      "Iter 199, Minibatch Loss ---- Train = 1.793562; Test = 1.583897\n",
      "Iter 200, Minibatch Loss ---- Train = 1.683851; Test = 1.593305\n",
      "Iter 201, Minibatch Loss ---- Train = 1.534693; Test = 1.562235\n",
      "Iter 202, Minibatch Loss ---- Train = 1.676949; Test = 1.627497\n",
      "Iter 203, Minibatch Loss ---- Train = 1.749443; Test = 1.626578\n",
      "Iter 204, Minibatch Loss ---- Train = 2.267381; Test = 2.288763\n",
      "Iter 205, Minibatch Loss ---- Train = 1.592346; Test = 1.569330\n",
      "Iter 206, Minibatch Loss ---- Train = 1.727544; Test = 1.500459\n",
      "Iter 207, Minibatch Loss ---- Train = 1.532246; Test = 1.458851\n",
      "Iter 208, Minibatch Loss ---- Train = 1.501099; Test = 1.494340\n",
      "Iter 209, Minibatch Loss ---- Train = 1.440434; Test = 1.485143\n",
      "Iter 210, Minibatch Loss ---- Train = 1.722184; Test = 1.595132\n",
      "Iter 211, Minibatch Loss ---- Train = 1.755954; Test = 1.465141\n",
      "Iter 212, Minibatch Loss ---- Train = 1.467178; Test = 1.468232\n",
      "Iter 213, Minibatch Loss ---- Train = 1.487822; Test = 1.462394\n",
      "Iter 214, Minibatch Loss ---- Train = 1.770445; Test = 1.940842\n",
      "Iter 215, Minibatch Loss ---- Train = 1.797222; Test = 1.641955\n",
      "Iter 216, Minibatch Loss ---- Train = 1.449260; Test = 1.468493\n",
      "Iter 217, Minibatch Loss ---- Train = 1.354079; Test = 1.419716\n",
      "Iter 218, Minibatch Loss ---- Train = 1.318416; Test = 1.318986\n",
      "Iter 219, Minibatch Loss ---- Train = 1.456846; Test = 1.352742\n",
      "Iter 220, Minibatch Loss ---- Train = 1.484574; Test = 1.331581\n",
      "Iter 221, Minibatch Loss ---- Train = 1.565665; Test = 1.392434\n",
      "Iter 222, Minibatch Loss ---- Train = 1.574099; Test = 1.413349\n",
      "Iter 223, Minibatch Loss ---- Train = 2.038034; Test = 1.814927\n",
      "Iter 224, Minibatch Loss ---- Train = 1.546372; Test = 1.263184\n",
      "Iter 225, Minibatch Loss ---- Train = 1.356435; Test = 1.225174\n",
      "Iter 226, Minibatch Loss ---- Train = 1.217960; Test = 1.206017\n",
      "Iter 227, Minibatch Loss ---- Train = 1.256514; Test = 1.185375\n",
      "Iter 228, Minibatch Loss ---- Train = 1.405153; Test = 1.175942\n",
      "Iter 229, Minibatch Loss ---- Train = 1.135442; Test = 1.181653\n",
      "Iter 230, Minibatch Loss ---- Train = 1.227178; Test = 1.198874\n",
      "Iter 231, Minibatch Loss ---- Train = 1.237093; Test = 1.181301\n",
      "Iter 232, Minibatch Loss ---- Train = 1.535564; Test = 1.579808\n",
      "Iter 233, Minibatch Loss ---- Train = 1.706373; Test = 1.629671\n",
      "Iter 234, Minibatch Loss ---- Train = 1.368505; Test = 1.312114\n",
      "Iter 235, Minibatch Loss ---- Train = 1.271405; Test = 1.147540\n",
      "Iter 236, Minibatch Loss ---- Train = 1.203503; Test = 1.121536\n",
      "Iter 237, Minibatch Loss ---- Train = 1.154066; Test = 1.113493\n",
      "Iter 238, Minibatch Loss ---- Train = 1.313146; Test = 1.265076\n",
      "Iter 239, Minibatch Loss ---- Train = 1.496529; Test = 1.370570\n",
      "Iter 240, Minibatch Loss ---- Train = 1.831769; Test = 1.806327\n",
      "Iter 241, Minibatch Loss ---- Train = 1.301440; Test = 1.227896\n",
      "Iter 242, Minibatch Loss ---- Train = 1.124563; Test = 1.129577\n",
      "Iter 243, Minibatch Loss ---- Train = 1.214174; Test = 1.105902\n",
      "Iter 244, Minibatch Loss ---- Train = 1.198789; Test = 1.075778\n",
      "Iter 245, Minibatch Loss ---- Train = 1.156556; Test = 1.068067\n",
      "Iter 246, Minibatch Loss ---- Train = 1.371487; Test = 1.211438\n",
      "Iter 247, Minibatch Loss ---- Train = 1.243219; Test = 1.305731\n",
      "Iter 248, Minibatch Loss ---- Train = 1.394825; Test = 1.293273\n",
      "Iter 249, Minibatch Loss ---- Train = 1.397094; Test = 1.414591\n",
      "Iter 250, Minibatch Loss ---- Train = 1.348688; Test = 1.226630\n",
      "Iter 251, Minibatch Loss ---- Train = 1.423820; Test = 1.384717\n",
      "Iter 252, Minibatch Loss ---- Train = 1.314434; Test = 1.169846\n",
      "Iter 253, Minibatch Loss ---- Train = 1.886602; Test = 1.688225\n",
      "Iter 254, Minibatch Loss ---- Train = 1.258571; Test = 1.199164\n",
      "Iter 255, Minibatch Loss ---- Train = 1.581434; Test = 1.219653\n",
      "Iter 256, Minibatch Loss ---- Train = 1.329249; Test = 1.188595\n",
      "Iter 257, Minibatch Loss ---- Train = 1.458500; Test = 1.260498\n",
      "Iter 258, Minibatch Loss ---- Train = 1.403641; Test = 1.266757\n",
      "Iter 259, Minibatch Loss ---- Train = 1.203024; Test = 1.194818\n",
      "Iter 260, Minibatch Loss ---- Train = 1.165204; Test = 1.173163\n",
      "Iter 261, Minibatch Loss ---- Train = 1.984310; Test = 1.599578\n",
      "Iter 262, Minibatch Loss ---- Train = 1.426975; Test = 1.521765\n",
      "Iter 263, Minibatch Loss ---- Train = 1.444505; Test = 1.157201\n",
      "Iter 264, Minibatch Loss ---- Train = 1.282696; Test = 1.121528\n",
      "Iter 265, Minibatch Loss ---- Train = 1.211854; Test = 1.141756\n",
      "Iter 266, Minibatch Loss ---- Train = 1.569622; Test = 1.298957\n",
      "Iter 267, Minibatch Loss ---- Train = 1.443647; Test = 1.241592\n",
      "Iter 268, Minibatch Loss ---- Train = 1.329472; Test = 1.137669\n",
      "Iter 269, Minibatch Loss ---- Train = 1.623042; Test = 1.394880\n",
      "Iter 270, Minibatch Loss ---- Train = 1.181839; Test = 1.083947\n",
      "Iter 271, Minibatch Loss ---- Train = 1.383117; Test = 1.117588\n",
      "Iter 272, Minibatch Loss ---- Train = 1.139377; Test = 0.991644\n",
      "Iter 273, Minibatch Loss ---- Train = 1.170343; Test = 0.975415\n",
      "Iter 274, Minibatch Loss ---- Train = 1.335766; Test = 1.006836\n",
      "Iter 275, Minibatch Loss ---- Train = 1.131182; Test = 1.007992\n",
      "Iter 276, Minibatch Loss ---- Train = 1.164039; Test = 1.057107\n",
      "Iter 277, Minibatch Loss ---- Train = 1.446860; Test = 1.092016\n",
      "Iter 278, Minibatch Loss ---- Train = 1.417221; Test = 1.461622\n",
      "Iter 279, Minibatch Loss ---- Train = 1.173059; Test = 1.011677\n",
      "Iter 280, Minibatch Loss ---- Train = 1.143770; Test = 1.041138\n",
      "Iter 281, Minibatch Loss ---- Train = 1.358585; Test = 1.014063\n",
      "Iter 282, Minibatch Loss ---- Train = 1.289694; Test = 1.096619\n",
      "Iter 283, Minibatch Loss ---- Train = 1.168180; Test = 1.061438\n",
      "Iter 284, Minibatch Loss ---- Train = 1.463294; Test = 1.404200\n",
      "Iter 285, Minibatch Loss ---- Train = 1.263580; Test = 1.059328\n",
      "Iter 286, Minibatch Loss ---- Train = 1.060417; Test = 0.960196\n",
      "Iter 287, Minibatch Loss ---- Train = 1.192763; Test = 0.962924\n",
      "Iter 288, Minibatch Loss ---- Train = 1.138862; Test = 0.977411\n",
      "Iter 289, Minibatch Loss ---- Train = 1.713466; Test = 1.486779\n",
      "Iter 290, Minibatch Loss ---- Train = 1.163930; Test = 1.060191\n",
      "Iter 291, Minibatch Loss ---- Train = 1.068753; Test = 1.004495\n",
      "Iter 292, Minibatch Loss ---- Train = 1.100035; Test = 0.979664\n",
      "Iter 293, Minibatch Loss ---- Train = 1.219825; Test = 0.931700\n",
      "Iter 294, Minibatch Loss ---- Train = 1.127634; Test = 1.012542\n",
      "Iter 295, Minibatch Loss ---- Train = 1.651304; Test = 1.331702\n",
      "Iter 296, Minibatch Loss ---- Train = 1.199435; Test = 0.960197\n",
      "Iter 297, Minibatch Loss ---- Train = 0.976479; Test = 0.908119\n",
      "Iter 298, Minibatch Loss ---- Train = 1.270986; Test = 0.930385\n",
      "Iter 299, Minibatch Loss ---- Train = 1.018715; Test = 0.995484\n",
      "Iter 300, Minibatch Loss ---- Train = 1.225338; Test = 1.115146\n",
      "Iter 301, Minibatch Loss ---- Train = 1.053980; Test = 0.994722\n",
      "Iter 302, Minibatch Loss ---- Train = 1.218013; Test = 0.914557\n",
      "Iter 303, Minibatch Loss ---- Train = 1.179141; Test = 0.888336\n",
      "Iter 304, Minibatch Loss ---- Train = 1.759655; Test = 1.680896\n",
      "Iter 305, Minibatch Loss ---- Train = 2.028420; Test = 1.769351\n",
      "Iter 306, Minibatch Loss ---- Train = 1.278020; Test = 1.077644\n",
      "Iter 307, Minibatch Loss ---- Train = 2.884751; Test = 2.595257\n",
      "Iter 308, Minibatch Loss ---- Train = 1.672360; Test = 1.685498\n",
      "Iter 309, Minibatch Loss ---- Train = 1.688538; Test = 1.299043\n",
      "Iter 310, Minibatch Loss ---- Train = 1.479620; Test = 1.134476\n",
      "Iter 311, Minibatch Loss ---- Train = 1.189745; Test = 1.097662\n",
      "Iter 312, Minibatch Loss ---- Train = 1.182079; Test = 1.035237\n",
      "Iter 313, Minibatch Loss ---- Train = 1.588727; Test = 1.480633\n",
      "Iter 314, Minibatch Loss ---- Train = 1.192074; Test = 1.000751\n",
      "Iter 315, Minibatch Loss ---- Train = 1.138861; Test = 0.987836\n",
      "Iter 316, Minibatch Loss ---- Train = 1.273589; Test = 0.979364\n",
      "Iter 317, Minibatch Loss ---- Train = 1.155687; Test = 0.989139\n",
      "Iter 318, Minibatch Loss ---- Train = 1.019029; Test = 0.997877\n",
      "Iter 319, Minibatch Loss ---- Train = 1.272618; Test = 0.942940\n",
      "Iter 320, Minibatch Loss ---- Train = 1.082222; Test = 0.940650\n",
      "Iter 321, Minibatch Loss ---- Train = 1.167475; Test = 1.019286\n",
      "Iter 322, Minibatch Loss ---- Train = 2.105978; Test = 2.036841\n",
      "Iter 323, Minibatch Loss ---- Train = 1.114655; Test = 0.965936\n",
      "Iter 324, Minibatch Loss ---- Train = 1.617605; Test = 1.839057\n",
      "Iter 325, Minibatch Loss ---- Train = 1.055280; Test = 0.949845\n",
      "Iter 326, Minibatch Loss ---- Train = 1.247543; Test = 0.960191\n",
      "Iter 327, Minibatch Loss ---- Train = 1.953557; Test = 1.930310\n",
      "Iter 328, Minibatch Loss ---- Train = 1.254098; Test = 1.181702\n",
      "Iter 329, Minibatch Loss ---- Train = 1.282926; Test = 1.046016\n",
      "Iter 330, Minibatch Loss ---- Train = 1.184319; Test = 0.978324\n",
      "Iter 331, Minibatch Loss ---- Train = 1.152250; Test = 0.988891\n",
      "Iter 332, Minibatch Loss ---- Train = 0.965377; Test = 0.941770\n",
      "Iter 333, Minibatch Loss ---- Train = 0.988995; Test = 0.927125\n",
      "Iter 334, Minibatch Loss ---- Train = 1.033706; Test = 0.932118\n",
      "Iter 335, Minibatch Loss ---- Train = 1.788599; Test = 1.520804\n",
      "Iter 336, Minibatch Loss ---- Train = 1.711002; Test = 1.430714\n",
      "Iter 337, Minibatch Loss ---- Train = 0.998194; Test = 1.072278\n",
      "Iter 338, Minibatch Loss ---- Train = 1.408996; Test = 1.080076\n",
      "Iter 339, Minibatch Loss ---- Train = 1.013024; Test = 1.043499\n",
      "Iter 340, Minibatch Loss ---- Train = 1.170794; Test = 1.058360\n",
      "Iter 341, Minibatch Loss ---- Train = 1.217382; Test = 1.106646\n",
      "Iter 342, Minibatch Loss ---- Train = 1.118825; Test = 1.004077\n",
      "Iter 343, Minibatch Loss ---- Train = 1.089624; Test = 1.126484\n",
      "Iter 344, Minibatch Loss ---- Train = 1.113245; Test = 1.043212\n",
      "Iter 345, Minibatch Loss ---- Train = 1.313170; Test = 1.067854\n",
      "Iter 346, Minibatch Loss ---- Train = 1.199393; Test = 0.998293\n",
      "Iter 347, Minibatch Loss ---- Train = 1.245074; Test = 1.043438\n",
      "Iter 348, Minibatch Loss ---- Train = 1.161734; Test = 1.043664\n",
      "Iter 349, Minibatch Loss ---- Train = 1.341638; Test = 1.099272\n",
      "Iter 350, Minibatch Loss ---- Train = 1.242965; Test = 1.026263\n",
      "Iter 351, Minibatch Loss ---- Train = 1.032045; Test = 0.993165\n",
      "Iter 352, Minibatch Loss ---- Train = 1.379655; Test = 1.311241\n",
      "Iter 353, Minibatch Loss ---- Train = 1.104337; Test = 1.026951\n",
      "Iter 354, Minibatch Loss ---- Train = 1.170372; Test = 1.054030\n",
      "Iter 355, Minibatch Loss ---- Train = 1.218564; Test = 0.910454\n",
      "Iter 356, Minibatch Loss ---- Train = 1.105524; Test = 0.875315\n",
      "Iter 357, Minibatch Loss ---- Train = 1.302744; Test = 1.019817\n",
      "Iter 358, Minibatch Loss ---- Train = 0.920936; Test = 0.921873\n",
      "Iter 359, Minibatch Loss ---- Train = 0.998881; Test = 1.048392\n",
      "Iter 360, Minibatch Loss ---- Train = 1.153456; Test = 1.136127\n",
      "Iter 361, Minibatch Loss ---- Train = 2.022477; Test = 1.873946\n",
      "Iter 362, Minibatch Loss ---- Train = 1.202411; Test = 1.086357\n",
      "Iter 363, Minibatch Loss ---- Train = 1.050110; Test = 0.974180\n",
      "Iter 364, Minibatch Loss ---- Train = 1.606430; Test = 1.549530\n",
      "Iter 365, Minibatch Loss ---- Train = 1.201684; Test = 1.060541\n",
      "Iter 366, Minibatch Loss ---- Train = 1.137323; Test = 0.944053\n",
      "Iter 367, Minibatch Loss ---- Train = 1.073702; Test = 0.921330\n",
      "Iter 368, Minibatch Loss ---- Train = 1.652622; Test = 1.484474\n",
      "Iter 369, Minibatch Loss ---- Train = 1.396325; Test = 1.023887\n",
      "Iter 370, Minibatch Loss ---- Train = 1.151014; Test = 0.940140\n",
      "Iter 371, Minibatch Loss ---- Train = 0.959295; Test = 0.905865\n",
      "Iter 372, Minibatch Loss ---- Train = 1.029682; Test = 0.898574\n",
      "Iter 373, Minibatch Loss ---- Train = 0.979335; Test = 0.900987\n",
      "Iter 374, Minibatch Loss ---- Train = 1.127096; Test = 1.057606\n",
      "Iter 375, Minibatch Loss ---- Train = 1.032956; Test = 0.899521\n",
      "Iter 376, Minibatch Loss ---- Train = 0.980173; Test = 0.880046\n",
      "Iter 377, Minibatch Loss ---- Train = 4.590439; Test = 4.242205\n",
      "Iter 378, Minibatch Loss ---- Train = 0.958838; Test = 0.832340\n",
      "Iter 379, Minibatch Loss ---- Train = 0.942006; Test = 0.848974\n",
      "Iter 380, Minibatch Loss ---- Train = 1.058749; Test = 1.015704\n",
      "Iter 381, Minibatch Loss ---- Train = 2.976173; Test = 2.989995\n",
      "Iter 382, Minibatch Loss ---- Train = 1.162165; Test = 1.115518\n",
      "Iter 383, Minibatch Loss ---- Train = 1.039319; Test = 1.032683\n",
      "Iter 384, Minibatch Loss ---- Train = 1.228888; Test = 1.028296\n",
      "Iter 385, Minibatch Loss ---- Train = 0.974037; Test = 1.070326\n",
      "Iter 386, Minibatch Loss ---- Train = 1.913571; Test = 1.738955\n",
      "Iter 387, Minibatch Loss ---- Train = 1.181193; Test = 1.199659\n",
      "Iter 388, Minibatch Loss ---- Train = 1.089403; Test = 1.032315\n",
      "Iter 389, Minibatch Loss ---- Train = 1.002727; Test = 0.890635\n",
      "Iter 390, Minibatch Loss ---- Train = 1.059064; Test = 0.852522\n",
      "Iter 391, Minibatch Loss ---- Train = 0.937933; Test = 0.828410\n",
      "Iter 392, Minibatch Loss ---- Train = 0.851426; Test = 0.825783\n",
      "Iter 393, Minibatch Loss ---- Train = 0.953081; Test = 0.922960\n",
      "Iter 394, Minibatch Loss ---- Train = 0.981628; Test = 0.861843\n",
      "Iter 395, Minibatch Loss ---- Train = 1.034183; Test = 0.926766\n",
      "Iter 396, Minibatch Loss ---- Train = 4.720694; Test = 4.837250\n",
      "Iter 397, Minibatch Loss ---- Train = 0.872369; Test = 0.885397\n",
      "Iter 398, Minibatch Loss ---- Train = 0.942756; Test = 0.861755\n",
      "Iter 399, Minibatch Loss ---- Train = 0.940973; Test = 0.881095\n",
      "Iter 400, Minibatch Loss ---- Train = 0.859188; Test = 0.862275\n",
      "Iter 401, Minibatch Loss ---- Train = 1.039882; Test = 0.955361\n",
      "Iter 402, Minibatch Loss ---- Train = 0.950865; Test = 0.865524\n",
      "Iter 403, Minibatch Loss ---- Train = 2.529464; Test = 1.929008\n",
      "Iter 404, Minibatch Loss ---- Train = 1.164560; Test = 1.002771\n",
      "Iter 405, Minibatch Loss ---- Train = 0.906592; Test = 0.841802\n",
      "Iter 406, Minibatch Loss ---- Train = 1.024231; Test = 0.834846\n",
      "Iter 407, Minibatch Loss ---- Train = 1.265181; Test = 0.970070\n",
      "Iter 408, Minibatch Loss ---- Train = 1.184319; Test = 1.028165\n",
      "Iter 409, Minibatch Loss ---- Train = 1.093697; Test = 0.995143\n",
      "Iter 410, Minibatch Loss ---- Train = 1.116435; Test = 0.877652\n",
      "Iter 411, Minibatch Loss ---- Train = 0.918020; Test = 0.883281\n",
      "Iter 412, Minibatch Loss ---- Train = 0.934700; Test = 0.848622\n",
      "Iter 413, Minibatch Loss ---- Train = 1.152399; Test = 0.960227\n",
      "Iter 414, Minibatch Loss ---- Train = 1.068968; Test = 0.886161\n",
      "Iter 415, Minibatch Loss ---- Train = 1.178808; Test = 1.038845\n",
      "Iter 416, Minibatch Loss ---- Train = 1.118759; Test = 1.038663\n",
      "Iter 417, Minibatch Loss ---- Train = 0.930259; Test = 0.854409\n",
      "Iter 418, Minibatch Loss ---- Train = 0.936910; Test = 0.832044\n",
      "Iter 419, Minibatch Loss ---- Train = 1.008295; Test = 0.903224\n",
      "Iter 420, Minibatch Loss ---- Train = 1.085110; Test = 0.916430\n",
      "Iter 421, Minibatch Loss ---- Train = 1.030134; Test = 0.864822\n",
      "Iter 422, Minibatch Loss ---- Train = 1.029770; Test = 0.843900\n",
      "Iter 423, Minibatch Loss ---- Train = 1.009477; Test = 0.842664\n",
      "Iter 424, Minibatch Loss ---- Train = 1.002306; Test = 0.983027\n",
      "Iter 425, Minibatch Loss ---- Train = 1.090360; Test = 0.908618\n",
      "Iter 426, Minibatch Loss ---- Train = 1.120837; Test = 0.867227\n",
      "Iter 427, Minibatch Loss ---- Train = 0.919939; Test = 0.812888\n",
      "Iter 428, Minibatch Loss ---- Train = 0.968117; Test = 0.884120\n",
      "Iter 429, Minibatch Loss ---- Train = 1.038939; Test = 0.883902\n",
      "Iter 430, Minibatch Loss ---- Train = 1.144722; Test = 1.004119\n",
      "Iter 431, Minibatch Loss ---- Train = 1.054428; Test = 0.916607\n",
      "Iter 432, Minibatch Loss ---- Train = 1.047522; Test = 0.822155\n",
      "Iter 433, Minibatch Loss ---- Train = 1.185719; Test = 0.908447\n",
      "Iter 434, Minibatch Loss ---- Train = 0.831215; Test = 0.809968\n",
      "Iter 435, Minibatch Loss ---- Train = 1.438999; Test = 1.032870\n",
      "Iter 436, Minibatch Loss ---- Train = 1.123357; Test = 1.038809\n",
      "Iter 437, Minibatch Loss ---- Train = 1.121600; Test = 0.927362\n",
      "Iter 438, Minibatch Loss ---- Train = 1.552478; Test = 1.159630\n",
      "Iter 439, Minibatch Loss ---- Train = 1.116248; Test = 0.972878\n",
      "Iter 440, Minibatch Loss ---- Train = 1.319477; Test = 0.923843\n",
      "Iter 441, Minibatch Loss ---- Train = 1.020023; Test = 0.876213\n",
      "Iter 442, Minibatch Loss ---- Train = 1.001208; Test = 0.857795\n",
      "Iter 443, Minibatch Loss ---- Train = 0.968766; Test = 0.814670\n",
      "Iter 444, Minibatch Loss ---- Train = 0.891608; Test = 0.823950\n",
      "Iter 445, Minibatch Loss ---- Train = 1.092327; Test = 0.891128\n",
      "Iter 446, Minibatch Loss ---- Train = 1.552242; Test = 1.775448\n",
      "Iter 447, Minibatch Loss ---- Train = 2.321632; Test = 2.285564\n",
      "Iter 448, Minibatch Loss ---- Train = 1.349836; Test = 1.176489\n",
      "Iter 449, Minibatch Loss ---- Train = 1.116985; Test = 1.050894\n",
      "Iter 450, Minibatch Loss ---- Train = 1.109747; Test = 1.095485\n",
      "Iter 451, Minibatch Loss ---- Train = 1.226788; Test = 1.017753\n",
      "Iter 452, Minibatch Loss ---- Train = 0.936773; Test = 0.881474\n",
      "Iter 453, Minibatch Loss ---- Train = 1.035500; Test = 0.878387\n",
      "Iter 454, Minibatch Loss ---- Train = 0.994174; Test = 0.883587\n",
      "Iter 455, Minibatch Loss ---- Train = 1.063065; Test = 0.888375\n",
      "Iter 456, Minibatch Loss ---- Train = 0.988803; Test = 0.862568\n",
      "Iter 457, Minibatch Loss ---- Train = 0.865028; Test = 0.853971\n",
      "Iter 458, Minibatch Loss ---- Train = 0.953434; Test = 0.824202\n",
      "Iter 459, Minibatch Loss ---- Train = 0.965386; Test = 0.907646\n",
      "Iter 460, Minibatch Loss ---- Train = 1.517067; Test = 1.275909\n",
      "Iter 461, Minibatch Loss ---- Train = 1.883407; Test = 1.869881\n",
      "Iter 462, Minibatch Loss ---- Train = 1.370174; Test = 1.202858\n",
      "Iter 463, Minibatch Loss ---- Train = 1.110210; Test = 1.069204\n",
      "Iter 464, Minibatch Loss ---- Train = 1.267041; Test = 1.017143\n",
      "Iter 465, Minibatch Loss ---- Train = 1.226951; Test = 1.093247\n",
      "Iter 466, Minibatch Loss ---- Train = 1.064416; Test = 0.989682\n",
      "Iter 467, Minibatch Loss ---- Train = 1.175119; Test = 0.930066\n",
      "Iter 468, Minibatch Loss ---- Train = 1.058479; Test = 0.904252\n",
      "Iter 469, Minibatch Loss ---- Train = 0.780931; Test = 0.889086\n",
      "Iter 470, Minibatch Loss ---- Train = 0.958143; Test = 0.861000\n",
      "Iter 471, Minibatch Loss ---- Train = 1.638481; Test = 1.384982\n",
      "Iter 472, Minibatch Loss ---- Train = 1.179346; Test = 0.992312\n",
      "Iter 473, Minibatch Loss ---- Train = 1.003842; Test = 0.963535\n",
      "Iter 474, Minibatch Loss ---- Train = 1.378133; Test = 1.216445\n",
      "Iter 475, Minibatch Loss ---- Train = 1.094446; Test = 1.059624\n",
      "Iter 476, Minibatch Loss ---- Train = 0.908641; Test = 0.922366\n",
      "Iter 477, Minibatch Loss ---- Train = 1.106165; Test = 0.911073\n",
      "Iter 478, Minibatch Loss ---- Train = 1.016981; Test = 0.902985\n",
      "Iter 479, Minibatch Loss ---- Train = 1.329153; Test = 1.155804\n",
      "Iter 480, Minibatch Loss ---- Train = 1.140625; Test = 0.957512\n",
      "Iter 481, Minibatch Loss ---- Train = 1.188259; Test = 1.068148\n",
      "Iter 482, Minibatch Loss ---- Train = 1.088512; Test = 0.894097\n",
      "Iter 483, Minibatch Loss ---- Train = 1.250715; Test = 0.907077\n",
      "Iter 484, Minibatch Loss ---- Train = 0.996208; Test = 0.877055\n",
      "Iter 485, Minibatch Loss ---- Train = 1.115447; Test = 0.950305\n",
      "Iter 486, Minibatch Loss ---- Train = 0.978376; Test = 0.872478\n",
      "Iter 487, Minibatch Loss ---- Train = 0.921104; Test = 0.821965\n",
      "Iter 488, Minibatch Loss ---- Train = 1.162521; Test = 0.891555\n",
      "Iter 489, Minibatch Loss ---- Train = 0.962661; Test = 0.844714\n",
      "Iter 490, Minibatch Loss ---- Train = 0.989321; Test = 0.845681\n",
      "Iter 491, Minibatch Loss ---- Train = 0.930845; Test = 0.913438\n",
      "Iter 492, Minibatch Loss ---- Train = 1.220993; Test = 0.991240\n",
      "Iter 493, Minibatch Loss ---- Train = 1.070043; Test = 0.922700\n",
      "Iter 494, Minibatch Loss ---- Train = 1.067367; Test = 0.913691\n",
      "Iter 495, Minibatch Loss ---- Train = 1.086422; Test = 0.892667\n",
      "Iter 496, Minibatch Loss ---- Train = 4.191751; Test = 3.691813\n",
      "Iter 497, Minibatch Loss ---- Train = 1.211068; Test = 1.123888\n",
      "Iter 498, Minibatch Loss ---- Train = 0.859047; Test = 0.840208\n",
      "Iter 499, Minibatch Loss ---- Train = 0.936767; Test = 0.827182\n",
      "Iter 500, Minibatch Loss ---- Train = 0.837114; Test = 0.838902\n",
      "Iter 501, Minibatch Loss ---- Train = 0.882536; Test = 0.802507\n",
      "Iter 502, Minibatch Loss ---- Train = 1.243946; Test = 0.830856\n",
      "Iter 503, Minibatch Loss ---- Train = 1.009463; Test = 0.983873\n",
      "Iter 504, Minibatch Loss ---- Train = 0.928184; Test = 0.776853\n",
      "Iter 505, Minibatch Loss ---- Train = 0.954059; Test = 0.812018\n",
      "Iter 506, Minibatch Loss ---- Train = 0.958711; Test = 0.809873\n",
      "Iter 507, Minibatch Loss ---- Train = 1.265306; Test = 1.052352\n",
      "Iter 508, Minibatch Loss ---- Train = 0.874522; Test = 0.840338\n",
      "Iter 509, Minibatch Loss ---- Train = 3.645465; Test = 3.789410\n",
      "Iter 510, Minibatch Loss ---- Train = 1.067613; Test = 0.926483\n",
      "Iter 511, Minibatch Loss ---- Train = 0.873030; Test = 0.869463\n",
      "Iter 512, Minibatch Loss ---- Train = 1.122122; Test = 0.928465\n",
      "Iter 513, Minibatch Loss ---- Train = 0.934262; Test = 0.859800\n",
      "Iter 514, Minibatch Loss ---- Train = 0.941676; Test = 0.832007\n",
      "Iter 515, Minibatch Loss ---- Train = 0.887314; Test = 0.795748\n",
      "Iter 516, Minibatch Loss ---- Train = 1.035147; Test = 0.810820\n",
      "Iter 517, Minibatch Loss ---- Train = 2.867108; Test = 2.626247\n",
      "Iter 518, Minibatch Loss ---- Train = 1.329371; Test = 1.099696\n",
      "Iter 519, Minibatch Loss ---- Train = 0.875824; Test = 0.800633\n",
      "Iter 520, Minibatch Loss ---- Train = 0.940468; Test = 0.823533\n",
      "Iter 521, Minibatch Loss ---- Train = 1.136949; Test = 0.869893\n",
      "Iter 522, Minibatch Loss ---- Train = 1.447946; Test = 1.380082\n",
      "Iter 523, Minibatch Loss ---- Train = 1.287570; Test = 1.019952\n",
      "Iter 524, Minibatch Loss ---- Train = 2.263194; Test = 2.341808\n",
      "Iter 525, Minibatch Loss ---- Train = 1.532865; Test = 1.266661\n",
      "Iter 526, Minibatch Loss ---- Train = 1.364913; Test = 0.986302\n",
      "Iter 527, Minibatch Loss ---- Train = 1.169555; Test = 1.150995\n",
      "Iter 528, Minibatch Loss ---- Train = 0.979943; Test = 0.863003\n",
      "Iter 529, Minibatch Loss ---- Train = 1.021697; Test = 0.848280\n",
      "Iter 530, Minibatch Loss ---- Train = 0.923279; Test = 0.881518\n",
      "Iter 531, Minibatch Loss ---- Train = 1.133961; Test = 0.829886\n",
      "Iter 532, Minibatch Loss ---- Train = 0.950838; Test = 0.831769\n",
      "Iter 533, Minibatch Loss ---- Train = 0.880038; Test = 0.815495\n",
      "Iter 534, Minibatch Loss ---- Train = 0.943270; Test = 0.781086\n",
      "Iter 535, Minibatch Loss ---- Train = 1.061784; Test = 0.861188\n",
      "Iter 536, Minibatch Loss ---- Train = 0.902018; Test = 0.807633\n",
      "Iter 537, Minibatch Loss ---- Train = 0.874089; Test = 0.842706\n",
      "Iter 538, Minibatch Loss ---- Train = 1.273484; Test = 1.161060\n",
      "Iter 539, Minibatch Loss ---- Train = 0.885692; Test = 0.867819\n",
      "Iter 540, Minibatch Loss ---- Train = 1.078295; Test = 0.814965\n",
      "Iter 541, Minibatch Loss ---- Train = 0.912345; Test = 0.785688\n",
      "Iter 542, Minibatch Loss ---- Train = 1.489692; Test = 1.323106\n",
      "Iter 543, Minibatch Loss ---- Train = 0.902794; Test = 0.798090\n",
      "Iter 544, Minibatch Loss ---- Train = 0.909634; Test = 0.759482\n",
      "Iter 545, Minibatch Loss ---- Train = 1.136774; Test = 0.765842\n",
      "Iter 546, Minibatch Loss ---- Train = 0.947996; Test = 1.051781\n",
      "Iter 547, Minibatch Loss ---- Train = 2.432704; Test = 2.427705\n",
      "Iter 548, Minibatch Loss ---- Train = 0.973266; Test = 0.778490\n",
      "Iter 549, Minibatch Loss ---- Train = 0.987715; Test = 0.766931\n",
      "Iter 550, Minibatch Loss ---- Train = 0.914654; Test = 0.793990\n",
      "Iter 551, Minibatch Loss ---- Train = 1.071467; Test = 0.889383\n",
      "Iter 552, Minibatch Loss ---- Train = 0.985827; Test = 0.924719\n",
      "Iter 553, Minibatch Loss ---- Train = 1.083074; Test = 0.844120\n",
      "Iter 554, Minibatch Loss ---- Train = 0.824838; Test = 0.775363\n",
      "Iter 555, Minibatch Loss ---- Train = 1.010405; Test = 0.938520\n",
      "Iter 556, Minibatch Loss ---- Train = 1.092133; Test = 0.964418\n",
      "Iter 557, Minibatch Loss ---- Train = 0.965551; Test = 0.837227\n",
      "Iter 558, Minibatch Loss ---- Train = 0.909466; Test = 0.925007\n",
      "Iter 559, Minibatch Loss ---- Train = 0.972604; Test = 0.890318\n",
      "Iter 560, Minibatch Loss ---- Train = 0.961316; Test = 0.894894\n",
      "Iter 561, Minibatch Loss ---- Train = 1.344964; Test = 0.983337\n",
      "Iter 562, Minibatch Loss ---- Train = 0.948078; Test = 0.798320\n",
      "Iter 563, Minibatch Loss ---- Train = 0.981260; Test = 0.826807\n",
      "Iter 564, Minibatch Loss ---- Train = 0.855757; Test = 0.831562\n",
      "Iter 565, Minibatch Loss ---- Train = 0.964994; Test = 0.848129\n",
      "Iter 566, Minibatch Loss ---- Train = 0.903288; Test = 0.803216\n",
      "Iter 567, Minibatch Loss ---- Train = 0.920920; Test = 0.806746\n",
      "Iter 568, Minibatch Loss ---- Train = 1.214966; Test = 0.991912\n",
      "Iter 569, Minibatch Loss ---- Train = 1.268193; Test = 1.062745\n",
      "Iter 570, Minibatch Loss ---- Train = 8.547241; Test = 9.404147\n",
      "Iter 571, Minibatch Loss ---- Train = 4.882192; Test = 4.225424\n",
      "Iter 572, Minibatch Loss ---- Train = 3.638284; Test = 3.002275\n",
      "Iter 573, Minibatch Loss ---- Train = 3.452801; Test = 3.120908\n",
      "Iter 574, Minibatch Loss ---- Train = 2.637313; Test = 2.189106\n",
      "Iter 575, Minibatch Loss ---- Train = 1.290784; Test = 1.142203\n",
      "Iter 576, Minibatch Loss ---- Train = 1.345243; Test = 1.193641\n",
      "Iter 577, Minibatch Loss ---- Train = 3.119618; Test = 3.237914\n",
      "Iter 578, Minibatch Loss ---- Train = 1.038351; Test = 0.940525\n",
      "Iter 579, Minibatch Loss ---- Train = 0.971651; Test = 0.858293\n",
      "Iter 580, Minibatch Loss ---- Train = 0.974453; Test = 0.828260\n",
      "Iter 581, Minibatch Loss ---- Train = 0.960061; Test = 0.879143\n",
      "Iter 582, Minibatch Loss ---- Train = 3.382103; Test = 3.563897\n",
      "Iter 583, Minibatch Loss ---- Train = 1.193053; Test = 1.150702\n",
      "Iter 584, Minibatch Loss ---- Train = 1.063977; Test = 0.867713\n",
      "Iter 585, Minibatch Loss ---- Train = 0.946831; Test = 0.829236\n",
      "Iter 586, Minibatch Loss ---- Train = 1.092205; Test = 0.949607\n",
      "Iter 587, Minibatch Loss ---- Train = 1.023703; Test = 0.823748\n",
      "Iter 588, Minibatch Loss ---- Train = 0.898154; Test = 0.858198\n",
      "Iter 589, Minibatch Loss ---- Train = 0.827893; Test = 0.827837\n",
      "Iter 590, Minibatch Loss ---- Train = 0.892835; Test = 0.862691\n",
      "Iter 591, Minibatch Loss ---- Train = 1.047613; Test = 0.914106\n",
      "Iter 592, Minibatch Loss ---- Train = 0.816540; Test = 0.821072\n",
      "Iter 593, Minibatch Loss ---- Train = 0.951121; Test = 0.885791\n",
      "Iter 594, Minibatch Loss ---- Train = 1.035647; Test = 0.969498\n",
      "Iter 595, Minibatch Loss ---- Train = 1.062059; Test = 0.909250\n",
      "Iter 596, Minibatch Loss ---- Train = 0.890853; Test = 0.849468\n",
      "Iter 597, Minibatch Loss ---- Train = 1.170176; Test = 0.959047\n",
      "Iter 598, Minibatch Loss ---- Train = 1.718178; Test = 1.493425\n",
      "Iter 599, Minibatch Loss ---- Train = 0.947198; Test = 0.856508\n",
      "Iter 600, Minibatch Loss ---- Train = 0.883147; Test = 0.887641\n",
      "Iter 601, Minibatch Loss ---- Train = 0.928992; Test = 0.834066\n",
      "Iter 602, Minibatch Loss ---- Train = 0.892703; Test = 0.810624\n",
      "Iter 603, Minibatch Loss ---- Train = 1.018428; Test = 0.885380\n",
      "Iter 604, Minibatch Loss ---- Train = 1.042477; Test = 0.841839\n",
      "Iter 605, Minibatch Loss ---- Train = 1.047494; Test = 0.842877\n",
      "Iter 606, Minibatch Loss ---- Train = 1.316193; Test = 1.142478\n",
      "Iter 607, Minibatch Loss ---- Train = 0.907586; Test = 0.841738\n",
      "Iter 608, Minibatch Loss ---- Train = 1.081562; Test = 0.992669\n",
      "Iter 609, Minibatch Loss ---- Train = 0.971709; Test = 0.820196\n",
      "Iter 610, Minibatch Loss ---- Train = 0.946184; Test = 0.858328\n",
      "Iter 611, Minibatch Loss ---- Train = 0.784158; Test = 0.809629\n",
      "Iter 612, Minibatch Loss ---- Train = 0.941108; Test = 0.785502\n",
      "Iter 613, Minibatch Loss ---- Train = 0.903299; Test = 0.838146\n",
      "Iter 614, Minibatch Loss ---- Train = 1.114785; Test = 1.040035\n",
      "Iter 615, Minibatch Loss ---- Train = 0.939094; Test = 0.770323\n",
      "Iter 616, Minibatch Loss ---- Train = 0.955721; Test = 0.849792\n",
      "Iter 617, Minibatch Loss ---- Train = 3.135205; Test = 3.341434\n",
      "Iter 618, Minibatch Loss ---- Train = 1.129790; Test = 0.970582\n",
      "Iter 619, Minibatch Loss ---- Train = 1.002106; Test = 0.929532\n",
      "Iter 620, Minibatch Loss ---- Train = 0.901354; Test = 0.812492\n",
      "Iter 621, Minibatch Loss ---- Train = 0.933189; Test = 0.752376\n",
      "Iter 622, Minibatch Loss ---- Train = 3.418626; Test = 3.038902\n",
      "Iter 623, Minibatch Loss ---- Train = 1.002304; Test = 0.860415\n",
      "Iter 624, Minibatch Loss ---- Train = 1.199085; Test = 0.832656\n",
      "Iter 625, Minibatch Loss ---- Train = 0.997209; Test = 0.893496\n",
      "Iter 626, Minibatch Loss ---- Train = 0.946422; Test = 0.784968\n",
      "Iter 627, Minibatch Loss ---- Train = 0.989664; Test = 0.843691\n",
      "Iter 628, Minibatch Loss ---- Train = 0.910055; Test = 0.847350\n",
      "Iter 629, Minibatch Loss ---- Train = 0.983860; Test = 0.938320\n",
      "Iter 630, Minibatch Loss ---- Train = 1.078401; Test = 0.875751\n",
      "Iter 631, Minibatch Loss ---- Train = 0.920876; Test = 0.822281\n",
      "Iter 632, Minibatch Loss ---- Train = 0.787528; Test = 0.742362\n",
      "Iter 633, Minibatch Loss ---- Train = 1.700101; Test = 1.417351\n",
      "Iter 634, Minibatch Loss ---- Train = 1.117209; Test = 0.899553\n",
      "Iter 635, Minibatch Loss ---- Train = 0.855982; Test = 0.766007\n",
      "Iter 636, Minibatch Loss ---- Train = 0.971205; Test = 0.781982\n",
      "Iter 637, Minibatch Loss ---- Train = 0.753925; Test = 0.736202\n",
      "Iter 638, Minibatch Loss ---- Train = 1.004466; Test = 0.904037\n",
      "Iter 639, Minibatch Loss ---- Train = 0.929855; Test = 0.827426\n",
      "Iter 640, Minibatch Loss ---- Train = 0.981950; Test = 0.782011\n",
      "Iter 641, Minibatch Loss ---- Train = 0.921161; Test = 0.896062\n",
      "Iter 642, Minibatch Loss ---- Train = 0.792257; Test = 0.741944\n",
      "Iter 643, Minibatch Loss ---- Train = 0.906867; Test = 0.778628\n",
      "Iter 644, Minibatch Loss ---- Train = 0.904180; Test = 0.822837\n",
      "Iter 645, Minibatch Loss ---- Train = 1.200992; Test = 0.932192\n",
      "Iter 646, Minibatch Loss ---- Train = 1.199270; Test = 0.960733\n",
      "Iter 647, Minibatch Loss ---- Train = 0.966198; Test = 0.800312\n",
      "Iter 648, Minibatch Loss ---- Train = 1.056603; Test = 0.979498\n",
      "Iter 649, Minibatch Loss ---- Train = 1.425246; Test = 0.919158\n",
      "Iter 650, Minibatch Loss ---- Train = 1.179708; Test = 0.895535\n",
      "Iter 651, Minibatch Loss ---- Train = 0.845871; Test = 0.796188\n",
      "Iter 652, Minibatch Loss ---- Train = 1.256423; Test = 0.838256\n",
      "Iter 653, Minibatch Loss ---- Train = 1.407219; Test = 1.206026\n",
      "Iter 654, Minibatch Loss ---- Train = 1.782205; Test = 1.496505\n",
      "Iter 655, Minibatch Loss ---- Train = 1.129284; Test = 0.854193\n",
      "Iter 656, Minibatch Loss ---- Train = 1.021341; Test = 0.840027\n",
      "Iter 657, Minibatch Loss ---- Train = 1.060521; Test = 0.899656\n",
      "Iter 658, Minibatch Loss ---- Train = 1.024445; Test = 0.841729\n",
      "Iter 659, Minibatch Loss ---- Train = 0.961687; Test = 0.838592\n",
      "Iter 660, Minibatch Loss ---- Train = 1.090496; Test = 0.845755\n",
      "Iter 661, Minibatch Loss ---- Train = 1.399735; Test = 1.157118\n",
      "Iter 662, Minibatch Loss ---- Train = 0.998969; Test = 0.867564\n",
      "Iter 663, Minibatch Loss ---- Train = 0.862423; Test = 0.842523\n",
      "Iter 664, Minibatch Loss ---- Train = 0.925144; Test = 0.812031\n",
      "Iter 665, Minibatch Loss ---- Train = 0.951351; Test = 0.831317\n",
      "Iter 666, Minibatch Loss ---- Train = 1.216889; Test = 1.074790\n",
      "Iter 667, Minibatch Loss ---- Train = 1.033504; Test = 0.789156\n",
      "Iter 668, Minibatch Loss ---- Train = 1.181168; Test = 1.037825\n",
      "Iter 669, Minibatch Loss ---- Train = 1.007288; Test = 0.898890\n",
      "Iter 670, Minibatch Loss ---- Train = 1.126850; Test = 0.797380\n",
      "Iter 671, Minibatch Loss ---- Train = 1.204442; Test = 0.906822\n",
      "Iter 672, Minibatch Loss ---- Train = 3.850002; Test = 4.385677\n",
      "Iter 673, Minibatch Loss ---- Train = 1.354585; Test = 0.961645\n",
      "Iter 674, Minibatch Loss ---- Train = 1.170703; Test = 0.979247\n",
      "Iter 675, Minibatch Loss ---- Train = 1.082349; Test = 0.906133\n",
      "Iter 676, Minibatch Loss ---- Train = 1.357831; Test = 0.964168\n",
      "Iter 677, Minibatch Loss ---- Train = 1.200295; Test = 1.002466\n",
      "Iter 678, Minibatch Loss ---- Train = 1.062659; Test = 0.981553\n",
      "Iter 679, Minibatch Loss ---- Train = 2.164088; Test = 1.766040\n",
      "Iter 680, Minibatch Loss ---- Train = 1.532875; Test = 1.161660\n",
      "Iter 681, Minibatch Loss ---- Train = 1.136499; Test = 0.901095\n",
      "Iter 682, Minibatch Loss ---- Train = 1.237020; Test = 0.912844\n",
      "Iter 683, Minibatch Loss ---- Train = 1.050046; Test = 0.876198\n",
      "Iter 684, Minibatch Loss ---- Train = 1.032806; Test = 0.870619\n",
      "Iter 685, Minibatch Loss ---- Train = 1.285090; Test = 1.046037\n",
      "Iter 686, Minibatch Loss ---- Train = 1.170163; Test = 1.009889\n",
      "Iter 687, Minibatch Loss ---- Train = 1.179552; Test = 0.944874\n",
      "Iter 688, Minibatch Loss ---- Train = 1.495075; Test = 1.392468\n",
      "Iter 689, Minibatch Loss ---- Train = 1.309451; Test = 1.082209\n",
      "Iter 690, Minibatch Loss ---- Train = 1.211196; Test = 0.924860\n",
      "Iter 691, Minibatch Loss ---- Train = 1.015107; Test = 0.908404\n",
      "Iter 692, Minibatch Loss ---- Train = 1.403911; Test = 1.104238\n",
      "Iter 693, Minibatch Loss ---- Train = 1.159320; Test = 0.937930\n",
      "Iter 694, Minibatch Loss ---- Train = 1.186998; Test = 0.969717\n",
      "Iter 695, Minibatch Loss ---- Train = 1.046356; Test = 0.941586\n",
      "Iter 696, Minibatch Loss ---- Train = 1.154467; Test = 1.082097\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5d0d8178b5b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mloss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mistate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mloss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mistate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m            \u001b[1;31m#compute the cost on the validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0moutput_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mistate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0moutp_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_tmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0moutput_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mistate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## iterating among all customers to find current training customer\n",
    "result_final = []\n",
    "for i in range(20):\n",
    "    test_x_name = data_dir + 'test_x_' + str(i) + '.csv'\n",
    "    test_y_name = data_dir + 'test_y_' + str(i) + '.csv'\n",
    "    train_x_name = data_dir + 'train_x_' + str(i) + '.csv'\n",
    "    train_y_name = data_dir + 'train_y_' + str(i) + '.csv'\n",
    "    tmp_data = np.array(pd.read_csv(test_x_name,header = None))\n",
    "    test_x_data = tmp_data[:,1:]\n",
    "    # print test_x_data.dtype  data are stored as float64 double precision format\n",
    "    tmp_data = np.array(pd.read_csv(test_y_name,header = None))\n",
    "    test_y_data = tmp_data[:,1:]\n",
    "    tmp_data = np.array(pd.read_csv(train_x_name,header = None))\n",
    "    train_x_data = tmp_data[:,1:]\n",
    "    tmp_data = np.array(pd.read_csv(train_y_name,header = None))\n",
    "    train_y_data = tmp_data[:,1:]\n",
    "    traindays = train_y_data.shape[0]\n",
    "    # generate test data\n",
    "    test_x,test_y = test_data_gen(test_x_data,test_y_data,n_steps)\n",
    "    test_x = test_x.reshape(test_batch_size,n_steps,feature_size)\n",
    "    ### Execute\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    outp = []\n",
    "    outlist = np.zeros([Rs,test_batch_size])\n",
    "    with tf.Session() as sess:\n",
    "        # Create a summary to monitor cost function\n",
    "        #tf.scalar_summary(\"loss\", cost)\n",
    "        #tf.scalar_summary(\"loss2\",cost2)\n",
    "        # Merge all summaries to a single operator\n",
    "        #merged_summary_op = tf.merge_all_summaries()\n",
    "\n",
    "        # tensorboard info.# Set logs writer into folder /tmp/tensorflow_logs\n",
    "        #summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=sess.graph_def)\n",
    "\n",
    "        #initialize all variables in the model\n",
    "        sess.run(init)\n",
    "        for k in range(num_epoches):\n",
    "            #Generate Data for each epoch\n",
    "            #What this does is it creates a list of of elements of length seq_len, each of size [batch_size,input_size]\n",
    "            #this is required to feed data into rnn.rnn\n",
    "            X,Y = train_data_gen(traindays,train_x_data,train_y_data,n_steps)\n",
    "            X = X.reshape(train_batch_size,n_steps,feature_size)\n",
    "\n",
    "\n",
    "            #Create the dictionary of inputs to feed into sess.run\n",
    "            if k < 50:\n",
    "                sess.run(optimizer2,feed_dict={x:X,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))})\n",
    "            else:\n",
    "                sess.run(optimizer,feed_dict={x:X,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))})   \n",
    "            #perform an update on the parameters\n",
    "\n",
    "            loss1 = sess.run(cost, feed_dict = {x:X,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))} )\n",
    "            loss2 = sess.run(cost, feed_dict = {x:test_x,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )            #compute the cost on the validation set\n",
    "            output_tmp = sess.run(pred,feed_dict = {x:X,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))} )\n",
    "            outp_train = output_tmp\n",
    "            output_tmp = sess.run(pred,feed_dict = {x:test_x,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )\n",
    "            outp_test = output_tmp\n",
    "            if k >= num_epoches-Rs:\n",
    "                outlist[k-num_epoches+Rs,:] = outp_test.copy().T\n",
    "\n",
    "            # Write logs at every iteration\n",
    "            #summary_str = sess.run(merged_summary_op, feed_dict={x:test_x,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )\n",
    "            #summary_writer.add_summary(summary_str, k)\n",
    "            print \"Iter \" + str(k) + \", Minibatch Loss ---- Train = \" + \"{:.6f}\".format(loss1) + \"; Test = \" + \"{:.6f}\".format(loss2)\n",
    "        #print \"haha{}\".format(outp)\n",
    "    R = []\n",
    "    RR  = []\n",
    "    for i in range(Rs):\n",
    "        out = np.array(outlist[i])\n",
    "        R.append(np.corrcoef(out.T,test_y.T)[0,1])\n",
    "        RR.append(np.corrcoef(out.T,test_y.T)[0,1]**2)\n",
    "    print R\n",
    "    RRR = np.mean(R)# average Rs R in this time of train\n",
    "    # Draw\n",
    "    #xxx = np.arange(0,test_batch_size)\n",
    "    #pl.plot(xxx,out,color = \"red\")\n",
    "    #pl.plot(xxx,test_y)\n",
    "    #pl.grid()\n",
    "    #pl.legend()\n",
    "    #pl.show()\n",
    "    \n",
    "    # run time\n",
    "    time2 = time.time()\n",
    "    print 'total running time cost:{}s'.format(time2-time1)\n",
    "    \n",
    "    # append R\n",
    "    result_final.append(RRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.70003356532066896,\n",
       " 0.74178963706467693,\n",
       " 0.58180925719145793,\n",
       " 0.58155671277989529,\n",
       " 0.60517719499771783]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
